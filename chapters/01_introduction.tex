% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Introduction}\label{chapter:introduction}

With the rapid development of communication technologies, social media has become one of the most frequently used news sources. It is easier, faster, and offers interaction with people.~\citeauthor{NewsConsumptionAcrossSocialMedia_pewresearch} (\citeyear{NewsConsumptionAcrossSocialMedia_pewresearch}) report that 48\% of adults in the U.S. "often" or "sometimes" get their news from social media. Furthermore, global data presented by~\citeauthor{StatistaUsageOfSocialMedia_Watson} (\citeyear{StatistaUsageOfSocialMedia_Watson}) shows that the rate of adults who use social media as a news source is under 40\% in The United Kingdom, The Netherlands, Germany, and Japan while this rate is over 70\% in Kenya, Malaysia, Phillippines, Bulgaria, and Greece.\\
While ensuring convenience, interactivity, and speed, social media can also be used as a ground to spread any kind
of information as there are no regulatory authorities checking the posts. As a result, floods of false and misleading information can be observed on social media~\parencite{SocialMediaAndFakeNewsIn2016Election_Allcott}.\\
Up to now, the research community has introduced numerous approaches to counteract the uncontrolled dissemination of fake news. For instance, some studies focus on building and analyzing datasets~\parencite{FakeNewsDetectionOnSocialMediaADataMiningPerspective_Shu, LiarLiarPantsOnFire_Wang, FakeReddit_Nakamura, SomeLikeItHoaxDataset_Tacchini, BuzzfaceDataset_Santia, UPFD_Dataset_Shu}, and some studies leveraged the power of \emph{Machine Learning} (ML) to automatically detect fake news by learning features from data. Due to the number of posts and the limitation of staff to check the posts, ML-based techniques can reduce manual labor when used with human supervision to counter the spreading of fake news. Since the task of detecting fake news is not trivial, the adopted ML methods are intrinsically complex. ML-based techniques with high complexity, such as \emph{Deep Neural Networks} (DNNs), are harder to understand and interpret since they act like black-boxes~\parencite{CanWeOpenTheBlackBoxOfAI_Castelvecchi}.\\
The integration of ML-based methods into society gains more impact every day. While incredibly helpful in some aspects, ML-based techniques do not offer a reason for a particular prediction. Furthermore, we can not simply accept classification accuracy as a metric to evaluate real-world problems ~\parencite{TowardsARigorousScienceML_Velez}. Therefore, integrating ML-based methods into society makes interpretability a requirement to increase social acceptance~\parencite{InterpretableMachineLearning_Molnar}.\\
Consequently, a new research field called \emph{eXplainable Artificial Intelligence} (XAI) has surfaced to fill this missing link between humans and \emph{Artificial Intelligence} (AI). XAI proposes creating a set of ML techniques that deliver more explainable models while preserving learning performance and helping humans to understand, properly trust, and effectively handle the emerging generation of artificially intelligent partners~\parencite{XAI_Gunning}. While incorporating XAI increases social acceptance, it also aims to create more privacy-aware~\parencite{SlaveToTheAlgorithm_EdwardsVeale}, fairer, and trustworthy systems~\parencite{TheMythosOfModelInterpretability_Lipton}.\\
Like all ML techniques, \emph{Fake News Detection} (FND) models need interpretability, particularly when implementing countermeasures for fake news. However, the interpretability of a model is not often considered despite the large amount of research produced in the last decade. Incorporating social context~\parencite{FakeNewsNet_Shu}, representing the propagation networks as graphs~\parencite{UPFD_Dataset_Shu}, and using \emph{Graph Neural Networks} (GNNs) to produce \emph{State Of The Art} (SOTA) models~\parencite{FakeNewsDetectionUsingGeometricDeepLearning_Monti} have increased the complexity, but also the performance of FND models. For instance, using social context data alone has proved more effective than utilizing textual data alone in recent studies~\parencite{UPFD_Dataset_Shu}. However, it is not clear which social features impact the decision process of these models.\\
This thesis focuses on the explainability of FND models using tools from the XAI suite. Specifically, we focus on news content-based models and mixed approaches (news content and social context) to elaborate on their interpretability. Thus, we define three research objectives:
\begin{description}
    \item[\textbf{RO1}] Determine the tools for explaining FND models.
    \item[\textbf{RO2}] Show that explanations of FND models play an essential role in understanding the shortcomings of the FND models.
    \item[\textbf{RO3}] Investigate the understandability of explanations and suggest improvements where necessary.
\end{description}
In Chapter~\ref{chapter:background}, we elaborate on fake news, FND methods, and XAI. We give foundations of fake news
and define its characteristics. We then categorize FND models and give important examples from the literature. After examining fake news and its detection methods, we focus on the characterization of XAI and give definitions that will be
used throughout this thesis.\\
In Chapter~\ref{chapter:NewsContentModelsForFND}, we introduce the background for the news content model we used, examining how it is constructed. With this information, we then discuss the news content dataset which is used in the training of our news content model. After sharing our insights and statistics from the dataset, we move on to reporting the model performance. In this chapter, we also explain the reasons behind our model's performance by conducting several experiments using the explanation tool provided in~\ref{subsec:ExplainingNewsContentModels_SHAPFramework}. We show that our model can indeed be improved with the help of explanation techniques.\\
In Chapter~\ref{chapter:MixedApproachesForFND}, we introduce a different type of neural network, namely GNNs. We summarize how GNNs are constructed, what kind of GNNs exist for FND, and how to work with them. For FND, We use a mixed approach that utilizes news content and social context data. We give our insights from the dataset and report our model's performance on the dataset. Lastly, we make use of a recently introduced explanation technique for GNNs to understand our model's behavior.\\
In Chapter~\ref{chapter:conclusion}, we talk about our findings from Chapter~\ref{chapter:NewsContentModelsForFND} and Chapter~\ref{chapter:MixedApproachesForFND}. We show that research objectives are attained. Additionally, we discuss the limitations that we have encountered and possible future works.\\


% \subsection{Subsection}

% See~\autoref{tab:sample}, \autoref{fig:sample-drawing}, \autoref{fig:sample-plot}, \autoref{fig:sample-listing}.

% \begin{table}[htpb]
%     \caption[Example table]{An example for a simple table.}\label{tab:sample}
%     \centering
%     \begin{tabular}{l l l l}
%         \toprule
%         A & B & C & D \\
%         \midrule
%         1 & 2 & 1 & 2 \\
%         2 & 3 & 2 & 3 \\
%         \bottomrule
%     \end{tabular}
% \end{table}

% \begin{figure}[htpb]
%     \centering
%     % This should probably go into a file in figures/
%     \begin{tikzpicture}[node distance=3cm]
%         \node (R0) {$R_1$};
%         \node (R1) [right of=R0] {$R_2$};
%         \node (R2) [below of=R1] {$R_4$};
%         \node (R3) [below of=R0] {$R_3$};
%         \node (R4) [right of=R1] {$R_5$};

%         \path[every node]
%         (R0) edge (R1)
%         (R0) edge (R3)
%         (R3) edge (R2)
%         (R2) edge (R1)
%         (R1) edge (R4);
%     \end{tikzpicture}
%     \caption[Example drawing]{An example for a simple drawing.}\label{fig:sample-drawing}
% \end{figure}

% \begin{figure}[htpb]
%     \centering

%     \pgfplotstableset{col sep=&, row sep=\\}
%     % This should probably go into a file in data/
%     \pgfplotstableread{
%         a & b    \\
%         1 & 1000 \\
%         2 & 1500 \\
%         3 & 1600 \\
%     }\exampleA
%     \pgfplotstableread{
%         a & b    \\
%         1 & 1200 \\
%         2 & 800 \\
%         3 & 1400 \\
%     }\exampleB
%     % This should probably go into a file in figures/
%     \begin{tikzpicture}
%         \begin{axis}[
%                 ymin=0,
%                 legend style={legend pos=south east},
%                 grid,
%                 thick,
%                 ylabel=Y,
%                 xlabel=X
%             ]
%             \addplot table[x=a, y=b]{\exampleA};
%             \addlegendentry{Example A};
%             \addplot table[x=a, y=b]{\exampleB};
%             \addlegendentry{Example B};
%         \end{axis}
%     \end{tikzpicture}
%     \caption[Example plot]{An example for a simple plot.}\label{fig:sample-plot}
% \end{figure}

% \begin{figure}[htpb]
%     \centering
%     \begin{tabular}{c}
%         \begin{lstlisting}[language=SQL]
%     SELECT * FROM tbl WHERE tbl.str = "str"
%   \end{lstlisting}
%     \end{tabular}
%     \caption[Example listing]{An example for a source code listing.}\label{fig:sample-listing}
% \end{figure}
