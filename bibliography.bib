@article{ThePsycologyOfFakeNews_Pennycook,
  title    = {The Psychology of Fake News},
  journal  = {Trends in Cognitive Sciences},
  volume   = {25},
  number   = {5},
  pages    = {388-402},
  year     = {2021},
  issn     = {1364-6613},
  doi      = {https://doi.org/10.1016/j.tics.2021.02.007},
  url      = {https://www.sciencedirect.com/science/article/pii/S1364661321000516},
  author   = {Gordon Pennycook and David G. Rand},
  keywords = {fake news, misinformation, social media, news media, motivated reasoning, dual process theory, crowdsourcing, attention, information sharing},
  abstract = {We synthesize a burgeoning literature investigating why people believe and share false or highly misleading news online. Contrary to a common narrative whereby politics drives susceptibility to fake news, people are ‘better’ at discerning truth from falsehood (despite greater overall belief) when evaluating politically concordant news. Instead, poor truth discernment is associated with lack of careful reasoning and relevant knowledge, and the use of heuristics such as familiarity. Furthermore, there is a substantial disconnect between what people believe and what they share on social media. This dissociation is largely driven by inattention, more so than by purposeful sharing of misinformation. Thus, interventions can successfully nudge social media users to focus more on accuracy. Crowdsourced veracity ratings can also be leveraged to improve social media ranking algorithms.}
}

@article{TheScienceOfFakeNews_Lazer,
  author   = {David M. J. Lazer  and Matthew A. Baum  and Yochai Benkler  and Adam J. Berinsky  and Kelly M. Greenhill  and Filippo Menczer  and Miriam J. Metzger  and Brendan Nyhan  and Gordon Pennycook  and David Rothschild  and Michael Schudson  and Steven A. Sloman  and Cass R. Sunstein  and Emily A. Thorson  and Duncan J. Watts  and Jonathan L. Zittrain },
  title    = {The science of fake news},
  journal  = {Science},
  volume   = {359},
  number   = {6380},
  pages    = {1094-1096},
  year     = {2018},
  doi      = {10.1126/science.aao2998},
  url      = {https://www.science.org/doi/abs/10.1126/science.aao2998},
  eprint   = {https://www.science.org/doi/pdf/10.1126/science.aao2998},
  abstract = {Addressing fake news requires a multidisciplinary effort The rise of fake news highlights the erosion of long-standing institutional bulwarks against misinformation in the internet age. Concern over the problem is global. However, much remains unknown regarding the vulnerabilities of individuals, institutions, and society to manipulations by malicious actors. A new system of safeguards is needed. Below, we discuss extant social and computer science research regarding belief in fake news and the mechanisms by which it spreads. Fake news has a long history, but we focus on unanswered scientific questions raised by the proliferation of its most recent, politically oriented incarnation. Beyond selected references in the text, suggested further reading can be found in the supplementary materials.}
}

@article{FakeNewsDetectionOnSocialMediaADataMiningPerspective_Shu,
  author     = {Shu, Kai and Sliva, Amy and Wang, Suhang and Tang, Jiliang and Liu, Huan},
  title      = {Fake News Detection on Social Media: A Data Mining Perspective},
  year       = {2017},
  issue_date = {June 2017},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {19},
  number     = {1},
  issn       = {1931-0145},
  url        = {https://doi.org/10.1145/3137597.3137600},
  doi        = {10.1145/3137597.3137600},
  abstract   = {Social media for news consumption is a double-edged sword. On the one hand, its low cost, easy access, and rapid dissemination of information lead people to seek out and consume news from social media. On the other hand, it enables the wide spread of fake news", i.e., low quality news with intentionally false information. The extensive spread of fake news has the potential for extremely negative impacts on individuals and society. Therefore, fake news detection on social media has recently become an emerging research that is attracting tremendous attention. Fake news detection on social media presents unique characteristics and challenges that make existing detection algorithms from traditional news media ine ective or not applicable. First, fake news is intentionally written to mislead readers to believe false information, which makes it difficult and nontrivial to detect based on news content; therefore, we need to include auxiliary information, such as user social engagements on social media, to help make a determination. Second, exploiting this auxiliary information is challenging in and of itself as users' social engagements with fake news produce data that is big, incomplete, unstructured, and noisy. Because the issue of fake news detection on social media is both challenging and relevant, we conducted this survey to further facilitate research on the problem. In this survey, we present a comprehensive review of detecting fake news on social media, including fake news characterizations on psychology and social theories, existing algorithms from a data mining perspective, evaluation metrics and representative datasets. We also discuss related research areas, open problems, and future research directions for fake news detection on social media.},
  journal    = {SIGKDD Explor. Newsl.},
  month      = {sep},
  pages      = {22–36},
  numpages   = {15}
}

@article{FakeNewsAndThePublic_McKernon,
  title    = {Fake news and the public. How the press combats rumor, the market rigger, and the propagandist},
  issn     = {0017-789X},
  url      = {https://harpers.org/archive/1925/10/fake-news-and-the-public/},
  urldate  = {2018-05-04},
  journal  = {Harper's Magazine},
  author   = {McKernon, Edward},
  month    = oct,
  year     = {1925},
  keywords = {20th century, Journalism, Journalistic ethics, News agencies, Press and propaganda, Rumor, Stock exchanges and current events, United States}
}

 @article{ReutersInstituteDigitalNewsReport,
  title     = {Reuters Institute Digital News Report 2022},
  url       = {https://reutersinstitute.politics.ox.ac.uk/sites/default/files/2022-06/Digital_News-Report_2022.pdf},
  journal   = {Digital News Report 2022},
  publisher = {Reuters Institute for the Study of Journalism},
  author    = {Newman, Nic and Fletcher, Richard and Robertson, Craig T. and Eddy, Kirsten and Nielsen, Rasmus Kleis},
  year      = {2022},
  month     = {06}
}

@inbook{USPresidentialElection2016,
  title     = {United States Presidential Election of 2016},
  booktitle = {Encyclopedia Britannica},
  author    = {Beckwith, David C},
  abstract  = {United States Presidential Election of 2016, American
               presidential election held on November 8, 2016, in which
               Republican Donald Trump lost the popular vote to Democrat
               Hillary Clinton by more than 2.8 million votes but won 30 states
               and the decisive electoral college with 304 electoral votes to
               Clinton's 227 and thus became the 45th president of the United
               States. The tumultuous, abrasive 2016 campaign defied
               established political norms. Clinton's campaign featured
               superior organization and fund-raising---and almost every
               election-eve poll pointed to a comfortable victory for her---but
               Trump's anti-Washington appeal to white working-class voters
               outside major cities in pivotal manufacturing states},
  month     = {10},
  year      = {2021}
}

@misc{FakeNewsNet_Shu,
  doi       = {10.48550/ARXIV.1809.01286},
  url       = {https://arxiv.org/abs/1809.01286},
  author    = {Shu, Kai and Mahudeswaran, Deepak and Wang, Suhang and Lee, Dongwon and Liu, Huan},
  keywords  = {Social and Information Networks (cs.SI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {FakeNewsNet: A Data Repository with News Content, Social Context and Spatialtemporal Information for Studying Fake News on Social Media},
  publisher = {arXiv},
  year      = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{LiarLiarPantsOnFire_Wang,
  author     = {William Yang Wang},
  title      = {"Liar, Liar Pants on Fire": {A} New Benchmark Dataset for Fake News
                Detection},
  journal    = {CoRR},
  volume     = {abs/1705.00648},
  year       = {2017},
  url        = {http://arxiv.org/abs/1705.00648},
  eprinttype = {arXiv},
  eprint     = {1705.00648},
  timestamp  = {Mon, 13 Aug 2018 16:48:58 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/Wang17j.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{FakeNewsDetectionUsingGeometricDeepLearning_Monti,
  author     = {Federico Monti and
                Fabrizio Frasca and
                Davide Eynard and
                Damon Mannion and
                Michael M. Bronstein},
  title      = {Fake News Detection on Social Media using Geometric Deep Learning},
  journal    = {CoRR},
  volume     = {abs/1902.06673},
  year       = {2019},
  url        = {http://arxiv.org/abs/1902.06673},
  eprinttype = {arXiv},
  eprint     = {1902.06673},
  timestamp  = {Tue, 21 May 2019 18:03:39 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1902-06673.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}


@article{UPFD_Dataset_Shu,
  author     = {Yingtong Dou and
                Kai Shu and
                Congying Xia and
                Philip S. Yu and
                Lichao Sun},
  title      = {User Preference-aware Fake News Detection},
  journal    = {CoRR},
  volume     = {abs/2104.12259},
  year       = {2021},
  url        = {https://arxiv.org/abs/2104.12259},
  eprinttype = {arXiv},
  eprint     = {2104.12259},
  timestamp  = {Mon, 03 May 2021 17:38:30 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2104-12259.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@misc{GraphAttentionNetworks_Velickovic,
  doi       = {10.48550/ARXIV.1710.10903},
  url       = {https://arxiv.org/abs/1710.10903},
  author    = {Veličković, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Liò, Pietro and Bengio, Yoshua},
  keywords  = {Machine Learning (stat.ML), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), Social and Information Networks (cs.SI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Graph Attention Networks},
  publisher = {arXiv},
  year      = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{FakeReddit_Nakamura,
  title     = {{F}akeddit: A New Multimodal Benchmark Dataset for Fine-grained Fake News Detection},
  author    = {Nakamura, Kai  and
               Levy, Sharon  and
               Wang, William Yang},
  booktitle = {Proceedings of the 12th Language Resources and Evaluation Conference},
  month     = may,
  year      = {2020},
  address   = {Marseille, France},
  publisher = {European Language Resources Association},
  url       = {https://aclanthology.org/2020.lrec-1.755},
  pages     = {6149--6157},
  abstract  = {Fake news has altered society in negative ways in politics and culture. It has adversely affected both online social network systems as well as offline communities and conversations. Using automatic machine learning classification models is an efficient way to combat the widespread dissemination of fake news. However, a lack of effective, comprehensive datasets has been a problem for fake news research and detection model development. Prior fake news datasets do not provide multimodal text and image data, metadata, comment data, and fine-grained fake news categorization at the scale and breadth of our dataset. We present Fakeddit, a novel multimodal dataset consisting of over 1 million samples from multiple categories of fake news. After being processed through several stages of review, the samples are labeled according to 2-way, 3-way, and 6-way classification categories through distant supervision. We construct hybrid text+image models and perform extensive experiments for multiple variations of classification, demonstrating the importance of the novel aspect of multimodality and fine-grained classification unique to Fakeddit.},
  language  = {English},
  isbn      = {979-10-95546-34-4}
}

@article{SomeLikeItHoaxDataset_Tacchini,
  doi       = {10.48550/ARXIV.1704.07506},
  url       = {https://arxiv.org/abs/1704.07506},
  author    = {Tacchini, Eugenio and Ballarin, Gabriele and Della Vedova, Marco L. and Moret, Stefano and de Alfaro, Luca},
  keywords  = {Machine Learning (cs.LG), Human-Computer Interaction (cs.HC), Social and Information Networks (cs.SI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Some Like it Hoax: Automated Fake News Detection in Social Networks},
  publisher = {arXiv},
  year      = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@paper{BuzzfaceDataset_Santia,
  author     = {Giovanni Santia and Jake Williams},
  title      = {BuzzFace: A News Veracity Dataset with Facebook User Commentary and Egos},
  conference = {International AAAI Conference on Web and Social Media},
  year       = {2018},
  keywords   = {Facebook; news veracity; Disqus; social bots},
  abstract   = {Veracity assessment of news and social bot detection have become two of the most pressing issues for social media platforms, yet current gold-standard data are limited. This paper presents a leap forward in the development of a sizeable and feature rich gold-standard dataset. The dataset was built by using a collection of news items posted to Facebook by nine news outlets during September 2016, which were annotated for veracity by BuzzFeed. These articles were refined beyond binary annotation to the four categories: mostly true, mostly false, mixture of true and false, and no factual content. Our contribution integrates data on Facebook comments and reactions publicly available on the platform’s Graph API, and provides tailored tools for accessing news article web content. The features of the accessed articles include body text, images, links, Facebook plugin comments, Disqus plugin comments, and embedded tweets. Embedded tweets provide a potent possible avenue for expansion across social media platforms. Upon development, this utility yielded over 1.6 million text items, making it over 400 times larger than the current gold-standard. The resulting dataset—BuzzFace—is presently the most extensive created, and allows for more robust machine learning applications to news veracity assessment and social bot detection than ever before.},
  url        = {https://www.aaai.org/ocs/index.php/ICWSM/ICWSM18/paper/view/17825/17046}
}

 @misc{NewsConsumptionAcrossSocialMedia_pewresearch,
  title     = {News consumption across social media in 2021},
  url       = {https://www.pewresearch.org/journalism/2021/09/20/news-consumption-across-social-media-in-2021/},
  journal   = {Pew Research Center's Journalism Project},
  publisher = {Pew Research Center},
  author    = {Walker, Mason and Matsa, Katerina Eva},
  year      = {2021},
  month     = {Sep}
}

@article{GetBackYouDontKnowMeLikeThat_Hannak,
  title        = {Get Back! You Don’t Know Me Like That: The Social Mediation of Fact Checking Interventions in Twitter Conversations},
  volume       = {8},
  url          = {https://ojs.aaai.org/index.php/ICWSM/article/view/14555},
  abstractnote = { &lt;p&gt; &lt;span&gt;The prevalence of misinformation within social media and online communities can undermine public security and distract attention from important issues. Fact-checking interventions, in which users cite fact-checking websites such as Snopes.com and FactCheck.org, are a strategy users can employ to refute false claims made by their peers. While laboratory research suggests such interventions are not effective in persuading people to abandon false ideas, little work considers how such interventions are actually deployed in real-world conversations. Using approximately 1,600 interventions observed on Twitter between 2012 and 2013, we examine the contexts and consequences of fact-checking interventions.W&lt;/span&gt;&lt;span&gt;e focus in particular on the social relationship between the individual who issues the fact-check and the individual whose facts are challenged. Our results indicate that though fact-checking interventions are most commonly issued by strangers, they are more likely to draw user attention and responses when they come from friends. Finally, we discuss implications for designing more effective interventions against misinformation.&lt;/span&gt; &lt;/p&gt; },
  number       = {1},
  journal      = {Proceedings of the International AAAI Conference on Web and Social Media},
  author       = {Hannak, Aniko and Margolin, Drew and Keegan, Brian and Weber, Ingmar},
  year         = {2014},
  month        = {May},
  pages        = {187-196}
}

@misc{GraphNeuralNetworksWithContinualLearningFakeNewsDetection_Han,
  doi       = {10.48550/ARXIV.2007.03316},
  url       = {https://arxiv.org/abs/2007.03316},
  author    = {Han, Yi and Karunasekera, Shanika and Leckie, Christopher},
  keywords  = {Social and Information Networks (cs.SI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Graph Neural Networks with Continual Learning for Fake News Detection from Social Media},
  publisher = {arXiv},
  year      = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{RumorDetectionBidirectionalGraphConvolutionalNetworks_Bian,
  doi       = {10.48550/ARXIV.2001.06362},
  url       = {https://arxiv.org/abs/2001.06362},
  author    = {Bian, Tian and Xiao, Xi and Xu, Tingyang and Zhao, Peilin and Huang, Wenbing and Rong, Yu and Huang, Junzhou},
  keywords  = {Social and Information Networks (cs.SI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Rumor Detection on Social Media with Bi-Directional Graph Convolutional Networks},
  publisher = {arXiv},
  year      = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{SAFEFND_Zhou,
  doi       = {10.48550/ARXIV.2003.04981},
  url       = {https://arxiv.org/abs/2003.04981},
  author    = {Zhou, Xinyi and Wu, Jindi and Zafarani, Reza},
  keywords  = {Computation and Language (cs.CL), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {SAFE: Similarity-Aware Multi-Modal Fake News Detection},
  publisher = {arXiv},
  year      = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{XAIConceptsTaxonomies_Arrieta,
  title    = {Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI},
  journal  = {Information Fusion},
  volume   = {58},
  pages    = {82-115},
  year     = {2020},
  issn     = {1566-2535},
  doi      = {https://doi.org/10.1016/j.inffus.2019.12.012},
  url      = {https://www.sciencedirect.com/science/article/pii/S1566253519308103},
  author   = {Alejandro {Barredo Arrieta} and Natalia Díaz-Rodríguez and Javier {Del Ser} and Adrien Bennetot and Siham Tabik and Alberto Barbado and Salvador Garcia and Sergio Gil-Lopez and Daniel Molina and Richard Benjamins and Raja Chatila and Francisco Herrera},
  keywords = {Explainable Artificial Intelligence, Machine Learning, Deep Learning, Data Fusion, Interpretability, Comprehensibility, Transparency, Privacy, Fairness, Accountability, Responsible Artificial Intelligence},
  abstract = {In the last few years, Artificial Intelligence (AI) has achieved a notable momentum that, if harnessed appropriately, may deliver the best of expectations over many application sectors across the field. For this to occur shortly in Machine Learning, the entire community stands in front of the barrier of explainability, an inherent problem of the latest techniques brought by sub-symbolism (e.g. ensembles or Deep Neural Networks) that were not present in the last hype of AI (namely, expert systems and rule based models). Paradigms underlying this problem fall within the so-called eXplainable AI (XAI) field, which is widely acknowledged as a crucial feature for the practical deployment of AI models. The overview presented in this article examines the existing literature and contributions already done in the field of XAI, including a prospect toward what is yet to be reached. For this purpose we summarize previous efforts made to define explainability in Machine Learning, establishing a novel definition of explainable Machine Learning that covers such prior conceptual propositions with a major focus on the audience for which the explainability is sought. Departing from this definition, we propose and discuss about a taxonomy of recent contributions related to the explainability of different Machine Learning models, including those aimed at explaining Deep Learning methods for which a second dedicated taxonomy is built and examined in detail. This critical literature analysis serves as the motivating background for a series of challenges faced by XAI, such as the interesting crossroads of data fusion and explainability. Our prospects lead toward the concept of Responsible Artificial Intelligence, namely, a methodology for the large-scale implementation of AI methods in real organizations with fairness, model explainability and accountability at its core. Our ultimate goal is to provide newcomers to the field of XAI with a thorough taxonomy that can serve as reference material in order to stimulate future research advances, but also to encourage experts and professionals from other disciplines to embrace the benefits of AI in their activity sectors, without any prior bias for its lack of interpretability.}
}

@book{InterpretableMachineLearning_Molnar,
  title    = {Interpretable Machine Learning},
  author   = {Christoph Molnar},
  year     = {2022},
  subtitle = {A Guide for Making Black Box Models Explainable},
  edition  = {2},
  url      = {https://christophm.github.io/interpretable-ml-book}
}

@misc{TowardsARigorousScienceML_Velez,
  doi       = {10.48550/ARXIV.1702.08608},
  url       = {https://arxiv.org/abs/1702.08608},
  author    = {Doshi-Velez, Finale and Kim, Been},
  keywords  = {Machine Learning (stat.ML), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Towards A Rigorous Science of Interpretable Machine Learning},
  publisher = {arXiv},
  year      = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{CanWeOpenTheBlackBoxOfAI_Castelvecchi,
  author  = {Castelvecchi, Davide},
  year    = {2016},
  month   = {10},
  pages   = {20-23},
  title   = {Can we open the black box of AI?},
  volume  = {538},
  journal = {Nature},
  doi     = {10.1038/538020a}
}

@article{XAI_Gunning,
  title        = {DARPA’s Explainable Artificial Intelligence (XAI) Program},
  volume       = {40},
  url          = {https://ojs.aaai.org/index.php/aimagazine/article/view/2850},
  doi          = {10.1609/aimag.v40i2.2850},
  abstractnote = {&lt;p&gt;Dramatic success in machine learning has led to a new wave of AI applications (for example, transportation, security, medicine, finance, defense) that offer tremendous benefits but cannot explain their decisions and actions to human users. DARPA’s explainable artificial intelligence (XAI) program endeavors to create AI systems whose learned models and decisions can be understood and appropriately trusted by end users. Realizing this goal requires methods for learning more explainable models, designing effective explanation interfaces, and understanding the psychologic requirements for effective explanations. The XAI developer teams are addressing the first two challenges by creating ML techniques and developing principles, strategies, and human-computer interaction techniques for generating effective explanations. Another XAI team is addressing the third challenge by summarizing, extending, and applying psychologic theories of explanation to help the XAI evaluator define a suitable evaluation framework, which the developer teams will use to test their systems. The XAI teams completed the first of this 4-year program in May 2018. In a series of ongoing evaluations, the developer teams are assessing how well their XAM systems’ explanations improve user understanding, user trust, and user task performance.&lt;/p&gt;},
  number       = {2},
  journal      = {AI Magazine},
  author       = {Gunning, David and Aha, David},
  year         = {2019},
  month        = {Jun.},
  pages        = {44-58}
}

@misc{TheMythosOfModelInterpretability_Lipton,
  doi       = {10.48550/ARXIV.1606.03490},
  url       = {https://arxiv.org/abs/1606.03490},
  author    = {Lipton, Zachary C.},
  keywords  = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Computer Vision and Pattern Recognition (cs.CV), Neural and Evolutionary Computing (cs.NE), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {The Mythos of Model Interpretability},
  publisher = {arXiv},
  year      = {2016},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{SlaveToTheAlgorithm_EdwardsVeale,
  title   = {Slave to the Algorithm? Why a 'Right to an Explanation' Is Probably Not the Remedy You Are Looking For},
  author  = {Lilian Edwards and Michael Veale},
  journal = {Duke law and technology review},
  year    = {2017},
  volume  = {16},
  pages   = {18-84}
}

@article{HierarchicalPropagationNetworksForFND_Shu,
  title        = {Hierarchical Propagation Networks for Fake News Detection: Investigation and Exploitation},
  volume       = {14},
  url          = {https://ojs.aaai.org/index.php/ICWSM/article/view/7329},
  abstractnote = {&lt;p&gt;Consuming news from social media is becoming increasingly popular. However, social media also enables the wide dissemination of &lt;em&gt;fake news&lt;/em&gt;. Because of the detrimental effects of fake news, fake news detection has attracted increasing attention. However, the performance of detecting fake news only from news content is generally limited as fake news pieces are written to mimic true news. In the real world, news pieces spread through &lt;em&gt;propagation networks&lt;/em&gt; on social media. The news propagation networks usually involve multi-levels. In this paper, we study the challenging problem of &lt;em&gt;investigating&lt;/em&gt; and &lt;em&gt;exploiting&lt;/em&gt; news hierarchical propagation network on social media for fake news detection.&lt;/p&gt;&lt;p&gt;In an attempt to understand the correlations between news propagation networks and fake news, first, we build hierarchical propagation networks for fake news and true news pieces; second, we perform a comparative analysis of the propagation network features from structural, temporal, and linguistic perspectives between fake and real news, which demonstrates the potential of utilizing these features to detect fake news; third, we show the effectiveness of these propagation network features for fake news detection. We further validate the effectiveness of these features from feature importance analysis. We conduct extensive experiments on real-world datasets and demonstrate the proposed features can significantly outperform state-of-the-art fake news detection methods by at least 1.7% with an average F1&gt;0.84. Altogether, this work presents a data-driven view of hierarchical propagation network and fake news and paves the way towards a healthier online news ecosystem.&lt;/p&gt;},
  number       = {1},
  journal      = {Proceedings of the International AAAI Conference on Web and Social Media},
  author       = {Shu, Kai and Mahudeswaran, Deepak and Wang, Suhang and Liu, Huan},
  year         = {2020},
  month        = {May},
  pages        = {626-637}
}

 @inbook{HistorysGreatestLies_Weir,
  place     = {Beverly, Massachusetts},
  booktitle = {History's greatest lies: The startling truths behind world events our history books got wrong},
  publisher = {Fair Winds Press},
  author    = {Weir, William},
  year      = {2009},
  pages     = {28–41}
}

 @misc{MarketQuaversAfterFakeAPTweet_ElBoghdady,
  title     = {Market quavers after fake AP tweet says Obama was hurt in White House explosions},
  url       = {https://www.washingtonpost.com/business/economy/market-quavers-after-fake-ap-tweet-says-obama-was-hurt-in-white-house-explosions/2013/04/23/d96d2dc6-ac4d-11e2-a8b9-2a63d75b5459_story.html},
  journal   = {The Washington Post},
  publisher = {WP Company},
  author    = {ElBoghdady, Dina},
  year      = {2013},
  month     = {Apr}
}

 @misc{Pizzagate_Fisher,
  title     = {Pizzagate: From rumor, to hashtag, to gunfire in D.C.},
  url       = {https://www.washingtonpost.com/local/pizzagate-from-rumor-to-hashtag-to-gunfire-in-dc/2016/12/06/4c7def50-bbd4-11e6-94ac-3d324840106c_story.html},
  journal   = {The Washington Post},
  publisher = {WP Company},
  author    = {Fisher, Marc and Cox, John Woodrow and Hermann, Peter},
  year      = {2016},
  month     = {Dec}
} 

 @misc{StatistaUsageOfSocialMedia_Watson,
  title   = {Usage of social media as a news source worldwide 2022},
  url     = {https://www.statista.com/statistics/718019/social-media-news-source/},
  journal = {Statista},
  author  = {Watson, Amy},
  year    = {2022},
  month   = {Aug}
}

@article{SocialMediaAndFakeNewsIn2016Election_Allcott,
  author  = {Allcott, Hunt and Gentzkow, Matthew},
  title   = {Social Media and Fake News in the 2016 Election},
  journal = {Journal of Economic Perspectives},
  volume  = {31},
  number  = {2},
  year    = {2017},
  month   = {May},
  pages   = {211-36},
  doi     = {10.1257/jep.31.2.211},
  url     = {https://www.aeaweb.org/articles?id=10.1257/jep.31.2.211}
}

@inbook{TheGreatMoonHoax_Foster,
  author    = {Foster, Vincent S.},
  title     = {The Great Moon Hoax},
  booktitle = {Modern Mysteries of the Moon: What We Still Don't Know About Our Lunar Companion},
  year      = {2016},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {11--44},
  abstract  = {Back in 1835 there was a Moon hoax that thousands of people fell for, despite the tale being complete fiction. A series of articles were published in a newspaper reporting incredible new astronomical observations of the Moon supposedly made by astronomer Sir John Herschel during an observing run at the Cape of Good Hope. Detailed descriptions of winged beings, plants, animals and a sapphire temple increased sales and subscriptions to the fledgling newspaper. The chapter offers a selection of these articles as they were published in the New York Sun.},
  isbn      = {978-3-319-22120-5},
  doi       = {10.1007/978-3-319-22120-5_2},
  url       = {https://doi.org/10.1007/978-3-319-22120-5_2}
}

 @misc{Buzzfeed_FakeNewsOutperformRealNews_Silverman,
  title     = {This analysis shows how viral fake election news stories outperformed Real News on facebook},
  url       = {https://www.buzzfeednews.com/article/craigsilverman/viral-fake-election-news-outperformed-real-news-on-facebook},
  journal   = {BuzzFeed News},
  publisher = {BuzzFeed News},
  author    = {Silverman, Craig},
  year      = {2016},
  month     = {Nov}
} 

 @misc{TrumpWonBecauseOfFacebook_Read,
  title     = {Donald Trump won because of Facebook},
  url       = {https://nymag.com/intelligencer/2016/11/donald-trump-won-because-of-facebook.html},
  journal   = {Intelligencer},
  publisher = {Intelligencer},
  author    = {Read, Max},
  year      = {2016},
  month     = {Nov}
}

@article{ConfirmationBias_Nickerson,
  author   = {Raymond S. Nickerson},
  title    = {Confirmation Bias: A Ubiquitous Phenomenon in Many Guises},
  journal  = {Review of General Psychology},
  volume   = {2},
  number   = {2},
  pages    = {175-220},
  year     = {1998},
  doi      = {10.1037/1089-2680.2.2.175},
  url      = { 
              https://doi.org/10.1037/1089-2680.2.2.175
              
              },
  eprint   = { 
              https://doi.org/10.1037/1089-2680.2.2.175
              
              },
  abstract = { Confirmation bias, as the term is typically used in the psychological literature, connotes the seeking or interpreting of evidence in ways that are partial to existing beliefs, expectations, or a hypothesis in hand. The author reviews evidence of such a bias in a variety of guises and gives examples of its operation in several practical contexts. Possible explanations are considered, and the question of its utility or disutility is discussed. }
}

@inproceedings{NaiveRealism_Reed,
  title  = {Naive Realism in Everyday Life: Implications for Social Conflict and Misunderstanding},
  author = {Edward S. Reed and Elliot Turiel and Terrance Brown},
  year   = {2013}
}

@article{SocialIdentityTheory_Ashforth,
  issn      = {03637425},
  url       = {http://www.jstor.org/stable/258189},
  abstract  = {It is argued that (a) social identification is a perception of oneness with a group of persons; (b) social identification stems from the categorization of individuals, the distinctiveness and prestige of the group, the salience of outgroups, and the factors that traditionally are associated with group formation; and (c) social identification leads to activities that are congruent with the identity, support for institutions that embody the identity, stereotypical perceptions of self and others, and outcomes that traditionally are associated with group formation, and it reinforces the antecedents of identification. This perspective is applied to organizational socialization, role conflict, and intergroup relations.},
  author    = {Blake E. Ashforth and Fred Mael},
  journal   = {The Academy of Management Review},
  number    = {1},
  pages     = {20--39},
  publisher = {Academy of Management},
  title     = {Social Identity Theory and the Organization},
  urldate   = {2022-09-12},
  volume    = {14},
  year      = {1989}
}

@article{NormativeSocialInfluence_Asch,
  journal = {Groups, leadership, and men},
  title   = {Effects of group pressure upon the modification and distortion of
             judgments.},
  author  = {Asch, S E and Guetzkow, H},
  pages   = {222--236},
  year    = {1951}
}

 @book{TheFilterBubble_Pariser,
  place     = {London},
  title     = {The filter bubble: What the internet is hiding from you},
  publisher = {Penguin UK},
  author    = {Pariser, Eli},
  year      = {2011}
}

 @book{EchoChambers_Sunstein,
  place     = {Princeton, NJ},
  title     = {Echo chambers: Bush v. Gore, impeachment, and beyond},
  publisher = {Princeton University Press},
  author    = {Sunstein, Cass R.},
  year      = {2001}
} 

@article{TheSpreadingOfMisinformationOnline_DelVicario,
  author   = {Michela Del Vicario  and Alessandro Bessi  and Fabiana Zollo  and Fabio Petroni  and Antonio Scala  and Guido Caldarelli  and H. Eugene Stanley  and Walter Quattrociocchi },
  title    = {The spreading of misinformation online},
  journal  = {Proceedings of the National Academy of Sciences},
  volume   = {113},
  number   = {3},
  pages    = {554-559},
  year     = {2016},
  doi      = {10.1073/pnas.1517441113},
  url      = {https://www.pnas.org/doi/abs/10.1073/pnas.1517441113},
  eprint   = {https://www.pnas.org/doi/pdf/10.1073/pnas.1517441113},
  abstract = {The wide availability of user-provided content in online social media facilitates the aggregation of people around common interests, worldviews, and narratives. However, the World Wide Web (WWW) also allows for the rapid dissemination of unsubstantiated rumors and conspiracy theories that often elicit rapid, large, but naive social responses such as the recent case of Jade Helm 15––where a simple military exercise turned out to be perceived as the beginning of a new civil war in the United States. In this work, we address the determinants governing misinformation spreading through a thorough quantitative analysis. In particular, we focus on how Facebook users consume information related to two distinct narratives: scientific and conspiracy news. We find that, although consumers of scientific and conspiracy stories present similar consumption patterns with respect to content, cascade dynamics differ. Selective exposure to content is the primary driver of content diffusion and generates the formation of homogeneous clusters, i.e., “echo chambers.” Indeed, homogeneity appears to be the primary driver for the diffusion of contents and each echo chamber has its own cascade dynamics. Finally, we introduce a data-driven percolation model mimicking rumor spreading and we show that homogeneity and polarization are the main determinants for predicting cascades’ size.}
}

@article{AutomaticDeceptionDetection_Conroy,
  author   = {Conroy, Nadia K. and Rubin, Victoria L. and Chen, Yimin},
  title    = {Automatic deception detection: Methods for finding fake news},
  journal  = {Proceedings of the Association for Information Science and Technology},
  volume   = {52},
  number   = {1},
  pages    = {1-4},
  keywords = {Deception detection, fake news detection, veracity assessment, news verification, methods, automation, SVM, knowledge networks, predictive modelling, fraud},
  doi      = {https://doi.org/10.1002/pra2.2015.145052010082},
  url      = {https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/pra2.2015.145052010082},
  eprint   = {https://asistdl.onlinelibrary.wiley.com/doi/pdf/10.1002/pra2.2015.145052010082},
  abstract = {ABSTRACT This research surveys the current state-of-the-art technologies that are instrumental in the adoption and development of fake news detection. “Fake news detection” is defined as the task of categorizing news along a continuum of veracity, with an associated measure of certainty. Veracity is compromised by the occurrence of intentional deceptions. The nature of online news publication has changed, such that traditional fact checking and vetting from potential deception is impossible against the flood arising from content generators, as well as various formats and genres. The paper provides a typology of several varieties of veracity assessment methods emerging from two major categories – linguistic cue approaches (with machine learning), and network analysis approaches. We see promise in an innovative hybrid approach that combines linguistic cue and machine learning, with network-based behavioral data. Although designing a fake news detector is not a straightforward problem, we propose operational guidelines for a feasible fake news detecting system.},
  year     = {2015}
}

@article{TheFakeNewsSpreadingPlague_Mustafaraj,
  author     = {Eni Mustafaraj and
                Panagiotis Takis Metaxas},
  title      = {The Fake News Spreading Plague: Was it Preventable?},
  journal    = {CoRR},
  volume     = {abs/1703.06988},
  year       = {2017},
  url        = {http://arxiv.org/abs/1703.06988},
  eprinttype = {arXiv},
  eprint     = {1703.06988},
  timestamp  = {Mon, 13 Aug 2018 16:48:43 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/MustafarajM17.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{WhenFakeNewsBecomesReal_Balmas,
  author   = {Meital Balmas},
  title    = {When Fake News Becomes Real: Combined Exposure to Multiple News Sources and Political Attitudes of Inefficacy, Alienation, and Cynicism},
  journal  = {Communication Research},
  volume   = {41},
  number   = {3},
  pages    = {430-454},
  year     = {2014},
  doi      = {10.1177/0093650212453600},
  url      = { 
              https://doi.org/10.1177/0093650212453600
              
              },
  eprint   = { 
              https://doi.org/10.1177/0093650212453600
              
              },
  abstract = { This research assesses possible associations between viewing fake news (i.e., political satire) and attitudes of inefficacy, alienation, and cynicism toward political candidates. Using survey data collected during the 2006 Israeli election campaign, the study provides evidence for an indirect positive effect of fake news viewing in fostering the feelings of inefficacy, alienation, and cynicism, through the mediator variable of perceived realism of fake news. Within this process, hard news viewing serves as a moderator of the association between viewing fake news and their perceived realism. It was also demonstrated that perceived realism of fake news is stronger among individuals with high exposure to fake news and low exposure to hard news than among those with high exposure to both fake and hard news. Overall, this study contributes to the scientific knowledge regarding the influence of the interaction between various types of media use on political effects. }
}

@article{TheImpactOfRealNewsAboutFakeNews_Brewer,
  author   = {Brewer, Paul R. and Young, Dannagal Goldthwaite and Morreale, Michelle},
  title    = {{The Impact of Real News about “Fake News”: Intertextual Processes and Political Satire}},
  journal  = {International Journal of Public Opinion Research},
  volume   = {25},
  number   = {3},
  pages    = {323-343},
  year     = {2013},
  month    = {09},
  abstract = {{This study builds on research about political humor, press metacoverage, and intertextuality to examine the effects of news coverage about political satire on audience members. The analysis uses experimental data to test whether news coverage of Stephen Colbert’s Super PAC influenced knowledge and opinion regarding Citizens United, as well as political trust and internal political efficacy. It also tests whether such effects depended on previous exposure to The Colbert Report (Colbert’s satirical television show) and traditional news. Results indicate that exposure to news coverage of satire can influence knowledge, opinion, and political trust. Additionally, regular satire viewers may experience stronger effects on opinion, as well as increased internal efficacy, when consuming news coverage about issues previously highlighted in satire programming.}},
  issn     = {0954-2892},
  doi      = {10.1093/ijpor/edt015},
  url      = {https://doi.org/10.1093/ijpor/edt015},
  eprint   = {https://academic.oup.com/ijpor/article-pdf/25/3/323/2358632/edt015.pdf}
}

@article{NewsVerificationByExploitingConflictingSocialViewpoints_Jin,
  title        = {News Verification by Exploiting Conflicting Social Viewpoints in Microblogs},
  volume       = {30},
  url          = {https://ojs.aaai.org/index.php/AAAI/article/view/10382},
  doi          = {10.1609/aaai.v30i1.10382},
  abstractnote = { &lt;p&gt; Fake news spreading in social media severely jeopardizes the veracity of online content. Fortunately, with the interactive and open features of microblogs, skeptical and opposing voices against fake news always arise along with it. The conflicting information, ignored by existing studies, is crucial for news verification. In this paper, we take advantage of this &quot;wisdom of crowds&quot; information to improve news verification by mining conflicting viewpoints in microblogs. First, we discover conflicting viewpoints in news tweets with a topic model method. Based on identified tweets’ viewpoints, we then build a credibility propagation network of tweets linked with supporting or opposing relations. Finally, with iterative deduction, the credibility propagation on the network generates the final evaluation result for news. Experiments conducted on a real-world data set show that the news verification performance of our approach significantly outperforms those of the baseline approaches. &lt;/p&gt; },
  number       = {1},
  journal      = {Proceedings of the AAAI Conference on Artificial Intelligence},
  author       = {Jin, Zhiwei and Cao, Juan and Zhang, Yongdong and Luo, Jiebo},
  year         = {2016},
  month        = {Mar.}
}

@inproceedings{FakeNewsOrTruthUsingSatiricalCues_Rubin,
  title     = {Fake News or Truth? Using Satirical Cues to Detect Potentially Misleading News},
  author    = {Rubin, Victoria  and
               Conroy, Niall  and
               Chen, Yimin  and
               Cornwell, Sarah},
  booktitle = {Proceedings of the Second Workshop on Computational Approaches to Deception Detection},
  month     = jun,
  year      = {2016},
  address   = {San Diego, California},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/W16-0802},
  doi       = {10.18653/v1/W16-0802},
  pages     = {7--17}
}

@article{DeceptionDetectionForFakeNews3TypesOfFakeNews_Rubin,
  author   = {Rubin, Victoria L. and Chen, Yimin and Conroy, Nadia K.},
  title    = {Deception detection for news: Three types of fakes},
  journal  = {Proceedings of the Association for Information Science and Technology},
  volume   = {52},
  number   = {1},
  pages    = {1-4},
  keywords = {news verification, deception detection, fake news detection, credibility assessment, reputable sources, fabrication, hoax, satire, natural language processing, text analytics, predictive modeling, corpus construction},
  doi      = {https://doi.org/10.1002/pra2.2015.145052010083},
  url      = {https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/pra2.2015.145052010083},
  eprint   = {https://asistdl.onlinelibrary.wiley.com/doi/pdf/10.1002/pra2.2015.145052010083},
  abstract = {ABSTRACT A fake news detection system aims to assist users in detecting and filtering out varieties of potentially deceptive news. The prediction of the chances that a particular news item is intentionally deceptive is based on the analysis of previously seen truthful and deceptive news. A scarcity of deceptive news, available as corpora for predictive modeling, is a major stumbling block in this field of natural language processing (NLP) and deception detection. This paper discusses three types of fake news, each in contrast to genuine serious reporting, and weighs their pros and cons as a corpus for text analytics and predictive modeling. Filtering, vetting, and verifying online information continues to be essential in library and information science (LIS), as the lines between traditional news and online information are blurring.},
  year     = {2015}
}

@article{ConspiracyTheories_Sunstein,
  author  = {Sunstein, Cass R. and Vermeule, Adrian},
  title   = {Conspiracy Theories: Causes and Cures*},
  journal = {Journal of Political Philosophy},
  volume  = {17},
  number  = {2},
  pages   = {202-227},
  doi     = {https://doi.org/10.1111/j.1467-9760.2008.00325.x},
  url     = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9760.2008.00325.x},
  eprint  = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-9760.2008.00325.x},
  year    = {2009}
}

@article{Superstition_Lindeman,
  title    = {Superstitious, magical, and paranormal beliefs: An integrative model},
  journal  = {Journal of Research in Personality},
  volume   = {41},
  number   = {4},
  pages    = {731-744},
  year     = {2007},
  issn     = {0092-6566},
  doi      = {https://doi.org/10.1016/j.jrp.2006.06.009},
  url      = {https://www.sciencedirect.com/science/article/pii/S0092656606000869},
  author   = {Marjaana Lindeman and Kia Aarnio},
  keywords = {Superstition, Magical thinking, Paranormal beliefs, Intuitive thinking, Core knowledge},
  abstract = {Lack of conceptual clarity has hampered theory formation and research on superstitious, magical, and paranormal beliefs. This study offers a conceptual framework where these concepts are differentiated from other unfounded beliefs and defined identically as a confusion of core knowledge about physical, psychological, and biological phenomena. When testing this definition with questionnaire items (N=239), the results showed that superstitious individuals accepted more violations of core ontological distinctions than skeptics did and that ontological confusions discriminated believers from skeptics better than intuitive thinking, analytical thinking, or emotional instability. The findings justify the present conceptualization of superstitious, magical, and paranormal beliefs, and offer new theoretical propositions for the familiar everyday beliefs that are yet scientifically so poorly understood.}
}

@article{RumorsAndHealthCareReform_Berinsky,
  title    = {Rumors and Health Care Reform: Experiments in Political Misinformation},
  author   = {Berinsky, Adam J.},
  year     = {2017},
  journal  = {British Journal of Political Science},
  volume   = {47},
  number   = {2},
  pages    = {241-262},
  abstract = {This article explores belief in political rumors surrounding the health care reforms enacted by Congress in 2010. Refuting rumors with statements from unlikely sources can, under certain circumstances, increase the willingness of citizens to reject rumors regardless of their own political predilections. Such source credibility effects, while well known in the political persuasion literature, have not been applied to the study of rumor. Though source credibility appears to be an effective tool for debunking political rumors, risks remain. Drawing upon research from psychology on â€˜fluencyâ€™ â€“ the ease of information recall â€“ this article argues that rumors acquire power through familiarity. Attempting to quash rumors through direct refutation may facilitate their diffusion by increasing fluency. The empirical results find that merely repeating a rumor increases its power.},
  url      = {https://EconPapers.repec.org/RePEc:cup:bjposi:v:47:y:2017:i:02:p:241-262_00}
}

﻿@article{WhenCorrectionsFail_Nyhan,
  author   = {Nyhan, Brendan
              and Reifler, Jason},
  title    = {When Corrections Fail: The Persistence of Political Misperceptions},
  journal  = {Political Behavior},
  year     = {2010},
  month    = {Jun},
  day      = {01},
  volume   = {32},
  number   = {2},
  pages    = {303-330},
  abstract = {An extensive literature addresses citizen ignorance, but very little research focuses on misperceptions. Can these false or unsubstantiated beliefs about politics be corrected? Previous studies have not tested the efficacy of corrections in a realistic format. We conducted four experiments in which subjects read mock news articles that included either a misleading claim from a politician, or a misleading claim and a correction. Results indicate that corrections frequently fail to reduce misperceptions among the targeted ideological group. We also document several instances of a ``backfire effect'' in which corrections actually increase misperceptions among the group in question.},
  issn     = {1573-6687},
  doi      = {10.1007/s11109-010-9112-2},
  url      = {https://doi.org/10.1007/s11109-010-9112-2}
}

@article{ProspectTheory_Kahneman,
  title   = {Prospect theory: analysis of decision under risk},
  author  = {Daniel Kahneman and Amos Tversky},
  journal = {Econometrica},
  year    = {1979},
  volume  = {47},
  pages   = {263-291}
}

@article{AdvancesInProspectTheory_Kahneman,
  title   = {Advances in prospect theory: Cumulative representation of uncertainty},
  author  = {Amos Tversky and Daniel Kahneman},
  journal = {Journal of Risk and Uncertainty},
  year    = {1992},
  volume  = {5},
  pages   = {297-323}
}

@article{TheEffectOfPeopleRecommenderOnEchoChambers_Cinus,
  title        = {The Effect of People Recommenders on Echo Chambers and Polarization},
  volume       = {16},
  url          = {https://ojs.aaai.org/index.php/ICWSM/article/view/19275},
  abstractnote = {The effects of online social media on critical issues, such as polarization and misinformation, are under scrutiny due to the disruptive consequences that these phenomena can have on our societies. Among the algorithms routinely used by social media platforms, people-recommender systems are of special interest, as they directly contribute to the evolution of the social network structure, affecting the information and the opinions users are exposed to. In this paper, we propose a novel framework to assess the effect of people recommenders on the evolution of opinions. Our proposal is based on Monte Carlo simulations combining link recommendation and opinion-dynamics models. In order to control initial conditions, we define a random network model to generate graphs with opinions, with tunable amounts of modularity and homophily. Finally, we join these elements into a methodology able to study the causal relationship between the recommender system and the echo chamber effect. Our method can also assess if such relationships are statistically significant. We also show how such a framework can be used to measure, by means of simulations, the impact of different intervention strategies. Our thorough experimentation shows that people recommenders can in fact lead to a significant increase in echo chambers. However, this happens only if there is considerable initial homophily in the network. Also, we find that if the network already contains echo chambers, the effect of the recommendation algorithm is negligible. Such findings are robust to two very different opinion dynamics models, a bounded confidence model and an epistemological model.},
  number       = {1},
  journal      = {Proceedings of the International AAAI Conference on Web and Social Media},
  author       = {Cinus, Federico and Minici, Marco and Monti, Corrado and Bonchi, Francesco},
  year         = {2022},
  month        = {May},
  pages        = {90-101}
}

@inproceedings{TheRussianFirehoseOfFalsehood_Paul,
  title  = {The Russian "Firehose of Falsehood" Propaganda Model: Why It Might Work and Options to Counter It},
  author = {Christopher Paul and Miriam Matthews},
  year   = {2016}
}

@article{TheRiseOfSocialBots_Ferrara,
  author     = {Ferrara, Emilio and Varol, Onur and Davis, Clayton and Menczer, Filippo and Flammini, Alessandro},
  title      = {The Rise of Social Bots},
  year       = {2016},
  issue_date = {July 2016},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {59},
  number     = {7},
  issn       = {0001-0782},
  url        = {https://doi.org/10.1145/2818717},
  doi        = {10.1145/2818717},
  abstract   = {Today's social bots are sophisticated and sometimes menacing. Indeed, their presence can endanger online ecosystems as well as our society.},
  journal    = {Commun. ACM},
  month      = {jun},
  pages      = {96–104},
  numpages   = {9}
}

 @article{SocialBotsDistortThe2016USPresidentialElection_Bessi,
  title   = {Social Bots Distort the 2016 US Presidential Election Online Discussion},
  volume  = {21},
  number  = {11},
  journal = {First Monday},
  author  = {Bessi, Alessandro and Ferrara, Emilio},
  year    = {2016},
  month   = {Nov}
} Available at SSRN: https://ssrn.com/abstract=2982233

@inproceedings{AnyoneCanBecomeATroll_Cheng,
  author    = {Cheng, Justin and Bernstein, Michael and Danescu-Niculescu-Mizil, Cristian and Leskovec, Jure},
  title     = {Anyone Can Become a Troll: Causes of Trolling Behavior in Online Discussions},
  year      = {2017},
  isbn      = {9781450343350},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2998181.2998213},
  doi       = {10.1145/2998181.2998213},
  abstract  = {In online communities, antisocial behavior such as trolling disrupts constructive discussion. While prior work suggests that trolling behavior is confined to a vocal and antisocial minority, we demonstrate that ordinary people can engage in such behavior as well. We propose two primary trigger mechanisms: the individual's mood, and the surrounding context of a discussion (e.g., exposure to prior trolling behavior). Through an experiment simulating an online discussion, we find that both negative mood and seeing troll posts by others significantly increases the probability of a user trolling, and together double this probability. To support and extend these results, we study how these same mechanisms play out in the wild via a data-driven, longitudinal analysis of a large online news discussion community. This analysis exposes temporal mood effects, and explores long range patterns of repeated exposure to trolling. A predictive model of trolling behavior reveals that mood and discussion context together can explain trolling behavior better than an individual's history of trolling. These results combine to suggest that ordinary people can, under the right circumstances, behave like trolls.},
  booktitle = {Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing},
  pages     = {1217–1230},
  numpages  = {14},
  keywords  = {online communities, antisocial behavior, trolling},
  location  = {Portland, Oregon, USA},
  series    = {CSCW '17}
}