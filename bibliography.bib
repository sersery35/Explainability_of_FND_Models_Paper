@article{ThePsycologyOfFakeNews_Pennycook,
  title    = {The Psychology of Fake News},
  journal  = {Trends in Cognitive Sciences},
  volume   = {25},
  number   = {5},
  pages    = {388-402},
  year     = {2021},
  issn     = {1364-6613},
  doi      = {https://doi.org/10.1016/j.tics.2021.02.007},
  url      = {https://www.sciencedirect.com/science/article/pii/S1364661321000516},
  author   = {Gordon Pennycook and David G. Rand},
  keywords = {fake news, misinformation, social media, news media, motivated reasoning, dual process theory, crowdsourcing, attention, information sharing},
  abstract = {We synthesize a burgeoning literature investigating why people believe and share false or highly misleading news online. Contrary to a common narrative whereby politics drives susceptibility to fake news, people are ‘better’ at discerning truth from falsehood (despite greater overall belief) when evaluating politically concordant news. Instead, poor truth discernment is associated with lack of careful reasoning and relevant knowledge, and the use of heuristics such as familiarity. Furthermore, there is a substantial disconnect between what people believe and what they share on social media. This dissociation is largely driven by inattention, more so than by purposeful sharing of misinformation. Thus, interventions can successfully nudge social media users to focus more on accuracy. Crowdsourced veracity ratings can also be leveraged to improve social media ranking algorithms.}
}

@article{TheScienceOfFakeNews_Lazer,
  author   = {David M. J. Lazer  and Matthew A. Baum  and Yochai Benkler  and Adam J. Berinsky  and Kelly M. Greenhill  and Filippo Menczer  and Miriam J. Metzger  and Brendan Nyhan  and Gordon Pennycook  and David Rothschild  and Michael Schudson  and Steven A. Sloman  and Cass R. Sunstein  and Emily A. Thorson  and Duncan J. Watts  and Jonathan L. Zittrain },
  title    = {The science of fake news},
  journal  = {Science},
  volume   = {359},
  number   = {6380},
  pages    = {1094-1096},
  year     = {2018},
  doi      = {10.1126/science.aao2998},
  url      = {https://www.science.org/doi/abs/10.1126/science.aao2998},
  eprint   = {https://www.science.org/doi/pdf/10.1126/science.aao2998},
  abstract = {Addressing fake news requires a multidisciplinary effort The rise of fake news highlights the erosion of long-standing institutional bulwarks against misinformation in the internet age. Concern over the problem is global. However, much remains unknown regarding the vulnerabilities of individuals, institutions, and society to manipulations by malicious actors. A new system of safeguards is needed. Below, we discuss extant social and computer science research regarding belief in fake news and the mechanisms by which it spreads. Fake news has a long history, but we focus on unanswered scientific questions raised by the proliferation of its most recent, politically oriented incarnation. Beyond selected references in the text, suggested further reading can be found in the supplementary materials.}
}

@article{FakeNewsDetectionOnSocialMediaADataMiningPerspective_Shu,
  author     = {Shu, Kai and Sliva, Amy and Wang, Suhang and Tang, Jiliang and Liu, Huan},
  title      = {Fake News Detection on Social Media: A Data Mining Perspective},
  year       = {2017},
  issue_date = {June 2017},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {19},
  number     = {1},
  issn       = {1931-0145},
  url        = {https://doi.org/10.1145/3137597.3137600},
  doi        = {10.1145/3137597.3137600},
  abstract   = {Social media for news consumption is a double-edged sword. On the one hand, its low cost, easy access, and rapid dissemination of information lead people to seek out and consume news from social media. On the other hand, it enables the wide spread of fake news", i.e., low quality news with intentionally false information. The extensive spread of fake news has the potential for extremely negative impacts on individuals and society. Therefore, fake news detection on social media has recently become an emerging research that is attracting tremendous attention. Fake news detection on social media presents unique characteristics and challenges that make existing detection algorithms from traditional news media ine ective or not applicable. First, fake news is intentionally written to mislead readers to believe false information, which makes it difficult and nontrivial to detect based on news content; therefore, we need to include auxiliary information, such as user social engagements on social media, to help make a determination. Second, exploiting this auxiliary information is challenging in and of itself as users' social engagements with fake news produce data that is big, incomplete, unstructured, and noisy. Because the issue of fake news detection on social media is both challenging and relevant, we conducted this survey to further facilitate research on the problem. In this survey, we present a comprehensive review of detecting fake news on social media, including fake news characterizations on psychology and social theories, existing algorithms from a data mining perspective, evaluation metrics and representative datasets. We also discuss related research areas, open problems, and future research directions for fake news detection on social media.},
  journal    = {SIGKDD Explor. Newsl.},
  month      = {sep},
  pages      = {22–36},
  numpages   = {15}
}

@article{FakeNewsAndThePublic_McKernon,
  title    = {Fake news and the public. How the press combats rumor, the market rigger, and the propagandist},
  issn     = {0017-789X},
  url      = {https://harpers.org/archive/1925/10/fake-news-and-the-public/},
  urldate  = {2018-05-04},
  journal  = {Harper's Magazine},
  author   = {McKernon, Edward},
  month    = oct,
  year     = {1925},
  keywords = {20th century, Journalism, Journalistic ethics, News agencies, Press and propaganda, Rumor, Stock exchanges and current events, United States}
}

 @article{ReutersInstituteDigitalNewsReport,
  title     = {Reuters Institute Digital News Report 2022},
  url       = {https://reutersinstitute.politics.ox.ac.uk/sites/default/files/2022-06/Digital_News-Report_2022.pdf},
  journal   = {Digital News Report 2022},
  publisher = {Reuters Institute for the Study of Journalism},
  author    = {Newman, Nic and Fletcher, Richard and Robertson, Craig T. and Eddy, Kirsten and Nielsen, Rasmus Kleis},
  year      = {2022},
  month     = {06}
}

@inbook{USPresidentialElection2016,
  title     = {United States Presidential Election of 2016},
  booktitle = {Encyclopedia Britannica},
  author    = {Beckwith, David C},
  abstract  = {United States Presidential Election of 2016, American
               presidential election held on November 8, 2016, in which
               Republican Donald Trump lost the popular vote to Democrat
               Hillary Clinton by more than 2.8 million votes but won 30 states
               and the decisive electoral college with 304 electoral votes to
               Clinton's 227 and thus became the 45th president of the United
               States. The tumultuous, abrasive 2016 campaign defied
               established political norms. Clinton's campaign featured
               superior organization and fund-raising---and almost every
               election-eve poll pointed to a comfortable victory for her---but
               Trump's anti-Washington appeal to white working-class voters
               outside major cities in pivotal manufacturing states},
  month     = {10},
  year      = {2021}
}

@misc{FakeNewsNet_Shu,
  doi       = {10.48550/ARXIV.1809.01286},
  url       = {https://arxiv.org/abs/1809.01286},
  author    = {Shu, Kai and Mahudeswaran, Deepak and Wang, Suhang and Lee, Dongwon and Liu, Huan},
  keywords  = {Social and Information Networks (cs.SI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {FakeNewsNet: A Data Repository with News Content, Social Context and Spatialtemporal Information for Studying Fake News on Social Media},
  publisher = {arXiv},
  year      = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{LiarLiarPantsOnFire_Wang,
  author     = {William Yang Wang},
  title      = {"Liar, Liar Pants on Fire": {A} New Benchmark Dataset for Fake News
                Detection},
  journal    = {CoRR},
  volume     = {abs/1705.00648},
  year       = {2017},
  url        = {http://arxiv.org/abs/1705.00648},
  eprinttype = {arXiv},
  eprint     = {1705.00648},
  timestamp  = {Mon, 13 Aug 2018 16:48:58 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/Wang17j.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{FakeNewsDetectionUsingGeometricDeepLearning_Monti,
  author     = {Federico Monti and
                Fabrizio Frasca and
                Davide Eynard and
                Damon Mannion and
                Michael M. Bronstein},
  title      = {Fake News Detection on Social Media using Geometric Deep Learning},
  journal    = {CoRR},
  volume     = {abs/1902.06673},
  year       = {2019},
  url        = {http://arxiv.org/abs/1902.06673},
  eprinttype = {arXiv},
  eprint     = {1902.06673},
  timestamp  = {Tue, 21 May 2019 18:03:39 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1902-06673.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}


@article{UPFD_Dataset_Shu,
  author     = {Yingtong Dou and
                Kai Shu and
                Congying Xia and
                Philip S. Yu and
                Lichao Sun},
  title      = {User Preference-aware Fake News Detection},
  journal    = {CoRR},
  volume     = {abs/2104.12259},
  year       = {2021},
  url        = {https://arxiv.org/abs/2104.12259},
  eprinttype = {arXiv},
  eprint     = {2104.12259},
  timestamp  = {Mon, 03 May 2021 17:38:30 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2104-12259.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@misc{GraphAttentionNetworks_Velickovic,
  doi       = {10.48550/ARXIV.1710.10903},
  url       = {https://arxiv.org/abs/1710.10903},
  author    = {Veličković, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Liò, Pietro and Bengio, Yoshua},
  keywords  = {Machine Learning (stat.ML), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), Social and Information Networks (cs.SI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Graph Attention Networks},
  publisher = {arXiv},
  year      = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{FakeReddit_Nakamura,
  title     = {{F}akeddit: A New Multimodal Benchmark Dataset for Fine-grained Fake News Detection},
  author    = {Nakamura, Kai  and
               Levy, Sharon  and
               Wang, William Yang},
  booktitle = {Proceedings of the 12th Language Resources and Evaluation Conference},
  month     = may,
  year      = {2020},
  address   = {Marseille, France},
  publisher = {European Language Resources Association},
  url       = {https://aclanthology.org/2020.lrec-1.755},
  pages     = {6149--6157},
  abstract  = {Fake news has altered society in negative ways in politics and culture. It has adversely affected both online social network systems as well as offline communities and conversations. Using automatic machine learning classification models is an efficient way to combat the widespread dissemination of fake news. However, a lack of effective, comprehensive datasets has been a problem for fake news research and detection model development. Prior fake news datasets do not provide multimodal text and image data, metadata, comment data, and fine-grained fake news categorization at the scale and breadth of our dataset. We present Fakeddit, a novel multimodal dataset consisting of over 1 million samples from multiple categories of fake news. After being processed through several stages of review, the samples are labeled according to 2-way, 3-way, and 6-way classification categories through distant supervision. We construct hybrid text+image models and perform extensive experiments for multiple variations of classification, demonstrating the importance of the novel aspect of multimodality and fine-grained classification unique to Fakeddit.},
  language  = {English},
  isbn      = {979-10-95546-34-4}
}

@article{SomeLikeItHoaxDataset_Tacchini,
  doi       = {10.48550/ARXIV.1704.07506},
  url       = {https://arxiv.org/abs/1704.07506},
  author    = {Tacchini, Eugenio and Ballarin, Gabriele and Della Vedova, Marco L. and Moret, Stefano and de Alfaro, Luca},
  keywords  = {Machine Learning (cs.LG), Human-Computer Interaction (cs.HC), Social and Information Networks (cs.SI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Some Like it Hoax: Automated Fake News Detection in Social Networks},
  publisher = {arXiv},
  year      = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{BuzzfaceDataset_Santia,
  title        = {BuzzFace: A News Veracity Dataset with Facebook User Commentary and Egos},
  volume       = {12},
  url          = {https://ojs.aaai.org/index.php/ICWSM/article/view/14985},
  abstractnote = { &lt;p&gt; Veracity assessment of news and social bot detection have become two of the most pressing issues for social media platforms, yet current gold-standard data are limited. This paper presents a leap forward in the development of a sizeable and feature rich gold-standard dataset. The dataset was built by using a collection of news items posted to Facebook by nine news outlets during September 2016, which were annotated for veracity by BuzzFeed. These articles were refined beyond binary annotation to the four categories: mostly true, mostly false, mixture of true and false, and no factual content. Our contribution integrates data on Facebook comments and reactions publicly available on the platform’s Graph API, and provides tailored tools for accessing news article web content. The features of the accessed articles include body text, images, links, Facebook plugin comments, Disqus plugin comments, and embedded tweets. Embedded tweets provide a potent possible avenue for expansion across social media platforms. Upon development, this utility yielded over 1.6 million text items, making it over 400 times larger than the current gold-standard. The resulting dataset—BuzzFace—is presently the most extensive created, and allows for more robust machine learning applications to news veracity assessment and social bot detection than ever before. &lt;/p&gt; },
  number       = {1},
  journal      = {Proceedings of the International AAAI Conference on Web and Social Media},
  author       = {Santia, Giovanni and Williams, Jake},
  year         = {2018},
  month        = {Jun.},
  pages        = {531-540}
}

@misc{NewsConsumptionAcrossSocialMedia_pewresearch,
  title     = {News consumption across social media in 2021},
  url       = {https://www.pewresearch.org/journalism/2021/09/20/news-consumption-across-social-media-in-2021/},
  journal   = {Pew Research Center's Journalism Project},
  publisher = {Pew Research Center},
  author    = {Walker, Mason and Matsa, Katerina Eva},
  year      = {2021},
  month     = {Sep}
}

@article{GetBackYouDontKnowMeLikeThat_Hannak,
  title        = {Get Back! You Don’t Know Me Like That: The Social Mediation of Fact Checking Interventions in Twitter Conversations},
  volume       = {8},
  url          = {https://ojs.aaai.org/index.php/ICWSM/article/view/14555},
  abstractnote = { &lt;p&gt; &lt;span&gt;The prevalence of misinformation within social media and online communities can undermine public security and distract attention from important issues. Fact-checking interventions, in which users cite fact-checking websites such as Snopes.com and FactCheck.org, are a strategy users can employ to refute false claims made by their peers. While laboratory research suggests such interventions are not effective in persuading people to abandon false ideas, little work considers how such interventions are actually deployed in real-world conversations. Using approximately 1,600 interventions observed on Twitter between 2012 and 2013, we examine the contexts and consequences of fact-checking interventions.W&lt;/span&gt;&lt;span&gt;e focus in particular on the social relationship between the individual who issues the fact-check and the individual whose facts are challenged. Our results indicate that though fact-checking interventions are most commonly issued by strangers, they are more likely to draw user attention and responses when they come from friends. Finally, we discuss implications for designing more effective interventions against misinformation.&lt;/span&gt; &lt;/p&gt; },
  number       = {1},
  journal      = {Proceedings of the International AAAI Conference on Web and Social Media},
  author       = {Hannak, Aniko and Margolin, Drew and Keegan, Brian and Weber, Ingmar},
  year         = {2014},
  month        = {May},
  pages        = {187-196}
}

@misc{GraphNeuralNetworksWithContinualLearningFakeNewsDetection_Han,
  doi       = {10.48550/ARXIV.2007.03316},
  url       = {https://arxiv.org/abs/2007.03316},
  author    = {Han, Yi and Karunasekera, Shanika and Leckie, Christopher},
  keywords  = {Social and Information Networks (cs.SI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Graph Neural Networks with Continual Learning for Fake News Detection from Social Media},
  publisher = {arXiv},
  year      = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{RumorDetectionBidirectionalGraphConvolutionalNetworks_Bian,
  doi       = {10.48550/ARXIV.2001.06362},
  url       = {https://arxiv.org/abs/2001.06362},
  author    = {Bian, Tian and Xiao, Xi and Xu, Tingyang and Zhao, Peilin and Huang, Wenbing and Rong, Yu and Huang, Junzhou},
  keywords  = {Social and Information Networks (cs.SI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Rumor Detection on Social Media with Bi-Directional Graph Convolutional Networks},
  publisher = {arXiv},
  year      = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{SAFEFND_Zhou,
  doi       = {10.48550/ARXIV.2003.04981},
  url       = {https://arxiv.org/abs/2003.04981},
  author    = {Zhou, Xinyi and Wu, Jindi and Zafarani, Reza},
  keywords  = {Computation and Language (cs.CL), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {SAFE: Similarity-Aware Multi-Modal Fake News Detection},
  publisher = {arXiv},
  year      = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{XAIConceptsTaxonomies_Arrieta,
  title    = {Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI},
  journal  = {Information Fusion},
  volume   = {58},
  pages    = {82-115},
  year     = {2020},
  issn     = {1566-2535},
  doi      = {https://doi.org/10.1016/j.inffus.2019.12.012},
  url      = {https://www.sciencedirect.com/science/article/pii/S1566253519308103},
  author   = {Alejandro {Barredo Arrieta} and Natalia Díaz-Rodríguez and Javier {Del Ser} and Adrien Bennetot and Siham Tabik and Alberto Barbado and Salvador Garcia and Sergio Gil-Lopez and Daniel Molina and Richard Benjamins and Raja Chatila and Francisco Herrera},
  keywords = {Explainable Artificial Intelligence, Machine Learning, Deep Learning, Data Fusion, Interpretability, Comprehensibility, Transparency, Privacy, Fairness, Accountability, Responsible Artificial Intelligence},
  abstract = {In the last few years, Artificial Intelligence (AI) has achieved a notable momentum that, if harnessed appropriately, may deliver the best of expectations over many application sectors across the field. For this to occur shortly in Machine Learning, the entire community stands in front of the barrier of explainability, an inherent problem of the latest techniques brought by sub-symbolism (e.g. ensembles or Deep Neural Networks) that were not present in the last hype of AI (namely, expert systems and rule based models). Paradigms underlying this problem fall within the so-called eXplainable AI (XAI) field, which is widely acknowledged as a crucial feature for the practical deployment of AI models. The overview presented in this article examines the existing literature and contributions already done in the field of XAI, including a prospect toward what is yet to be reached. For this purpose we summarize previous efforts made to define explainability in Machine Learning, establishing a novel definition of explainable Machine Learning that covers such prior conceptual propositions with a major focus on the audience for which the explainability is sought. Departing from this definition, we propose and discuss about a taxonomy of recent contributions related to the explainability of different Machine Learning models, including those aimed at explaining Deep Learning methods for which a second dedicated taxonomy is built and examined in detail. This critical literature analysis serves as the motivating background for a series of challenges faced by XAI, such as the interesting crossroads of data fusion and explainability. Our prospects lead toward the concept of Responsible Artificial Intelligence, namely, a methodology for the large-scale implementation of AI methods in real organizations with fairness, model explainability and accountability at its core. Our ultimate goal is to provide newcomers to the field of XAI with a thorough taxonomy that can serve as reference material in order to stimulate future research advances, but also to encourage experts and professionals from other disciplines to embrace the benefits of AI in their activity sectors, without any prior bias for its lack of interpretability.}
}

@book{InterpretableMachineLearning_Molnar,
  title    = {Interpretable Machine Learning},
  author   = {Christoph Molnar},
  year     = {2022},
  subtitle = {A Guide for Making Black Box Models Explainable},
  edition  = {2},
  url      = {https://christophm.github.io/interpretable-ml-book}
}

@misc{TowardsARigorousScienceML_Velez,
  doi       = {10.48550/ARXIV.1702.08608},
  url       = {https://arxiv.org/abs/1702.08608},
  author    = {Doshi-Velez, Finale and Kim, Been},
  keywords  = {Machine Learning (stat.ML), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Towards A Rigorous Science of Interpretable Machine Learning},
  publisher = {arXiv},
  year      = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{CanWeOpenTheBlackBoxOfAI_Castelvecchi,
  author  = {Castelvecchi, Davide},
  year    = {2016},
  month   = {10},
  pages   = {20-23},
  title   = {Can we open the black box of AI?},
  volume  = {538},
  journal = {Nature},
  doi     = {10.1038/538020a}
}

@article{XAI_Gunning,
  title        = {DARPA’s Explainable Artificial Intelligence (XAI) Program},
  volume       = {40},
  url          = {https://ojs.aaai.org/index.php/aimagazine/article/view/2850},
  doi          = {10.1609/aimag.v40i2.2850},
  abstractnote = {&lt;p&gt;Dramatic success in machine learning has led to a new wave of AI applications (for example, transportation, security, medicine, finance, defense) that offer tremendous benefits but cannot explain their decisions and actions to human users. DARPA’s explainable artificial intelligence (XAI) program endeavors to create AI systems whose learned models and decisions can be understood and appropriately trusted by end users. Realizing this goal requires methods for learning more explainable models, designing effective explanation interfaces, and understanding the psychologic requirements for effective explanations. The XAI developer teams are addressing the first two challenges by creating ML techniques and developing principles, strategies, and human-computer interaction techniques for generating effective explanations. Another XAI team is addressing the third challenge by summarizing, extending, and applying psychologic theories of explanation to help the XAI evaluator define a suitable evaluation framework, which the developer teams will use to test their systems. The XAI teams completed the first of this 4-year program in May 2018. In a series of ongoing evaluations, the developer teams are assessing how well their XAM systems’ explanations improve user understanding, user trust, and user task performance.&lt;/p&gt;},
  number       = {2},
  journal      = {AI Magazine},
  author       = {Gunning, David and Aha, David},
  year         = {2019},
  month        = {Jun.},
  pages        = {44-58}
}

@misc{TheMythosOfModelInterpretability_Lipton,
  doi       = {10.48550/ARXIV.1606.03490},
  url       = {https://arxiv.org/abs/1606.03490},
  author    = {Lipton, Zachary C.},
  keywords  = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Computer Vision and Pattern Recognition (cs.CV), Neural and Evolutionary Computing (cs.NE), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {The Mythos of Model Interpretability},
  publisher = {arXiv},
  year      = {2016},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{SlaveToTheAlgorithm_EdwardsVeale,
  title   = {Slave to the Algorithm? Why a 'Right to an Explanation' Is Probably Not the Remedy You Are Looking For},
  author  = {Lilian Edwards and Michael Veale},
  journal = {Duke law and technology review},
  year    = {2017},
  volume  = {16},
  pages   = {18-84}
}

@article{HierarchicalPropagationNetworksForFND_Shu,
  title        = {Hierarchical Propagation Networks for Fake News Detection: Investigation and Exploitation},
  volume       = {14},
  url          = {https://ojs.aaai.org/index.php/ICWSM/article/view/7329},
  abstractnote = {&lt;p&gt;Consuming news from social media is becoming increasingly popular. However, social media also enables the wide dissemination of &lt;em&gt;fake news&lt;/em&gt;. Because of the detrimental effects of fake news, fake news detection has attracted increasing attention. However, the performance of detecting fake news only from news content is generally limited as fake news pieces are written to mimic true news. In the real world, news pieces spread through &lt;em&gt;propagation networks&lt;/em&gt; on social media. The news propagation networks usually involve multi-levels. In this paper, we study the challenging problem of &lt;em&gt;investigating&lt;/em&gt; and &lt;em&gt;exploiting&lt;/em&gt; news hierarchical propagation network on social media for fake news detection.&lt;/p&gt;&lt;p&gt;In an attempt to understand the correlations between news propagation networks and fake news, first, we build hierarchical propagation networks for fake news and true news pieces; second, we perform a comparative analysis of the propagation network features from structural, temporal, and linguistic perspectives between fake and real news, which demonstrates the potential of utilizing these features to detect fake news; third, we show the effectiveness of these propagation network features for fake news detection. We further validate the effectiveness of these features from feature importance analysis. We conduct extensive experiments on real-world datasets and demonstrate the proposed features can significantly outperform state-of-the-art fake news detection methods by at least 1.7% with an average F1&gt;0.84. Altogether, this work presents a data-driven view of hierarchical propagation network and fake news and paves the way towards a healthier online news ecosystem.&lt;/p&gt;},
  number       = {1},
  journal      = {Proceedings of the International AAAI Conference on Web and Social Media},
  author       = {Shu, Kai and Mahudeswaran, Deepak and Wang, Suhang and Liu, Huan},
  year         = {2020},
  month        = {May},
  pages        = {626-637}
}

 @inbook{HistorysGreatestLies_Weir,
  place     = {Beverly, Massachusetts},
  booktitle = {History's greatest lies: The startling truths behind world events our history books got wrong},
  publisher = {Fair Winds Press},
  author    = {Weir, William},
  year      = {2009},
  pages     = {28–41}
}

 @misc{MarketQuaversAfterFakeAPTweet_ElBoghdady,
  title     = {Market quavers after fake AP tweet says Obama was hurt in White House explosions},
  url       = {https://www.washingtonpost.com/business/economy/market-quavers-after-fake-ap-tweet-says-obama-was-hurt-in-white-house-explosions/2013/04/23/d96d2dc6-ac4d-11e2-a8b9-2a63d75b5459_story.html},
  journal   = {The Washington Post},
  publisher = {WP Company},
  author    = {ElBoghdady, Dina},
  year      = {2013},
  month     = {Apr}
}

 @misc{Pizzagate_Fisher,
  title     = {Pizzagate: From rumor, to hashtag, to gunfire in D.C.},
  url       = {https://www.washingtonpost.com/local/pizzagate-from-rumor-to-hashtag-to-gunfire-in-dc/2016/12/06/4c7def50-bbd4-11e6-94ac-3d324840106c_story.html},
  journal   = {The Washington Post},
  publisher = {WP Company},
  author    = {Fisher, Marc and Cox, John Woodrow and Hermann, Peter},
  year      = {2016},
  month     = {Dec}
} 

 @misc{StatistaUsageOfSocialMedia_Watson,
  title   = {Usage of social media as a news source worldwide 2022},
  url     = {https://www.statista.com/statistics/718019/social-media-news-source/},
  journal = {Statista},
  author  = {Watson, Amy},
  year    = {2022},
  month   = {Aug}
}

@article{SocialMediaAndFakeNewsIn2016Election_Allcott,
  author  = {Allcott, Hunt and Gentzkow, Matthew},
  title   = {Social Media and Fake News in the 2016 Election},
  journal = {Journal of Economic Perspectives},
  volume  = {31},
  number  = {2},
  year    = {2017},
  month   = {May},
  pages   = {211-36},
  doi     = {10.1257/jep.31.2.211},
  url     = {https://www.aeaweb.org/articles?id=10.1257/jep.31.2.211}
}

@inbook{TheGreatMoonHoax_Foster,
  author    = {Foster, Vincent S.},
  title     = {The Great Moon Hoax},
  booktitle = {Modern Mysteries of the Moon: What We Still Don't Know About Our Lunar Companion},
  year      = {2016},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {11--44},
  abstract  = {Back in 1835 there was a Moon hoax that thousands of people fell for, despite the tale being complete fiction. A series of articles were published in a newspaper reporting incredible new astronomical observations of the Moon supposedly made by astronomer Sir John Herschel during an observing run at the Cape of Good Hope. Detailed descriptions of winged beings, plants, animals and a sapphire temple increased sales and subscriptions to the fledgling newspaper. The chapter offers a selection of these articles as they were published in the New York Sun.},
  isbn      = {978-3-319-22120-5},
  doi       = {10.1007/978-3-319-22120-5_2},
  url       = {https://doi.org/10.1007/978-3-319-22120-5_2}
}

 @misc{Buzzfeed_FakeNewsOutperformRealNews_Silverman,
  title     = {This analysis shows how viral fake election news stories outperformed Real News on facebook},
  url       = {https://www.buzzfeednews.com/article/craigsilverman/viral-fake-election-news-outperformed-real-news-on-facebook},
  journal   = {BuzzFeed News},
  publisher = {BuzzFeed News},
  author    = {Silverman, Craig},
  year      = {2016},
  month     = {Nov}
} 

 @misc{TrumpWonBecauseOfFacebook_Read,
  title     = {Donald Trump won because of Facebook},
  url       = {https://nymag.com/intelligencer/2016/11/donald-trump-won-because-of-facebook.html},
  journal   = {Intelligencer},
  publisher = {Intelligencer},
  author    = {Read, Max},
  year      = {2016},
  month     = {Nov}
}

@article{ConfirmationBias_Nickerson,
  author   = {Raymond S. Nickerson},
  title    = {Confirmation Bias: A Ubiquitous Phenomenon in Many Guises},
  journal  = {Review of General Psychology},
  volume   = {2},
  number   = {2},
  pages    = {175-220},
  year     = {1998},
  doi      = {10.1037/1089-2680.2.2.175},
  url      = { 
              https://doi.org/10.1037/1089-2680.2.2.175
              
              },
  eprint   = { 
              https://doi.org/10.1037/1089-2680.2.2.175
              
              },
  abstract = { Confirmation bias, as the term is typically used in the psychological literature, connotes the seeking or interpreting of evidence in ways that are partial to existing beliefs, expectations, or a hypothesis in hand. The author reviews evidence of such a bias in a variety of guises and gives examples of its operation in several practical contexts. Possible explanations are considered, and the question of its utility or disutility is discussed. }
}

@inproceedings{NaiveRealism_Reed,
  title  = {Naive Realism in Everyday Life: Implications for Social Conflict and Misunderstanding},
  author = {Edward S. Reed and Elliot Turiel and Terrance Brown},
  year   = {2013}
}

@article{SocialIdentityTheory_Ashforth,
  issn      = {03637425},
  url       = {http://www.jstor.org/stable/258189},
  abstract  = {It is argued that (a) social identification is a perception of oneness with a group of persons; (b) social identification stems from the categorization of individuals, the distinctiveness and prestige of the group, the salience of outgroups, and the factors that traditionally are associated with group formation; and (c) social identification leads to activities that are congruent with the identity, support for institutions that embody the identity, stereotypical perceptions of self and others, and outcomes that traditionally are associated with group formation, and it reinforces the antecedents of identification. This perspective is applied to organizational socialization, role conflict, and intergroup relations.},
  author    = {Blake E. Ashforth and Fred Mael},
  journal   = {The Academy of Management Review},
  number    = {1},
  pages     = {20--39},
  publisher = {Academy of Management},
  title     = {Social Identity Theory and the Organization},
  urldate   = {2022-09-12},
  volume    = {14},
  year      = {1989}
}

@article{NormativeSocialInfluence_Asch,
  journal = {Groups, leadership, and men},
  title   = {Effects of group pressure upon the modification and distortion of
             judgments.},
  author  = {Asch, S E and Guetzkow, H},
  pages   = {222--236},
  year    = {1951}
}

 @book{TheFilterBubble_Pariser,
  place     = {London},
  title     = {The filter bubble: What the internet is hiding from you},
  publisher = {Penguin UK},
  author    = {Pariser, Eli},
  year      = {2011}
}

 @book{EchoChambers_Sunstein,
  place     = {Princeton, NJ},
  title     = {Echo chambers: Bush v. Gore, impeachment, and beyond},
  publisher = {Princeton University Press},
  author    = {Sunstein, Cass R.},
  year      = {2001}
} 

@article{TheSpreadingOfMisinformationOnline_DelVicario,
  author   = {Michela Del Vicario  and Alessandro Bessi  and Fabiana Zollo  and Fabio Petroni  and Antonio Scala  and Guido Caldarelli  and H. Eugene Stanley  and Walter Quattrociocchi },
  title    = {The spreading of misinformation online},
  journal  = {Proceedings of the National Academy of Sciences},
  volume   = {113},
  number   = {3},
  pages    = {554-559},
  year     = {2016},
  doi      = {10.1073/pnas.1517441113},
  url      = {https://www.pnas.org/doi/abs/10.1073/pnas.1517441113},
  eprint   = {https://www.pnas.org/doi/pdf/10.1073/pnas.1517441113},
  abstract = {The wide availability of user-provided content in online social media facilitates the aggregation of people around common interests, worldviews, and narratives. However, the World Wide Web (WWW) also allows for the rapid dissemination of unsubstantiated rumors and conspiracy theories that often elicit rapid, large, but naive social responses such as the recent case of Jade Helm 15––where a simple military exercise turned out to be perceived as the beginning of a new civil war in the United States. In this work, we address the determinants governing misinformation spreading through a thorough quantitative analysis. In particular, we focus on how Facebook users consume information related to two distinct narratives: scientific and conspiracy news. We find that, although consumers of scientific and conspiracy stories present similar consumption patterns with respect to content, cascade dynamics differ. Selective exposure to content is the primary driver of content diffusion and generates the formation of homogeneous clusters, i.e., “echo chambers.” Indeed, homogeneity appears to be the primary driver for the diffusion of contents and each echo chamber has its own cascade dynamics. Finally, we introduce a data-driven percolation model mimicking rumor spreading and we show that homogeneity and polarization are the main determinants for predicting cascades’ size.}
}

@article{AutomaticDeceptionDetection_Conroy,
  author   = {Conroy, Nadia K. and Rubin, Victoria L. and Chen, Yimin},
  title    = {Automatic deception detection: Methods for finding fake news},
  journal  = {Proceedings of the Association for Information Science and Technology},
  volume   = {52},
  number   = {1},
  pages    = {1-4},
  keywords = {Deception detection, fake news detection, veracity assessment, news verification, methods, automation, SVM, knowledge networks, predictive modelling, fraud},
  doi      = {https://doi.org/10.1002/pra2.2015.145052010082},
  url      = {https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/pra2.2015.145052010082},
  eprint   = {https://asistdl.onlinelibrary.wiley.com/doi/pdf/10.1002/pra2.2015.145052010082},
  abstract = {ABSTRACT This research surveys the current state-of-the-art technologies that are instrumental in the adoption and development of fake news detection. “Fake news detection” is defined as the task of categorizing news along a continuum of veracity, with an associated measure of certainty. Veracity is compromised by the occurrence of intentional deceptions. The nature of online news publication has changed, such that traditional fact checking and vetting from potential deception is impossible against the flood arising from content generators, as well as various formats and genres. The paper provides a typology of several varieties of veracity assessment methods emerging from two major categories – linguistic cue approaches (with machine learning), and network analysis approaches. We see promise in an innovative hybrid approach that combines linguistic cue and machine learning, with network-based behavioral data. Although designing a fake news detector is not a straightforward problem, we propose operational guidelines for a feasible fake news detecting system.},
  year     = {2015}
}

@article{TheFakeNewsSpreadingPlague_Mustafaraj,
  author     = {Eni Mustafaraj and
                Panagiotis Takis Metaxas},
  title      = {The Fake News Spreading Plague: Was it Preventable?},
  journal    = {CoRR},
  volume     = {abs/1703.06988},
  year       = {2017},
  url        = {http://arxiv.org/abs/1703.06988},
  eprinttype = {arXiv},
  eprint     = {1703.06988},
  timestamp  = {Mon, 13 Aug 2018 16:48:43 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/MustafarajM17.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{WhenFakeNewsBecomesReal_Balmas,
  author   = {Meital Balmas},
  title    = {When Fake News Becomes Real: Combined Exposure to Multiple News Sources and Political Attitudes of Inefficacy, Alienation, and Cynicism},
  journal  = {Communication Research},
  volume   = {41},
  number   = {3},
  pages    = {430-454},
  year     = {2014},
  doi      = {10.1177/0093650212453600},
  url      = { 
              https://doi.org/10.1177/0093650212453600
              
              },
  eprint   = { 
              https://doi.org/10.1177/0093650212453600
              
              },
  abstract = { This research assesses possible associations between viewing fake news (i.e., political satire) and attitudes of inefficacy, alienation, and cynicism toward political candidates. Using survey data collected during the 2006 Israeli election campaign, the study provides evidence for an indirect positive effect of fake news viewing in fostering the feelings of inefficacy, alienation, and cynicism, through the mediator variable of perceived realism of fake news. Within this process, hard news viewing serves as a moderator of the association between viewing fake news and their perceived realism. It was also demonstrated that perceived realism of fake news is stronger among individuals with high exposure to fake news and low exposure to hard news than among those with high exposure to both fake and hard news. Overall, this study contributes to the scientific knowledge regarding the influence of the interaction between various types of media use on political effects. }
}

@article{TheImpactOfRealNewsAboutFakeNews_Brewer,
  author   = {Brewer, Paul R. and Young, Dannagal Goldthwaite and Morreale, Michelle},
  title    = {{The Impact of Real News about “Fake News”: Intertextual Processes and Political Satire}},
  journal  = {International Journal of Public Opinion Research},
  volume   = {25},
  number   = {3},
  pages    = {323-343},
  year     = {2013},
  month    = {09},
  abstract = {{This study builds on research about political humor, press metacoverage, and intertextuality to examine the effects of news coverage about political satire on audience members. The analysis uses experimental data to test whether news coverage of Stephen Colbert’s Super PAC influenced knowledge and opinion regarding Citizens United, as well as political trust and internal political efficacy. It also tests whether such effects depended on previous exposure to The Colbert Report (Colbert’s satirical television show) and traditional news. Results indicate that exposure to news coverage of satire can influence knowledge, opinion, and political trust. Additionally, regular satire viewers may experience stronger effects on opinion, as well as increased internal efficacy, when consuming news coverage about issues previously highlighted in satire programming.}},
  issn     = {0954-2892},
  doi      = {10.1093/ijpor/edt015},
  url      = {https://doi.org/10.1093/ijpor/edt015},
  eprint   = {https://academic.oup.com/ijpor/article-pdf/25/3/323/2358632/edt015.pdf}
}

@article{NewsVerificationByExploitingConflictingSocialViewpoints_Jin,
  title        = {News Verification by Exploiting Conflicting Social Viewpoints in Microblogs},
  volume       = {30},
  url          = {https://ojs.aaai.org/index.php/AAAI/article/view/10382},
  doi          = {10.1609/aaai.v30i1.10382},
  abstractnote = { &lt;p&gt; Fake news spreading in social media severely jeopardizes the veracity of online content. Fortunately, with the interactive and open features of microblogs, skeptical and opposing voices against fake news always arise along with it. The conflicting information, ignored by existing studies, is crucial for news verification. In this paper, we take advantage of this &quot;wisdom of crowds&quot; information to improve news verification by mining conflicting viewpoints in microblogs. First, we discover conflicting viewpoints in news tweets with a topic model method. Based on identified tweets’ viewpoints, we then build a credibility propagation network of tweets linked with supporting or opposing relations. Finally, with iterative deduction, the credibility propagation on the network generates the final evaluation result for news. Experiments conducted on a real-world data set show that the news verification performance of our approach significantly outperforms those of the baseline approaches. &lt;/p&gt; },
  number       = {1},
  journal      = {Proceedings of the AAAI Conference on Artificial Intelligence},
  author       = {Jin, Zhiwei and Cao, Juan and Zhang, Yongdong and Luo, Jiebo},
  year         = {2016},
  month        = {Mar.}
}

@inproceedings{FakeNewsOrTruthUsingSatiricalCues_Rubin,
  title     = {Fake News or Truth? Using Satirical Cues to Detect Potentially Misleading News},
  author    = {Rubin, Victoria  and
               Conroy, Niall  and
               Chen, Yimin  and
               Cornwell, Sarah},
  booktitle = {Proceedings of the Second Workshop on Computational Approaches to Deception Detection},
  month     = jun,
  year      = {2016},
  address   = {San Diego, California},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/W16-0802},
  doi       = {10.18653/v1/W16-0802},
  pages     = {7--17}
}

@article{DeceptionDetectionForFakeNews3TypesOfFakeNews_Rubin,
  author   = {Rubin, Victoria L. and Chen, Yimin and Conroy, Nadia K.},
  title    = {Deception detection for news: Three types of fakes},
  journal  = {Proceedings of the Association for Information Science and Technology},
  volume   = {52},
  number   = {1},
  pages    = {1-4},
  keywords = {news verification, deception detection, fake news detection, credibility assessment, reputable sources, fabrication, hoax, satire, natural language processing, text analytics, predictive modeling, corpus construction},
  doi      = {https://doi.org/10.1002/pra2.2015.145052010083},
  url      = {https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/pra2.2015.145052010083},
  eprint   = {https://asistdl.onlinelibrary.wiley.com/doi/pdf/10.1002/pra2.2015.145052010083},
  abstract = {ABSTRACT A fake news detection system aims to assist users in detecting and filtering out varieties of potentially deceptive news. The prediction of the chances that a particular news item is intentionally deceptive is based on the analysis of previously seen truthful and deceptive news. A scarcity of deceptive news, available as corpora for predictive modeling, is a major stumbling block in this field of natural language processing (NLP) and deception detection. This paper discusses three types of fake news, each in contrast to genuine serious reporting, and weighs their pros and cons as a corpus for text analytics and predictive modeling. Filtering, vetting, and verifying online information continues to be essential in library and information science (LIS), as the lines between traditional news and online information are blurring.},
  year     = {2015}
}

@article{ConspiracyTheories_Sunstein,
  author  = {Sunstein, Cass R. and Vermeule, Adrian},
  title   = {Conspiracy Theories: Causes and Cures*},
  journal = {Journal of Political Philosophy},
  volume  = {17},
  number  = {2},
  pages   = {202-227},
  doi     = {https://doi.org/10.1111/j.1467-9760.2008.00325.x},
  url     = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9760.2008.00325.x},
  eprint  = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-9760.2008.00325.x},
  year    = {2009}
}

@article{Superstition_Lindeman,
  title    = {Superstitious, magical, and paranormal beliefs: An integrative model},
  journal  = {Journal of Research in Personality},
  volume   = {41},
  number   = {4},
  pages    = {731-744},
  year     = {2007},
  issn     = {0092-6566},
  doi      = {https://doi.org/10.1016/j.jrp.2006.06.009},
  url      = {https://www.sciencedirect.com/science/article/pii/S0092656606000869},
  author   = {Marjaana Lindeman and Kia Aarnio},
  keywords = {Superstition, Magical thinking, Paranormal beliefs, Intuitive thinking, Core knowledge},
  abstract = {Lack of conceptual clarity has hampered theory formation and research on superstitious, magical, and paranormal beliefs. This study offers a conceptual framework where these concepts are differentiated from other unfounded beliefs and defined identically as a confusion of core knowledge about physical, psychological, and biological phenomena. When testing this definition with questionnaire items (N=239), the results showed that superstitious individuals accepted more violations of core ontological distinctions than skeptics did and that ontological confusions discriminated believers from skeptics better than intuitive thinking, analytical thinking, or emotional instability. The findings justify the present conceptualization of superstitious, magical, and paranormal beliefs, and offer new theoretical propositions for the familiar everyday beliefs that are yet scientifically so poorly understood.}
}

@article{RumorsAndHealthCareReform_Berinsky,
  title    = {Rumors and Health Care Reform: Experiments in Political Misinformation},
  author   = {Berinsky, Adam J.},
  year     = {2017},
  journal  = {British Journal of Political Science},
  volume   = {47},
  number   = {2},
  pages    = {241-262},
  abstract = {This article explores belief in political rumors surrounding the health care reforms enacted by Congress in 2010. Refuting rumors with statements from unlikely sources can, under certain circumstances, increase the willingness of citizens to reject rumors regardless of their own political predilections. Such source credibility effects, while well known in the political persuasion literature, have not been applied to the study of rumor. Though source credibility appears to be an effective tool for debunking political rumors, risks remain. Drawing upon research from psychology on â€˜fluencyâ€™ â€“ the ease of information recall â€“ this article argues that rumors acquire power through familiarity. Attempting to quash rumors through direct refutation may facilitate their diffusion by increasing fluency. The empirical results find that merely repeating a rumor increases its power.},
  url      = {https://EconPapers.repec.org/RePEc:cup:bjposi:v:47:y:2017:i:02:p:241-262_00}
}

﻿@article{WhenCorrectionsFail_Nyhan,
  author   = {Nyhan, Brendan
              and Reifler, Jason},
  title    = {When Corrections Fail: The Persistence of Political Misperceptions},
  journal  = {Political Behavior},
  year     = {2010},
  month    = {Jun},
  day      = {01},
  volume   = {32},
  number   = {2},
  pages    = {303-330},
  abstract = {An extensive literature addresses citizen ignorance, but very little research focuses on misperceptions. Can these false or unsubstantiated beliefs about politics be corrected? Previous studies have not tested the efficacy of corrections in a realistic format. We conducted four experiments in which subjects read mock news articles that included either a misleading claim from a politician, or a misleading claim and a correction. Results indicate that corrections frequently fail to reduce misperceptions among the targeted ideological group. We also document several instances of a ``backfire effect'' in which corrections actually increase misperceptions among the group in question.},
  issn     = {1573-6687},
  doi      = {10.1007/s11109-010-9112-2},
  url      = {https://doi.org/10.1007/s11109-010-9112-2}
}

@article{ProspectTheory_Kahneman,
  title   = {Prospect theory: analysis of decision under risk},
  author  = {Daniel Kahneman and Amos Tversky},
  journal = {Econometrica},
  year    = {1979},
  volume  = {47},
  pages   = {263-291}
}

@article{AdvancesInProspectTheory_Kahneman,
  title   = {Advances in prospect theory: Cumulative representation of uncertainty},
  author  = {Amos Tversky and Daniel Kahneman},
  journal = {Journal of Risk and Uncertainty},
  year    = {1992},
  volume  = {5},
  pages   = {297-323}
}

@article{TheEffectOfPeopleRecommenderOnEchoChambers_Cinus,
  title        = {The Effect of People Recommenders on Echo Chambers and Polarization},
  volume       = {16},
  url          = {https://ojs.aaai.org/index.php/ICWSM/article/view/19275},
  abstractnote = {The effects of online social media on critical issues, such as polarization and misinformation, are under scrutiny due to the disruptive consequences that these phenomena can have on our societies. Among the algorithms routinely used by social media platforms, people-recommender systems are of special interest, as they directly contribute to the evolution of the social network structure, affecting the information and the opinions users are exposed to. In this paper, we propose a novel framework to assess the effect of people recommenders on the evolution of opinions. Our proposal is based on Monte Carlo simulations combining link recommendation and opinion-dynamics models. In order to control initial conditions, we define a random network model to generate graphs with opinions, with tunable amounts of modularity and homophily. Finally, we join these elements into a methodology able to study the causal relationship between the recommender system and the echo chamber effect. Our method can also assess if such relationships are statistically significant. We also show how such a framework can be used to measure, by means of simulations, the impact of different intervention strategies. Our thorough experimentation shows that people recommenders can in fact lead to a significant increase in echo chambers. However, this happens only if there is considerable initial homophily in the network. Also, we find that if the network already contains echo chambers, the effect of the recommendation algorithm is negligible. Such findings are robust to two very different opinion dynamics models, a bounded confidence model and an epistemological model.},
  number       = {1},
  journal      = {Proceedings of the International AAAI Conference on Web and Social Media},
  author       = {Cinus, Federico and Minici, Marco and Monti, Corrado and Bonchi, Francesco},
  year         = {2022},
  month        = {May},
  pages        = {90-101}
}

@inproceedings{TheRussianFirehoseOfFalsehood_Paul,
  title  = {The Russian "Firehose of Falsehood" Propaganda Model: Why It Might Work and Options to Counter It},
  author = {Christopher Paul and Miriam Matthews},
  year   = {2016}
}

@article{TheRiseOfSocialBots_Ferrara,
  author     = {Ferrara, Emilio and Varol, Onur and Davis, Clayton and Menczer, Filippo and Flammini, Alessandro},
  title      = {The Rise of Social Bots},
  year       = {2016},
  issue_date = {July 2016},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {59},
  number     = {7},
  issn       = {0001-0782},
  url        = {https://doi.org/10.1145/2818717},
  doi        = {10.1145/2818717},
  abstract   = {Today's social bots are sophisticated and sometimes menacing. Indeed, their presence can endanger online ecosystems as well as our society.},
  journal    = {Commun. ACM},
  month      = {jun},
  pages      = {96–104},
  numpages   = {9}
}

 @article{SocialBotsDistortThe2016USPresidentialElection_Bessi,
  title   = {Social Bots Distort the 2016 US Presidential Election Online Discussion},
  volume  = {21},
  number  = {11},
  journal = {First Monday},
  author  = {Bessi, Alessandro and Ferrara, Emilio},
  year    = {2016},
  month   = {Nov}
} Available at SSRN: https://ssrn.com/abstract=2982233

@inproceedings{AnyoneCanBecomeATroll_Cheng,
  author    = {Cheng, Justin and Bernstein, Michael and Danescu-Niculescu-Mizil, Cristian and Leskovec, Jure},
  title     = {Anyone Can Become a Troll: Causes of Trolling Behavior in Online Discussions},
  year      = {2017},
  isbn      = {9781450343350},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2998181.2998213},
  doi       = {10.1145/2998181.2998213},
  abstract  = {In online communities, antisocial behavior such as trolling disrupts constructive discussion. While prior work suggests that trolling behavior is confined to a vocal and antisocial minority, we demonstrate that ordinary people can engage in such behavior as well. We propose two primary trigger mechanisms: the individual's mood, and the surrounding context of a discussion (e.g., exposure to prior trolling behavior). Through an experiment simulating an online discussion, we find that both negative mood and seeing troll posts by others significantly increases the probability of a user trolling, and together double this probability. To support and extend these results, we study how these same mechanisms play out in the wild via a data-driven, longitudinal analysis of a large online news discussion community. This analysis exposes temporal mood effects, and explores long range patterns of repeated exposure to trolling. A predictive model of trolling behavior reveals that mood and discussion context together can explain trolling behavior better than an individual's history of trolling. These results combine to suggest that ordinary people can, under the right circumstances, behave like trolls.},
  booktitle = {Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing},
  pages     = {1217–1230},
  numpages  = {14},
  keywords  = {online communities, antisocial behavior, trolling},
  location  = {Portland, Oregon, USA},
  series    = {CSCW '17}
}

@article{NewsInAnOnlineWorld_Chen,
  author   = {Chen, Yimin and Conroy, Nadia K. and Rubin, Victoria L.},
  title    = {News in an online world: The need for an “automatic crap detector”},
  journal  = {Proceedings of the Association for Information Science and Technology},
  volume   = {52},
  number   = {1},
  pages    = {1-4},
  keywords = {News verification, deception detection, fake news detection, credibility assessment, journalism practices, online news, media commercialization, natural language processing},
  doi      = {https://doi.org/10.1002/pra2.2015.145052010081},
  url      = {https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/pra2.2015.145052010081},
  eprint   = {https://asistdl.onlinelibrary.wiley.com/doi/pdf/10.1002/pra2.2015.145052010081},
  abstract = {ABSTRACT Widespread adoption of internet technologies has changed the way that news is created and consumed. The current online news environment is one that incentivizes speed and spectacle in reporting, at the cost of fact-checking and verification. The line between user generated content and traditional news has also become increasingly blurred. This poster reviews some of the professional and cultural issues surrounding online news and argues for a two-pronged approach inspired by Hemingway's “automatic crap detector” (Manning, 1965) in order to address these problems: a) proactive public engagement by educators, librarians, and information specialists to promote digital literacy practices; b) the development of automated tools and technologies to assist journalists in vetting, verifying, and fact-checking, and to assist news readers by filtering and flagging dubious information.},
  year     = {2015}
}

@inproceedings{TowardsNewsVerification_Rubin,
  author = {Rubin, Victoria and Conroy, Nadia and Chen, Yimin},
  year   = {2015},
  month  = {01},
  pages  = {},
  title  = {Towards News Verification: Deception Detection Methods for News Discourse},
  doi    = {10.13140/2.1.4822.8166}
}

@book{DieEntwicklungDerGerichtspsychologischen_Undeutsch,
  author    = {Undeutsch, Udo},
  title     = {Die Entwicklung der gerichtspsychologischen Gutachtertaetigkeit},
  publisher = {Hogrefe},
  address   = {Goettingen},
  year      = {1954},
  pages     = {32 S.},
  language  = {ger},
  library   = {JU [Signatur: JU/PH 9020 U56]}
}

 @book{SCAN_Sapir1987,
  place     = {Phoenix, AZ},
  journal   = {Scientific Content Analysis (SCAN)},
  title     = {Scientific Content Analysis ({SCAN})},
  publisher = {Laboratory of Scientific Interrogation},
  author    = {Sapir, A},
  year      = {1987}
}

 @book{SCAN_Smith2001,
  place     = {London},
  title     = {Reading between the lines: An evauluation of the Scientific Content Analysis Techniques (SCAN)},
  publisher = {Home Office},
  author    = {Smith, Nicky},
  year      = {2001}
}

@article{TheAccuracyConfidenceRelation_DePaulo,
  author   = {Bella M. DePaulo and Kelly Charlton and Harris Cooper and James J. Lindsay and Laura Muhlenbruck},
  title    = {The Accuracy-Confidence Correlation in the Detection of Deception},
  journal  = {Personality and Social Psychology Review},
  volume   = {1},
  number   = {4},
  pages    = {346-357},
  year     = {1997},
  doi      = {10.1207/s15327957pspr0104\_5},
  note     = {PMID: 15661668},
  url      = {https://doi.org/10.1207/s15327957pspr0104_5},
  eprint   = {https://doi.org/10.1207/s15327957pspr0104_5},
  abstract = {A meta-analysis was conducted of research on the relation between judges' accuracy at detecting deception and their confidence in their judgments. A total of 18 independent samples revealed an average weighted accuracy-confidence correlation of .04, a relation not significantly different from zero. However, confidence was positively correlated with judges' tendency to perceive messages as truthful, regardless of the actual truthfulness of the messages. Judges were also more confident when they really were rating truths compared to when they were rating lies. Also, men were more confident than women, and judges who had a closer relationship to the message sender felt more confident in their judgments of truths and lies. Methodological and theoretical explanations for these findings are discussed. }
}

 @misc{CommunicationUnderStress_Adams,
  title     = {Communication under stress: Indicators of veracity and deception in written narratives},
  url       = {http://hdl.handle.net/10919/11057},
  journal   = {VTechWorks Home},
  publisher = {Virginia Tech},
  author    = {Adams, Susan H.},
  year      = {2002},
  month     = {Apr}
} 

@article{LyingWords_Newman,
  author   = {Matthew L. Newman and James W. Pennebaker and Diane S. Berry and Jane M. Richards},
  title    = {Lying Words: Predicting Deception from Linguistic Styles},
  journal  = {Personality and Social Psychology Bulletin},
  volume   = {29},
  number   = {5},
  pages    = {665-675},
  year     = {2003},
  doi      = {10.1177/0146167203029005010},
  note     = {PMID: 15272998},
  url      = {https://doi.org/10.1177/0146167203029005010},
  eprint   = {https://doi.org/10.1177/0146167203029005010},
  abstract = {Telling lies often requires creating a story about an experience or attitude that does not exist. As a result, false stories may be qualitatively different from true stories. The current project investigated the features of linguistic style that distinguish between true and false stories. In an analysis of five independent samples, a computer-based text analysis program correctly classified liars and truth-tellers at a rate of 67\% when the topic was constant and a rate of 61\% overall. Compared to truth-tellers, liars showed lower cognitive complexity, used fewer self-references and other-references, and used more negative emotion words. }
}

@inproceedings{VerificatoinAndImplementationofLBDeceptionIndicators_Bachenko,
  title     = {Verification and Implementation of Language-Based Deception Indicators in Civil and Criminal Narratives},
  author    = {Bachenko, Joan  and
               Fitzpatrick, Eileen  and
               Schonwetter, Michael},
  booktitle = {Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008)},
  month     = {08},
  year      = {2008},
  address   = {Manchester, UK},
  publisher = {Coling 2008 Organizing Committee},
  url       = {https://aclanthology.org/C08-1006},
  pages     = {41--48}
}

@book{ClassificationRegressioniTrees_Breiman,
  title     = {Classification and Regression Trees},
  author    = {Breiman, L. and Friedman, J. and Stone, C.J. and Olshen, R.A.},
  isbn      = {9780412048418},
  lccn      = {83019708},
  url       = {https://books.google.de/books?id=JwQx-WOmSyQC},
  year      = {1984},
  publisher = {Taylor \& Francis}
}

@article{DecisionSupportForDeterminingVeracity_Fuller,
  title    = {Decision support for determining veracity via linguistic-based cues},
  journal  = {Decision Support Systems},
  volume   = {46},
  number   = {3},
  pages    = {695-703},
  year     = {2009},
  note     = {Wireless in the Healthcare},
  issn     = {0167-9236},
  doi      = {https://doi.org/10.1016/j.dss.2008.11.001},
  url      = {https://www.sciencedirect.com/science/article/pii/S0167923608001991},
  author   = {Christie M. Fuller and David P. Biros and Rick L. Wilson},
  keywords = {Deception, Deception detection, Credibility assessment, Classification, Linguistic-based cues, Decision support systems, Neural networks, Decision trees, Logistic regression},
  abstract = {Deception detection is an essential skill in careers such as law enforcement and must be accomplished accurately. However, humans are not very competent at determining veracity without aid. This study examined automated text-based deception detection which attempts to overcome the shortcomings of previous credibility assessment methods. A real-world, high-stakes sample of statements was collected and analyzed. Several different sets of linguistic-based cues were used as inputs for classification models. Overall accuracy rates of up to 74% were achieved, suggesting that automated deception detection systems can be an invaluable tool for those who must assess the credibility of text.}
}

@article{OnLyingAndBeingLiedTo_Hancock,
  author    = { Jeffrey T.   Hancock  and  Lauren E.   Curry  and  Saurabh   Goorha  and  Michael   Woodworth },
  title     = {On Lying and Being Lied To: A Linguistic Analysis of Deception in Computer-Mediated Communication},
  journal   = {Discourse Processes},
  volume    = {45},
  number    = {1},
  pages     = {1-23},
  year      = {2007},
  publisher = {Routledge},
  doi       = {10.1080/01638530701739181},
  url       = {https://doi.org/10.1080/01638530701739181},
  eprint    = {https://doi.org/10.1080/01638530701739181}
}

@inproceedings{OnDeceptionAndDeceptionDetection_Rubin,
  author    = {Rubin, Victoria L.},
  title     = {On Deception and Deception Detection: Content Analysis of Computer-Mediated Stated Beliefs},
  year      = {2010},
  publisher = {American Society for Information Science},
  address   = {USA},
  abstract  = {Deception in computer-mediated communication is defined as a message knowingly and intentionally transmitted by a sender to foster a false belief or conclusion by the perceiver. Stated beliefs about deception and deceptive messages or incidents are content analyzed in a sample of 324 computer-mediated communications. Relevant stated beliefs are obtained through systematic sampling and querying of the blogosphere based on 80 English words commonly used to describe deceptive incidents. Deception is conceptualized broader than lying and includes a variety of deceptive strategies: falsification, concealment (omitting material facts) and equivocation (dodging or skirting issues). The stated beliefs are argued to be valuable toward the creation of a unified multi-faceted ontology of deception, stratified along several classificatory facets such as (1) contextual domain (e.g., personal relations, politics, finances and insurance), (2) deception content (e.g., events, time, place, abstract notions), (3) message format (e.g., a complaint: they lied to us, a victim story: I was lied to or tricked, or a direct accusation: you're lying), and (4) deception variety, each tied to particular verbal cues (e.g., misinforming, scheming, misrepresenting, or cheating). The paper positions automated deception detection within the field of library and information science (LIS), as a feasible natural language processing (NLP) task. Key findings and important constructs in deception research from interpersonal communication, psychology, criminology, and language technology studies are synthesized into an overview. Deception research is juxtaposed to several benevolent constructs in LIS research: trust, credibility, certainty, and authority.},
  booktitle = {Proceedings of the 73rd ASIST Annual Meeting on Navigating Streams in an Information Ecosystem - Volume 47},
  articleno = {32},
  numpages  = {10},
  keywords  = {trust, computer-mediated communications, credibility, natural language processing, information security, content analysis, blogs, deception detection, automated text classification},
  location  = {Pittsburgh, Pennsylvania},
  series    = {ASIST '10}
}

@article{AutomatingLinguisticsBasedCues_Zhou,
  author   = {Zhou, Lina
              and Burgoon, Judee K.
              and Nunamaker, Jay F.
              and Twitchell, Doug},
  title    = {Automating Linguistics-Based Cues for Detecting Deception in Text-Based Asynchronous Computer-Mediated Communications},
  journal  = {Group Decision and Negotiation},
  year     = {2004},
  month    = {Jan},
  day      = {01},
  volume   = {13},
  number   = {1},
  pages    = {81-106},
  abstract = {The detection of deception is a promising but challenging task. A systematic discussion of automated Linguistics Based Cues (LBC) to deception has rarely been touched before. The experiment studied the effectiveness of automated LBC in the context of text-based asynchronous computer mediated communication (TA-CMC). Twenty-seven cues either extracted from the prior research or created for this study were clustered into nine linguistics constructs: quantity, diversity, complexity, specificity, expressivity, informality, affect, uncertainty, and nonimmediacy. A test of the selected LBC in a simulated TA-CMC experiment showed that: (1) a systematic analysis of linguistic information could be useful in the detection of deception; (2) some existing LBC were effective as expected, while some others turned out in the opposite direction to the prediction of the prior research; and (3) some newly discovered linguistic constructs and their component LBC were helpful in differentiating deception from truth.},
  issn     = {1572-9907},
  doi      = {10.1023/B:GRUP.0000011944.62889.6f},
  url      = {https://doi.org/10.1023/B:GRUP.0000011944.62889.6f}
}

@inproceedings{iSkim_Zhou,
  author    = {Lina Zhou and Booker, Q.E. and Dongsong Zhang},
  booktitle = {Proceedings of the 35th Annual Hawaii International Conference on System Sciences},
  title     = {ROD - toward rapid ontology development for underdeveloped domains},
  year      = {2002},
  volume    = {},
  number    = {},
  pages     = {957-965},
  doi       = {10.1109/HICSS.2002.994046}
}

@inproceedings{IdentificationOfTruth_Rubin,
  author    = {Rubin, Victoria L. and Vashchilko, Tatiana},
  title     = {Identification of Truth and Deception in Text: Application of Vector Space Model to Rhetorical Structure Theory},
  year      = {2012},
  publisher = {Association for Computational Linguistics},
  address   = {USA},
  abstract  = {The paper proposes to use Rhetorical Structure Theory (RST) analytic framework to identify systematic differences between deceptive and truthful stories in terms of their coherence and structure. A sample of 36 elicited personal stories, self-ranked as completely truthful or completely deceptive, is manually analyzed by assigning RST discourse relations among a story's constituent parts. Vector Space Model (VSM) assesses each story's position in multi-dimensional RST space with respect to its distance to truth and deceptive centers as measures of the story's level of deception and truthfulness. Ten human judges evaluate if each story is deceptive or not, and assign their confidence levels, which produce measures of the human expected deception and truthfulness levels. The paper contributes to deception detection research and RST twofold: a) demonstration of discourse structure analysis in pragmatics as a prominent way of automated deception detection and, as such, an effective complement to lexico-semantic analysis, and b) development of RST-VSM methodology to interpret RST analysis in identification of previously unseen deceptive texts.},
  booktitle = {Proceedings of the Workshop on Computational Approaches to Deception Detection},
  pages     = {97–106},
  numpages  = {10},
  location  = {Avignon, France},
  series    = {EACL 2012}
}

@article{TruthAndDeception_Rubin,
  author     = {Rubin, Victoria L. and Lukoianova, Tatiana},
  title      = {Truth and Deception at the Rhetorical Structure Level},
  year       = {2015},
  issue_date = {May 2015},
  publisher  = {John Wiley &amp; Sons, Inc.},
  address    = {USA},
  volume     = {66},
  number     = {5},
  issn       = {2330-1635},
  url        = {https://doi.org/10.1002/asi.23216},
  doi        = {10.1002/asi.23216},
  abstract   = {This paper furthers the development of methods to distinguish truth from deception in textual data. We use rhetorical structure theory RST as the analytic framework to identify systematic differences between deceptive and truthful stories in terms of their coherence and structure. A sample of 36 elicited personal stories, self-ranked as truthful or deceptive, is manually analyzed by assigning RST discourse relations among each story's constituent parts. A vector space model VSM assesses each story's position in multidimensional RST space with respect to its distance from truthful and deceptive centers as measures of the story's level of deception and truthfulness. Ten human judges evaluate independently whether each story is deceptive and assign their confidence levels 360 evaluations total, producing measures of the expected human ability to recognize deception. As a robustness check, a test sample of 18 truthful stories with 180 additional evaluations is used to determine the reliability of our RST-VSM method in determining deception. The contribution is in demonstration of the discourse structure analysis as a significant method for automated deception detection and an effective complement to lexicosemantic analysis. The potential is in developing novel discourse-based tools to alert information users to potential deception in computer-mediated texts.},
  journal    = {J. Assoc. Inf. Sci. Technol.},
  month      = {may},
  pages      = {905–917},
  numpages   = {13},
  keywords   = {computer mediated communications, discourse analysis, natural language processing}
}

@article{RST_William,
  url         = {https://doi.org/10.1515/text.1.1988.8.3.243},
  title       = {Rhetorical Structure Theory: Toward a functional theory of text organization},
  title       = {},
  author      = {William C. Mann and Sandra A. Thompson},
  pages       = {243--281},
  volume      = {8},
  number      = {3},
  journal     = {Text - Interdisciplinary Journal for the Study of Discourse},
  doi         = {doi:10.1515/text.1.1988.8.3.243},
  year        = {1988},
  lastchecked = {2022-09-24}
}

﻿@article{C45_Salzberg,
  author  = {Salzberg, Steven L.},
  title   = {C4.5: Programs for Machine Learning by J. Ross Quinlan. Morgan Kaufmann Publishers, Inc., 1993},
  journal = {Machine Learning},
  year    = {1994},
  month   = {Sep},
  day     = {01},
  volume  = {16},
  number  = {3},
  pages   = {235-240},
  issn    = {1573-0565},
  doi     = {10.1007/BF00993309},
  url     = {https://doi.org/10.1007/BF00993309}
}

@inproceedings{DetecingDeceptionThroughLA_Burgoon,
  author    = {Burgoon, Judee K.
               and Blair, J. P.
               and Qin, Tiantian
               and Nunamaker, Jay F.},
  editor    = {Chen, Hsinchun
               and Miranda, Richard
               and Zeng, Daniel D.
               and Demchak, Chris
               and Schroeder, Jenny
               and Madhusudan, Therani},
  title     = {Detecting Deception through Linguistic Analysis},
  booktitle = {Intelligence and Security Informatics},
  year      = {2003},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {91--101},
  abstract  = {Tools to detect deceit from language use pose a promising avenue for increasing the ability to distinguish truthful transmissions, transcripts, intercepted messages, informant reports and the like from deceptive ones. This investigation presents preliminary tests of 16 linguistic features that can be automated to return assessments of the likely truthful or deceptiveness of a piece of text. Results from a mock theft experiment demonstrate that deceivers do utilize language differently than truth tellers and that combinations of cues can improve the ability to predict which texts may contain deception.},
  isbn      = {978-3-540-44853-2}
}

@inproceedings{DetectingHoaxesFraudsAndDeception_Afroz,
  author    = {Afroz, Sadia and Brennan, Michael and Greenstadt, Rachel},
  booktitle = {2012 IEEE Symposium on Security and Privacy},
  title     = {Detecting Hoaxes, Frauds, and Deception in Writing Style Online},
  year      = {2012},
  volume    = {},
  number    = {},
  pages     = {461-475},
  doi       = {10.1109/SP.2012.34}
}

@inproceedings{LIWC2007_Pennebaker,
  title  = {Linguistic Inquiry and Word Count (LIWC2007)},
  author = {James W. Pennebaker and Roger John Booth and Martha E. Francis},
  year   = {2007}
}

@inbook{POS_Daelemans,
  author    = {Daelemans, Walter},
  editor    = {Sammut, Claude
               and Webb, Geoffrey I.},
  title     = {POS Tagging},
  booktitle = {Encyclopedia of Machine Learning},
  year      = {2010},
  publisher = {Springer US},
  address   = {Boston, MA},
  pages     = {776--779},
  isbn      = {978-0-387-30164-8},
  doi       = {10.1007/978-0-387-30164-8_643},
  url       = {https://doi.org/10.1007/978-0-387-30164-8_643}
}

@article{SVM_Hearst,
  author  = {Hearst, M.A. and Dumais, S.T. and Osuna, E. and Platt, J. and Scholkopf, B.},
  journal = {IEEE Intelligent Systems and their Applications},
  title   = {Support vector machines},
  year    = {1998},
  volume  = {13},
  number  = {4},
  pages   = {18-28},
  doi     = {10.1109/5254.708428}
}

@article{TF_Luhn,
  author  = {Luhn, H. P.},
  journal = {IBM Journal of Research and Development},
  title   = {A Statistical Approach to Mechanized Encoding and Searching of Literary Information},
  year    = {1957},
  volume  = {1},
  number  = {4},
  pages   = {309-317},
  doi     = {10.1147/rd.14.0309}
}

@article{IDF_Jones,
  author  = {Karen Spärck Jones},
  title   = {A statistical interpretation of term specificity and its application in retrieval},
  journal = {Journal of Documentation},
  year    = {1972},
  volume  = {28},
  pages   = {11--21}
}

@article{AStylometricInquiry_Potthast,
  author     = {Martin Potthast and
                Johannes Kiesel and
                Kevin Reinartz and
                Janek Bevendorff and
                Benno Stein},
  title      = {A Stylometric Inquiry into Hyperpartisan and Fake News},
  journal    = {CoRR},
  volume     = {abs/1702.05638},
  year       = {2017},
  url        = {http://arxiv.org/abs/1702.05638},
  eprinttype = {arXiv},
  eprint     = {1702.05638},
  timestamp  = {Wed, 30 Oct 2019 15:47:55 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/PotthastKRBS17.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{VerifyingMultimediaUse_Boididou,
  author = {Boididou, Christina and Papadopoulos, Symeon and Dang Nguyen, Duc Tien and Boato, G. and Riegler, Michael and Petlund, Andreas and Kompatsiaris, Ioannis},
  year   = {2016},
  month  = {10},
  pages  = {},
  title  = {Verifying Multimedia Use at MediaEval 2016}
}

@article{VisualMisAndDisinformation_Viorela,
  author  = {Viorela Dan and Britt Paris and Joan Donovan and Michael Hameleers and Jon Roozenbeek and Sander van der Linden and Christian von Sikorski},
  title   = {Visual Mis- and Disinformation, Social Media, and Democracy},
  journal = {Journalism \& Mass Communication Quarterly},
  volume  = {98},
  number  = {3},
  pages   = {641-664},
  year    = {2021},
  doi     = {10.1177/10776990211035395},
  url     = {https://doi.org/10.1177/10776990211035395},
  eprint  = {https://doi.org/10.1177/10776990211035395
             }
}

 @misc{PutinBehindBars_Harding,
  title     = {Putin seen behind bars in spoof video},
  url       = {https://www.theguardian.com/world/2012/feb/15/putin-behind-bars-spoof-video},
  journal   = {The Guardian},
  publisher = {Guardian News and Media},
  author    = {Harding, Luke},
  year      = {2012},
  month     = {Feb}
}

 @misc{DeepFakeQueensSpeech_Sawer,
  title     = {'deepfake' Queen's speech: Channel 4 criticised for 'disrespectful' Christmas message},
  url       = {https://www.telegraph.co.uk/news/2020/12/23/deepfake-queens-speech-channel-4-criticised-disrespectful-christmas/},
  journal   = {The Telegraph},
  publisher = {Telegraph Media Group},
  author    = {Sawer, Patrick},
  year      = {2020},
  month     = {Dec}
} 

@article{ExploitingMultiDomainVisualInformation_Qi,
  author     = {Peng Qi and
                Juan Cao and
                Tianyun Yang and
                Junbo Guo and
                Jintao Li},
  title      = {Exploiting Multi-domain Visual Information for Fake News Detection},
  journal    = {CoRR},
  volume     = {abs/1908.04472},
  year       = {2019},
  url        = {http://arxiv.org/abs/1908.04472},
  eprinttype = {arXiv},
  eprint     = {1908.04472},
  timestamp  = {Fri, 30 Jul 2021 15:26:18 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1908-04472.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{BeyondNewsContents_Shu,
  author    = {Shu, Kai and Wang, Suhang and Liu, Huan},
  title     = {Beyond News Contents: The Role of Social Context for Fake News Detection},
  year      = {2019},
  isbn      = {9781450359405},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3289600.3290994},
  doi       = {10.1145/3289600.3290994},
  abstract  = {Social media is becoming popular for news consumption due to its fast dissemination, easy access, and low cost. However, it also enables the wide propagation of fake news, i.e., news with intentionally false information. Detecting fake news is an important task, which not only ensures users receive authentic information but also helps maintain a trustworthy news ecosystem. The majority of existing detection algorithms focus on finding clues from news contents, which are generally not effective because fake news is often intentionally written to mislead users by mimicking true news. Therefore, we need to explore auxiliary information to improve detection. The social context during news dissemination process on social media forms the inherent tri-relationship, the relationship among publishers, news pieces, and users, which has the potential to improve fake news detection. For example, partisan-biased publishers are more likely to publish fake news, and low-credible users are more likely to share fake news. In this paper, we study the novel problem of exploiting social context for fake news detection. We propose a tri-relationship embedding framework TriFN, which models publisher-news relations and user-news interactions simultaneously for fake news classification. We conduct experiments on two real-world datasets, which demonstrate that the proposed approach significantly outperforms other baseline methods for fake news detection.},
  booktitle = {Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining},
  pages     = {312–320},
  numpages  = {9},
  keywords  = {joint learning, fake news detection, social media mining},
  location  = {Melbourne VIC, Australia},
  series    = {WSDM '19}
}

@inproceedings{InformationCredibilityOnTwiter_Castillo,
  author    = {Castillo, Carlos and Mendoza, Marcelo and Poblete, Barbara},
  title     = {Information Credibility on Twitter},
  year      = {2011},
  isbn      = {9781450306324},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/1963405.1963500},
  doi       = {10.1145/1963405.1963500},
  abstract  = {We analyze the information credibility of news propagated through Twitter, a popular microblogging service. Previous research has shown that most of the messages posted on Twitter are truthful, but the service is also used to spread misinformation and false rumors, often unintentionally.On this paper we focus on automatic methods for assessing the credibility of a given set of tweets. Specifically, we analyze microblog postings related to "trending" topics, and classify them as credible or not credible, based on features extracted from them. We use features from users' posting and re-posting ("re-tweeting") behavior, from the text of the posts, and from citations to external sources.We evaluate our methods using a significant number of human assessments about the credibility of items on a recent sample of Twitter postings. Our results shows that there are measurable differences in the way messages propagate, that can be used to classify them automatically as credible or not credible, with precision and recall in the range of 70\% to 80\%.},
  booktitle = {Proceedings of the 20th International Conference on World Wide Web},
  pages     = {675–684},
  numpages  = {10},
  keywords  = {social media credibility, twitter, social media analytics},
  location  = {Hyderabad, India},
  series    = {WWW '11}
}

@inproceedings{AutomaticDetectionOfRumor_Yang,
  author    = {Yang, Fan and Liu, Yang and Yu, Xiaohui and Yang, Min},
  title     = {Automatic Detection of Rumor on Sina Weibo},
  year      = {2012},
  isbn      = {9781450315463},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2350190.2350203},
  doi       = {10.1145/2350190.2350203},
  abstract  = {The problem of gauging information credibility on social networks has received considerable attention in recent years. Most previous work has chosen Twitter, the world's largest micro-blogging platform, as the premise of research. In this work, we shift the premise and study the problem of information credibility on Sina Weibo, China's leading micro-blogging service provider. With eight times more users than Twitter, Sina Weibo is more of a Facebook-Twitter hybrid than a pure Twitter clone, and exhibits several important characteristics that distinguish it from Twitter. We collect an extensive set of microblogs which have been confirmed to be false rumors based on information from the official rumor-busting service provided by Sina Weibo. Unlike previous studies on Twitter where the labeling of rumors is done manually by the participants of the experiments, the official nature of this service ensures the high quality of the dataset. We then examine an extensive set of features that can be extracted from the microblogs, and train a classifier to automatically detect the rumors from a mixed set of true information and false information. The experiments show that some of the new features we propose are indeed effective in the classification, and even the features considered in previous studies have different implications with Sina Weibo than with Twitter. To the best of our knowledge, this is the first study on rumor analysis and detection on Sina Weibo.},
  booktitle = {Proceedings of the ACM SIGKDD Workshop on Mining Data Semantics},
  articleno = {13},
  numpages  = {7},
  keywords  = {rumor detection, classification, Sina Weibo},
  location  = {Beijing, China},
  series    = {MDS '12}
}

@inproceedings{DetectRumorsUsingTimeSeries_Ma,
  author    = {Ma, Jing and Gao, Wei and Wei, Zhongyu and Lu, Yueming and Wong, Kam-Fai},
  title     = {Detect Rumors Using Time Series of Social Context Information on Microblogging Websites},
  year      = {2015},
  isbn      = {9781450337946},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2806416.2806607},
  doi       = {10.1145/2806416.2806607},
  abstract  = {Automatically identifying rumors from online social media especially microblogging websites is an important research issue. Most of existing work for rumor detection focuses on modeling features related to microblog contents, users and propagation patterns, but ignore the importance of the variation of these social context features during the message propagation over time. In this study, we propose a novel approach to capture the temporal characteristics of these features based on the time series of rumor's lifecycle, for which time series modeling technique is applied to incorporate various social context information. Our experiments using the events in two microblog datasets confirm that the method outperforms state-of-the-art rumor detection approaches by large margins. Moreover, our model demonstrates strong performance on detecting rumors at early stage after their initial broadcast.},
  booktitle = {Proceedings of the 24th ACM International on Conference on Information and Knowledge Management},
  pages     = {1751–-1754},
  numpages  = {4},
  keywords  = {temporal, rumor detection, time series, social context},
  location  = {Melbourne, Australia},
  series    = {CIKM '15}
}

@article{LatentDirichletAllocation_Blei,
  author     = {Blei, David M. and Ng, Andrew Y. and Jordan, Michael I.},
  title      = {Latent Dirichlet Allocation},
  year       = {2003},
  issue_date = {3/1/2003},
  publisher  = {JMLR.org},
  volume     = {3},
  number     = {null},
  issn       = {1532-4435},
  abstract   = {We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a finite mixture over an underlying set of topics. Each topic is, in turn, modeled as an infinite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efficient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classification, and collaborative filtering, comparing to a mixture of unigrams model and the probabilistic LSI model.},
  journal    = {J. Mach. Learn. Res.},
  month      = {mar},
  pages      = {993–1022},
  numpages   = {30}
}

@inproceedings{DetectingRumorsFromMicroblogs_Ma,
  author    = {Ma, Jing and Gao, Wei and Mitra, Prasenjit and Kwon, Sejeong and Jansen, Bernard J. and Wong, Kam-Fai and Cha, Meeyoung},
  title     = {Detecting Rumors from Microblogs with Recurrent Neural Networks},
  year      = {2016},
  isbn      = {9781577357704},
  publisher = {AAAI Press},
  abstract  = {Microblogging platforms are an ideal place for spreading rumors and automatically debunking rumors is a crucial problem. To detect rumors, existing approaches have relied on hand-crafted features for employing machine learning algorithms that require daunting manual effort. Upon facing a dubious claim, people dispute its truthfulness by posting various cues over time, which generates long-distance dependencies of evidence. This paper presents a novel method that learns continuous representations of microblog events for identifying rumors. The proposed model is based on recurrent neural networks (RNN) for learning the hidden representations that capture the variation of contextual information of relevant posts over time. Experimental results on datasets from two real-world microblog platforms demonstrate that (1) the RNN method outperforms state-of-the-art rumor detection models that use hand-crafted features; (2) performance of the RNN-based algorithm is further improved via sophisticated recurrent units and extra hidden layers; (3) RNN-based method detects rumors more quickly and accurately than existing techniques, including the leading online rumor debunking services.},
  booktitle = {Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence},
  pages     = {3818–3824},
  numpages  = {7},
  location  = {New York, New York, USA},
  series    = {IJCAI'16}
}

@inproceedings{StanceClassificationAttention_Du,
  author    = {Jiachen Du and Ruifeng Xu and Yulan He and Lin Gui},
  title     = {Stance Classification with Target-specific Neural Attention},
  booktitle = {Proceedings of the Twenty-Sixth International Joint Conference on
               Artificial Intelligence, {IJCAI-17}},
  pages     = {3988--3994},
  year      = {2017},
  doi       = {10.24963/ijcai.2017/557},
  url       = {https://doi.org/10.24963/ijcai.2017/557}
}

@inproceedings{ProminentFeaturesOfRumorPropagation_Kwon,
  author    = {Kwon, Sejeong and Cha, Meeyoung and Jung, Kyomin and Chen, Wei and Wang, Yajun},
  booktitle = {2013 IEEE 13th International Conference on Data Mining},
  title     = {Prominent Features of Rumor Propagation in Online Social Media},
  year      = {2013},
  volume    = {},
  number    = {},
  pages     = {1103-1108},
  doi       = {10.1109/ICDM.2013.61}
}


@article{FightingMisinformationOnSocialMedia_Pennycook,
  author   = {Gordon Pennycook  and David G. Rand },
  title    = {Fighting misinformation on social media using crowdsourced judgments of news source quality},
  journal  = {Proceedings of the National Academy of Sciences},
  volume   = {116},
  number   = {7},
  pages    = {2521-2526},
  year     = {2019},
  doi      = {10.1073/pnas.1806781116},
  url      = {https://www.pnas.org/doi/abs/10.1073/pnas.1806781116},
  eprint   = {https://www.pnas.org/doi/pdf/10.1073/pnas.1806781116},
  abstract = {Reducing the spread of misinformation, especially on social media, is a major challenge. We investigate one potential approach: having social media platform algorithms preferentially display content from news sources that users rate as trustworthy. To do so, we ask whether crowdsourced trust ratings can effectively differentiate more versus less reliable sources. We ran two preregistered experiments (n = 1,010 from Mechanical Turk and n = 970 from Lucid) where individuals rated familiarity with, and trust in, 60 news sources from three categories: (i) mainstream media outlets, (ii) hyperpartisan websites, and (iii) websites that produce blatantly false content (“fake news”). Despite substantial partisan differences, we find that laypeople across the political spectrum rated mainstream sources as far more trustworthy than either hyperpartisan or fake news sources. Although this difference was larger for Democrats than Republicans—mostly due to distrust of mainstream sources by Republicans—every mainstream source (with one exception) was rated as more trustworthy than every hyperpartisan or fake news source across both studies when equally weighting ratings of Democrats and Republicans. Furthermore, politically balanced layperson ratings were strongly correlated (r = 0.90) with ratings provided by professional fact-checkers. We also found that, particularly among liberals, individuals higher in cognitive reflection were better able to discern between low- and high-quality sources. Finally, we found that excluding ratings from participants who were not familiar with a given news source dramatically reduced the effectiveness of the crowd. Our findings indicate that having algorithms up-rank content from trusted media outlets may be a promising approach for fighting the spread of misinformation on social media.}
}

@inproceedings{ClickbaitDetectionUsingDL_Agrawal,
  author    = {Agrawal, Amol},
  booktitle = {2016 2nd International Conference on Next Generation Computing Technologies (NGCT)},
  title     = {Clickbait detection using deep learning},
  year      = {2016},
  volume    = {},
  number    = {},
  pages     = {268-272},
  doi       = {10.1109/NGCT.2016.7877426}
}

@inproceedings{DivingDeepIntoClickbaits_Rony,
  author    = {Rony, Md Main Uddin and Hassan, Naeemul and Yousuf, Mohammad},
  title     = {Diving Deep into Clickbaits: Who Use Them to What Extents in Which Topics with What Effects?},
  year      = {2017},
  isbn      = {9781450349932},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3110025.3110054},
  doi       = {10.1145/3110025.3110054},
  abstract  = {The use of alluring headlines (clickbait) to tempt the readers has become a growing practice nowadays. For the sake of existence in the highly competitive media industry, most of the on-line media including the mainstream ones, have started following this practice. Although the wide-spread practice of clickbait makes the reader's reliability on media vulnerable, a large scale analysis to reveal this fact is still absent. In this paper, we analyze 1.67 million Facebook posts created by 153 media organizations to understand the extent of clickbait practice, its impact and user engagement by using our own developed clickbait detection model. The model uses distributed sub-word embeddings learned from a large corpus. The accuracy of the model is 98.3\%. Powered with this model, we further study the distribution of topics in clickbait and non-clickbait contents.},
  booktitle = {Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2017},
  pages     = {232–239},
  numpages  = {8},
  location  = {Sydney, Australia},
  series    = {ASONAM '17}
}

@article{EnrichingWordVectorsWithSubwordInfo_Bojanowski,
  author     = {Piotr Bojanowski and
                Edouard Grave and
                Armand Joulin and
                Tomas Mikolov},
  title      = {Enriching Word Vectors with Subword Information},
  journal    = {CoRR},
  volume     = {abs/1607.04606},
  year       = {2016},
  url        = {http://arxiv.org/abs/1607.04606},
  eprinttype = {arXiv},
  eprint     = {1607.04606},
  timestamp  = {Mon, 28 Dec 2020 11:31:02 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/BojanowskiGJM16.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{BagOfTricksForTextClassificatoin_Joulin,
  author     = {Armand Joulin and
                Edouard Grave and
                Piotr Bojanowski and
                Tomas Mikolov},
  title      = {Bag of Tricks for Efficient Text Classification},
  journal    = {CoRR},
  volume     = {abs/1607.01759},
  year       = {2016},
  url        = {http://arxiv.org/abs/1607.01759},
  eprinttype = {arXiv},
  eprint     = {1607.01759},
  timestamp  = {Mon, 28 Dec 2020 11:31:01 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/JoulinGBM16.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{DistributedRepresentationsOfWords_Mikolov,
  author     = {Tomas Mikolov and
                Ilya Sutskever and
                Kai Chen and
                Greg Corrado and
                Jeffrey Dean},
  title      = {Distributed Representations of Words and Phrases and their Compositionality},
  journal    = {CoRR},
  volume     = {abs/1310.4546},
  year       = {2013},
  url        = {http://arxiv.org/abs/1310.4546},
  eprinttype = {arXiv},
  eprint     = {1310.4546},
  timestamp  = {Mon, 28 Dec 2020 11:31:02 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/MikolovSCCD13.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{ClickbaitAndTabloidStrategies_Dolors,
  author  = {Palau-Sampio, Dolors},
  year    = {2016},
  month   = {4},
  pages   = {63-79},
  title   = {Reference press metamorphosis in the digital context: Clickbait and tabloid strategies in Elpais.com},
  volume  = {29},
  journal = {Communication \& Society},
  doi     = {10.15581/003.29.2.63-79}
}

@inproceedings{SemEvalHyperpartisanNewsDetection_Kiesel,
  title     = {{S}em{E}val-2019 Task 4: Hyperpartisan News Detection},
  author    = {Kiesel, Johannes  and
               Mestre, Maria  and
               Shukla, Rishabh  and
               Vincent, Emmanuel  and
               Adineh, Payam  and
               Corney, David  and
               Stein, Benno  and
               Potthast, Martin},
  booktitle = {Proceedings of the 13th International Workshop on Semantic Evaluation},
  month     = {06},
  year      = {2019},
  address   = {Minneapolis, Minnesota, USA},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/S19-2145},
  doi       = {10.18653/v1/S19-2145},
  pages     = {829--839},
  abstract  = {Hyperpartisan news is news that takes an extreme left-wing or right-wing standpoint. If one is able to reliably compute this meta information, news articles may be automatically tagged, this way encouraging or discouraging readers to consume the text. It is an open question how successfully hyperpartisan news detection can be automated, and the goal of this SemEval task was to shed light on the state of the art. We developed new resources for this purpose, including a manually labeled dataset with 1,273 articles, and a second dataset with 754,000 articles, labeled via distant supervision. The interest of the research community in our task exceeded all our expectations: The datasets were downloaded about 1,000 times, 322 teams registered, of which 184 configured a virtual machine on our shared task cloud service TIRA, of which in turn 42 teams submitted a valid run. The best team achieved an accuracy of 0.822 on a balanced sample (yes : no hyperpartisan) drawn from the manually tagged corpus; an ensemble of the submitted systems increased the accuracy by 0.048.}
}

@article{BERT_Devlin,
  author     = {Jacob Devlin and
                Ming{-}Wei Chang and
                Kenton Lee and
                Kristina Toutanova},
  title      = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
                Understanding},
  journal    = {CoRR},
  volume     = {abs/1810.04805},
  year       = {2018},
  url        = {http://arxiv.org/abs/1810.04805},
  eprinttype = {arXiv},
  eprint     = {1810.04805},
  timestamp  = {Tue, 30 Oct 2018 20:39:56 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@book{TheGeneralInquirer_Stone,
  author  = {Stone, Philip and Dunphy, Dexter and Smith, Marshall and Ogilvie, Daniel},
  year    = {1966},
  month   = {01},
  pages   = {},
  title   = {The General Inquirer: A Computer Approach to Content Analysis},
  volume  = {4},
  journal = {American Educational Research Journal - AMER EDUC RES J},
  doi     = {10.2307/1161774}
}

@inproceedings{FactChecking_Vlachos,
  title     = {Fact Checking: Task definition and dataset construction},
  author    = {Vlachos, Andreas  and
               Riedel, Sebastian},
  booktitle = {Proceedings of the {ACL} 2014 Workshop on Language Technologies and Computational Social Science},
  month     = jun,
  year      = {2014},
  address   = {Baltimore, MD, USA},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/W14-2508},
  doi       = {10.3115/v1/W14-2508},
  pages     = {18--22}
}

@article{AutomatedFactChecking_Thorne,
  author     = {James Thorne and
                Andreas Vlachos},
  title      = {Automated Fact Checking: Task formulations, methods and future directions},
  journal    = {CoRR},
  volume     = {abs/1806.07687},
  year       = {2018},
  url        = {http://arxiv.org/abs/1806.07687},
  eprinttype = {arXiv},
  eprint     = {1806.07687},
  timestamp  = {Tue, 03 Nov 2020 12:45:06 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1806-07687.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{OverviewOfCheckThat_Barroncede,
  author    = {Barr{\'o}n-Cede{\~{n}}o, Alberto
               and Elsayed, Tamer
               and Nakov, Preslav
               and Da San Martino, Giovanni
               and Hasanain, Maram
               and Suwaileh, Reem
               and Haouari, Fatima
               and Babulkov, Nikolay
               and Hamdan, Bayan
               and Nikolov, Alex
               and Shaar, Shaden
               and Ali, Zien Sheikh},
  editor    = {Arampatzis, Avi
               and Kanoulas, Evangelos
               and Tsikrika, Theodora
               and Vrochidis, Stefanos
               and Joho, Hideo
               and Lioma, Christina
               and Eickhoff, Carsten
               and N{\'e}v{\'e}ol, Aur{\'e}lie
               and Cappellato, Linda
               and Ferro, Nicola},
  title     = {Overview of CheckThat! 2020: Automatic Identification and Verification of Claims in Social Media},
  booktitle = {Experimental IR Meets Multilinguality, Multimodality, and Interaction},
  year      = {2020},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {215--236},
  abstract  = {We present an overview of the third edition of the CheckThat!  Lab at CLEF 2020. The lab featured five tasks in two different languages: English and Arabic. The first four tasks compose the full pipeline of claim verification in social media: Task 1 on check-worthiness estimation, Task 2 on retrieving previously fact-checked claims, Task 3 on evidence retrieval, and Task 4 on claim verification. The lab is completed with Task 5 on check-worthiness estimation in political debates and speeches. A total of 67 teams registered to participate in the lab (up from 47 at CLEF 2019), and 23 of them actually submitted runs (compared to 14 at CLEF 2019). Most teams used deep neural networks based on BERT, LSTMs, or CNNs, and achieved sizable improvements over the baselines on all tasks. Here we describe the tasks setup, the evaluation results, and a summary of the approaches used by the participants, and we discuss some lessons learned. Last but not least, we release to the research community all datasets from the lab as well as the evaluation scripts, which should enable further research in the important tasks of check-worthiness estimation and automatic claim verification.},
  isbn      = {978-3-030-58219-7}
}

@article{WisdomOfCrowds_Galton,
  title   = {Vox populi (the wisdom of crowds)},
  author  = {Galton, Francis},
  journal = {Nature},
  volume  = {75},
  number  = {7},
  pages   = {450--451},
  year    = {1907}
}

@article{ScalingUpFactChecking_Allen,
  author   = {Jennifer Allen  and Antonio A. Arechar  and Gordon Pennycook  and David G. Rand },
  title    = {Scaling up fact-checking using the wisdom of crowds},
  journal  = {Science Advances},
  volume   = {7},
  number   = {36},
  pages    = {eabf4393},
  year     = {2021},
  doi      = {10.1126/sciadv.abf4393},
  url      = {https://www.science.org/doi/abs/10.1126/sciadv.abf4393},
  eprint   = {https://www.science.org/doi/pdf/10.1126/sciadv.abf4393},
  abstract = {When rating articles’ accuracy, a small politically balanced crowd of laypeople yields high agreement with fact-checkers. Professional fact-checking, a prominent approach to combating misinformation, does not scale easily. Furthermore, some distrust fact-checkers because of alleged liberal bias. We explore a solution to these problems: using politically balanced groups of laypeople to identify misinformation at scale. Examining 207 news articles flagged for fact-checking by Facebook algorithms, we compare accuracy ratings of three professional fact-checkers who researched each article to those of 1128 Americans from Amazon Mechanical Turk who rated each article’s headline and lede. The average ratings of small, politically balanced crowds of laypeople (i) correlate with the average fact-checker ratings as well as the fact-checkers’ ratings correlate with each other and (ii) predict whether the majority of fact-checkers rated a headline as “true” with high accuracy. Furthermore, cognitive reflection, political knowledge, and Democratic Party preference are positively related to agreement with fact-checkers, and identifying each headline’s publisher leads to a small increase in agreement with fact-checkers.}
}

@article{ASurveyOnAutomatedFactChecking_Guo,
  author   = {Guo, Zhijiang and Schlichtkrull, Michael and Vlachos, Andreas},
  title    = {{A Survey on Automated Fact-Checking}},
  journal  = {Transactions of the Association for Computational Linguistics},
  volume   = {10},
  pages    = {178-206},
  year     = {2022},
  month    = {02},
  abstract = {{Fact-checking has become increasingly important due to the speed with which both
              information and misinformation can spread in the modern media ecosystem.
              Therefore, researchers have been exploring how fact-checking can be automated,
              using techniques based on natural language processing, machine learning,
              knowledge representation, and databases to automatically predict the veracity of
              claims. In this paper, we survey automated fact-checking stemming from natural
              language processing, and discuss its connections to related tasks and
              disciplines. In this process, we present an overview of existing datasets and
              models, aiming to unify the various definitions given and identify common
              concepts. Finally, we highlight challenges for future research.}},
  issn     = {2307-387X},
  doi      = {10.1162/tacl_a_00454},
  url      = {https://doi.org/10.1162/tacl\_a\_00454},
  eprint   = {https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl\_a\_00454/1987018/tacl\_a\_00454.pdf}
}

@inproceedings{DetectingCheckWorthyClaims_Hassan,
  author    = {Hassan, Naeemul and Li, Chengkai and Tremayne, Mark},
  title     = {Detecting Check-Worthy Factual Claims in Presidential Debates},
  year      = {2015},
  isbn      = {9781450337946},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2806416.2806652},
  doi       = {10.1145/2806416.2806652},
  abstract  = {Public figures such as politicians make claims about "facts" all the time. Journalists and citizens spend a good amount of time checking the veracity of such claims. Toward automatic fact checking, we developed tools to find check-worthy factual claims from natural language sentences. Specifically, we prepared a U.S. presidential debate dataset and built classification models to distinguish check-worthy factual claims from non-factual claims and unimportant factual claims. We also identified the most-effective features based on their impact on the classification models' accuracy.},
  booktitle = {Proceedings of the 24th ACM International on Conference on Information and Knowledge Management},
  pages     = {1835–1838},
  numpages  = {4},
  keywords  = {fact checking, computational journalism, text classification},
  location  = {Melbourne, Australia},
  series    = {CIKM '15}
}

@inproceedings{FEVER_Thorne,
  title     = {{FEVER}: a Large-scale Dataset for Fact Extraction and {VER}ification},
  author    = {Thorne, James  and
               Vlachos, Andreas  and
               Christodoulopoulos, Christos  and
               Mittal, Arpit},
  booktitle = {Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)},
  month     = jun,
  year      = {2018},
  address   = {New Orleans, Louisiana},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/N18-1074},
  doi       = {10.18653/v1/N18-1074},
  pages     = {809--819},
  abstract  = {In this paper we introduce a new publicly available dataset for verification against textual sources, FEVER: Fact Extraction and VERification. It consists of 185,445 claims generated by altering sentences extracted from Wikipedia and subsequently verified without knowledge of the sentence they were derived from. The claims are classified as Supported, Refuted or NotEnoughInfo by annotators achieving 0.6841 in Fleiss kappa. For the first two classes, the annotators also recorded the sentence(s) forming the necessary evidence for their judgment. To characterize the challenge of the dataset presented, we develop a pipeline approach and compare it to suitably designed oracles. The best accuracy we achieve on labeling a claim accompanied by the correct evidence is 31.87{\%}, while if we ignore the evidence we achieve 50.91{\%}. Thus we believe that FEVER is a challenging testbed that will help stimulate progress on claim verification against textual sources.}
}

@article{UnsupervisedNamedEntityExtraction_Etzioni,
  title    = {Unsupervised named-entity extraction from the Web: An experimental study},
  journal  = {Artificial Intelligence},
  volume   = {165},
  number   = {1},
  pages    = {91-134},
  year     = {2005},
  issn     = {0004-3702},
  doi      = {https://doi.org/10.1016/j.artint.2005.03.001},
  url      = {https://www.sciencedirect.com/science/article/pii/S0004370205000366},
  author   = {Oren Etzioni and Michael Cafarella and Doug Downey and Ana-Maria Popescu and Tal Shaked and Stephen Soderland and Daniel S. Weld and Alexander Yates},
  keywords = {Information Extraction, Pointwise mutual information, Unsupervised, Question answering},
  abstract = {The KnowItAll system aims to automate the tedious process of extracting large collections of facts (e.g., names of scientists or politicians) from the Web in an unsupervised, domain-independent, and scalable manner. The paper presents an overview of KnowItAll's novel architecture and design principles, emphasizing its distinctive ability to extract information without any hand-labeled training examples. In its first major run, KnowItAll extracted over 50,000 class instances, but suggested a challenge: How can we improve KnowItAll's recall and extraction rate without sacrificing precision? This paper presents three distinct ways to address this challenge and evaluates their performance. Pattern Learning learns domain-specific extraction rules, which enable additional extractions. Subclass Extraction automatically identifies sub-classes in order to boost recall (e.g., “chemist” and “biologist” are identified as sub-classes of “scientist”). List Extraction locates lists of class instances, learns a “wrapper” for each list, and extracts elements of each list. Since each method bootstraps from KnowItAll's domain-independent methods, the methods also obviate hand-labeled training examples. The paper reports on experiments, focused on building lists of named entities, that measure the relative efficacy of each method and demonstrate their synergy. In concert, our methods gave KnowItAll a 4-fold to 8-fold increase in recall at precision of 0.90, and discovered over 10,000 cities missing from the Tipster Gazetteer.}
}

@inproceedings{WebBasedStatisticalFactChecking_Magdy,
  author    = {Magdy, Amr and Wanas, Nayer},
  title     = {Web-Based Statistical Fact Checking of Textual Documents},
  year      = {2010},
  isbn      = {9781450303866},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/1871985.1872002},
  doi       = {10.1145/1871985.1872002},
  abstract  = {User generated content has been growing tremendously in recent years. This content reflects the interests and the diversity of online users. In turn, the diversity among internet users is also reflected in the quality of the content being published online. This increases the need to develop means to gauge the support available for content posted online. In this work, we aim to make use of the web-content to calculate a statistical support score for textual documents. In the proposed algorithm, phrases representing key facts are extracted to construct basic elements of the document. Search is used thereon to validate the support available for these elements online, leading to assigning an overall score for each document. Experimental results have shown a difference between the score distribution of factual news data and false facts data. This indicates that the approach seems to be a promising seed for distinguishing different articles based on the content.},
  booktitle = {Proceedings of the 2nd International Workshop on Search and Mining User-Generated Contents},
  pages     = {103–110},
  numpages  = {8},
  keywords  = {content filtering, statistical fact analysis, web-based assessment},
  location  = {Toronto, ON, Canada},
  series    = {SMUC '10}
}

@inproceedings{SemanticFakeNewsDetection_Bracsoveanu,
  author    = {Bra{\c{s}}oveanu, Adrian M. P.
               and Andonie, R{\u{a}}zvan},
  editor    = {Rojas, Ignacio
               and Joya, Gonzalo
               and Catala, Andreu},
  title     = {Semantic Fake News Detection: A Machine Learning Perspective},
  booktitle = {Advances in Computational Intelligence},
  year      = {2019},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {656--667},
  abstract  = {Fake news detection is a difficult problem due to the nuances of language. Understanding the reasoning behind certain fake items implies inferring a lot of details about the various actors involved. We believe that the solution to this problem should be a hybrid one, combining machine learning, semantics and natural language processing. We introduce a new semantic fake news detection method built around relational features like sentiment, entities or facts extracted directly from text. Our experiments show that by adding semantic features the accuracy of fake news classification improves significantly.},
  isbn      = {978-3-030-20521-8}
}

@inproceedings{DBPedia_Auer,
  author    = {Auer, S\"{o}ren and Bizer, Christian and Kobilarov, Georgi and Lehmann, Jens and Cyganiak, Richard and Ives, Zachary},
  title     = {DBpedia: A Nucleus for a Web of Open Data},
  year      = {2007},
  isbn      = {3540762973},
  publisher = {Springer-Verlag},
  address   = {Berlin, Heidelberg},
  abstract  = {DBpedia is a community effort to extract structured information from Wikipedia and to make this information available on the Web. DBpedia allows you to ask sophisticated queries against datasets derived from Wikipedia and to link other datasets on the Web to Wikipedia data. We describe the extraction of the DBpedia datasets, and how the resulting information is published on the Web for human-andmachine-consumption. We describe some emerging applications from the DBpedia community and show how website authors can facilitate DBpedia content within their sites. Finally, we present the current status of interlinking DBpedia with other open datasets on the Web and outline how DBpedia could serve as a nucleus for an emerging Web of open data.},
  booktitle = {Proceedings of the 6th International The Semantic Web and 2nd Asian Conference on Asian Semantic Web Conference},
  pages     = {722–735},
  numpages  = {14},
  location  = {Busan, Korea},
  series    = {ISWC'07/ASWC'07}
}

@article{StanceDetectionOnSocialMeda_Abeer,
  title    = {Stance detection on social media: State of the art and trends},
  journal  = {Information Processing \& Management},
  volume   = {58},
  number   = {4},
  pages    = {102597},
  year     = {2021},
  issn     = {0306-4573},
  doi      = {https://doi.org/10.1016/j.ipm.2021.102597},
  url      = {https://www.sciencedirect.com/science/article/pii/S0306457321000960},
  author   = {Abeer ALDayel and Walid Magdy},
  keywords = {Stance detection, Stance, Social media, Stance classification},
  abstract = {Stance detection on social media is an emerging opinion mining paradigm for various social and political applications in which sentiment analysis may be sub-optimal. There has been a growing research interest for developing effective methods for stance detection methods varying among multiple communities including natural language processing, web science, and social computing, where each modeled stance detection in different ways. In this paper, we survey the work on stance detection across those communities and present an exhaustive review of stance detection techniques on social media, including the task definition, different types of targets in stance detection, features set used, and various machine learning approaches applied. Our survey reports state-of-the-art results on the existing benchmark datasets on stance detection, and discusses the most effective approaches. In addition, we explore the emerging trends and different applications of stance detection on social media, including opinion mining and prediction and recently using it for fake news detection. The study concludes by discussing the gaps in the current existing research and highlights the possible future directions for stance detection on social media.}
}

@article{StanceAndSentimentINTweets_Saif,
  author     = {Saif M. Mohammad and
                Parinaz Sobhani and
                Svetlana Kiritchenko},
  title      = {Stance and Sentiment in Tweets},
  journal    = {CoRR},
  volume     = {abs/1605.01655},
  year       = {2016},
  url        = {http://arxiv.org/abs/1605.01655},
  eprinttype = {arXiv},
  eprint     = {1605.01655},
  timestamp  = {Mon, 13 Aug 2018 16:49:12 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/MohammadSK16.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{StanceClassificationDialogicProps_Walker,
  title     = {Stance Classification using Dialogic Properties of Persuasion},
  author    = {Walker, Marilyn  and
               Anand, Pranav  and
               Abbott, Rob  and
               Grant, Ricky},
  booktitle = {Proceedings of the 2012 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies},
  month     = {06},
  year      = {2012},
  address   = {Montr{\'e}al, Canada},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/N12-1072},
  pages     = {592--596}
}


@inproceedings{FindingAndArguingExpressions_Trabelsi,
  title     = {Finding Arguing Expressions of Divergent Viewpoints in Online Debates},
  author    = {Trabelsi, Amine  and
               Zaiane, Osmar R.},
  booktitle = {Proceedings of the 5th Workshop on Language Analysis for Social Media ({LASM})},
  month     = {04},
  year      = {2014},
  address   = {Gothenburg, Sweden},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/W14-1305},
  doi       = {10.3115/v1/W14-1305},
  pages     = {35--43}
}

@inproceedings{ARetrospectiveAnalysisOfFNC_Hanselowski,
  title     = {A Retrospective Analysis of the Fake News Challenge Stance-Detection Task},
  author    = {Hanselowski, Andreas  and
               PVS, Avinesh  and
               Schiller, Benjamin  and
               Caspelherr, Felix  and
               Chaudhuri, Debanjan  and
               Meyer, Christian M.  and
               Gurevych, Iryna},
  booktitle = {Proceedings of the 27th International Conference on Computational Linguistics},
  month     = {08},
  year      = {2018},
  address   = {Santa Fe, New Mexico, USA},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/C18-1158},
  pages     = {1859--1874},
  abstract  = {The 2017 Fake News Challenge Stage 1 (FNC-1) shared task addressed a stance classification task as a crucial first step towards detecting fake news. To date, there is no in-depth analysis paper to critically discuss FNC-1{'}s experimental setup, reproduce the results, and draw conclusions for next-generation stance classification methods. In this paper, we provide such an in-depth analysis for the three top-performing systems. We first find that FNC-1{'}s proposed evaluation metric favors the majority class, which can be easily classified, and thus overestimates the true discriminative power of the methods. Therefore, we propose a new F1-based metric yielding a changed system ranking. Next, we compare the features and architectures used, which leads to a novel feature-rich stacked LSTM model that performs on par with the best systems, but is superior in predicting minority classes. To understand the methods{'} ability to generalize, we derive a new dataset and perform both in-domain and cross-domain experiments. Our qualitative and quantitative study helps interpreting the original FNC-1 scores and understand which features help improving performance and why. Our new dataset and all source code used during the reproduction study are publicly available for future research.}
}

@inproceedings{StanceDetectionInFakeNews_Ghanem,
  title     = {Stance Detection in Fake News A Combined Feature Representation},
  author    = {Ghanem, Bilal  and
               Rosso, Paolo  and
               Rangel, Francisco},
  booktitle = {Proceedings of the First Workshop on Fact Extraction and {VER}ification ({FEVER})},
  month     = {11},
  year      = {2018},
  address   = {Brussels, Belgium},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/W18-5510},
  doi       = {10.18653/v1/W18-5510},
  pages     = {66--71},
  abstract  = {With the uncontrolled increasing of fake news and rumors over the Web, different approaches have been proposed to address the problem. In this paper, we present an approach that combines lexical, word embeddings and n-gram features to detect the stance in fake news. Our approach has been tested on the Fake News Challenge (FNC-1) dataset. Given a news title-article pair, the FNC-1 task aims at determining the relevance of the article and the title. Our proposed approach has achieved an accurate result (59.6 {\%} Macro F1) that is close to the state-of-the-art result with 0.013 difference using a simple feature representation. Furthermore, we have investigated the importance of different lexicons in the detection of the classification labels.}
}

@inproceedings{StanceClassificationOnTwitterDebates_Addawood,
  author    = {Addawood, Aseel and Schneider, Jodi and Bashir, Masooda},
  title     = {Stance Classification of Twitter Debates: The Encryption Debate as A Use Case},
  year      = {2017},
  isbn      = {9781450348478},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3097286.3097288},
  doi       = {10.1145/3097286.3097288},
  abstract  = {Social media have enabled a revolution in user-generated content. They allow users to connect, build community, produce and share content, and publish opinions. To better understand online users' attitudes and opinions, we use stance classification. Stance classification is a relatively new and challenging approach to deepen opinion mining by classifying a user's stance in a debate. Our stance classification use case is tweets that were related to the spring 2016 debate over the FBI's request that Apple decrypt a user's iPhone. In this "encryption debate," public opinion was polarized between advocates for individual privacy and advocates for national security. We propose a machine learning approach to classify stance in the debate, and a topic classification that uses lexical, syntactic, Twitter-specific, and argumentative features as a predictor for classifications. Models trained on these feature sets showed significant increases in accuracy relative to the unigram baseline.},
  booktitle = {Proceedings of the 8th International Conference on Social Media \& Society},
  articleno = {2},
  numpages  = {10},
  keywords  = {Natural Language Processing, Argumentative Features, Stance Classification, Supervised Machine Learning},
  location  = {Toronto, ON, Canada}
}

@inproceedings{RumorHasIt_Qazvinian,
  title     = {Rumor has it: Identifying Misinformation in Microblogs},
  author    = {Qazvinian, Vahed  and
               Rosengren, Emily  and
               Radev, Dragomir R.  and
               Mei, Qiaozhu},
  booktitle = {Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing},
  month     = {07},
  year      = {2011},
  address   = {Edinburgh, Scotland, UK.},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/D11-1147},
  pages     = {1589--1599}
}

@inproceedings{NewsCredibilityEvaluationOnMicroblog_Jin,
  author    = {Jin, Zhiwei and Cao, Juan and Jiang, Yu-Gang and Zhang, Yongdong},
  booktitle = {2014 IEEE International Conference on Data Mining},
  title     = {News Credibility Evaluation on Microblog with a Hierarchical Propagation Model},
  year      = {2014},
  volume    = {},
  number    = {},
  pages     = {230-239},
  doi       = {10.1109/ICDM.2014.91}
}

@article{GraphSAGE_Hamilton,
  author     = {William L. Hamilton and
                Rex Ying and
                Jure Leskovec},
  title      = {Inductive Representation Learning on Large Graphs},
  journal    = {CoRR},
  volume     = {abs/1706.02216},
  year       = {2017},
  url        = {http://arxiv.org/abs/1706.02216},
  eprinttype = {arXiv},
  eprint     = {1706.02216},
  timestamp  = {Mon, 13 Aug 2018 16:46:12 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/HamiltonYL17.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@misc{AIMarketSizeRevenue_Statista,
  title     = {Artificial Intelligence Market Size/revenue comparisons 2022},
  url       = {https://www.statista.com/statistics/941835/artificial-intelligence-market-size-revenue-comparisons/},
  journal   = {Statista},
  publisher = {Statista},
  author    = {Thormundsson, Bergur},
  year      = {2022},
  month     = {Jun}
} 

@article{EURegulationsOnDecisionMaking_Goodman,
  title        = {European Union Regulations on Algorithmic Decision-Making and a “Right to Explanation”},
  volume       = {38},
  url          = {https://ojs.aaai.org/index.php/aimagazine/article/view/2741},
  doi          = {10.1609/aimag.v38i3.2741},
  abstractnote = {We summarize the potential impact that the European Union’s new General Data Protection Regulation will have on the routine use of machine learning algorithms. Slated to take effect as law across the EU in 2018, it will restrict automated individual decision-making (that is, algorithms that make decisions based on user-level predictors) which “significantly affect” users. The law will also effectively create a “right to explanation,” whereby a user can ask for an explanation of an algorithmic decision that was made about them. We argue that while this law will pose large challenges for industry, it highlights opportunities for computer scientists to take the lead in designing algorithms and evaluation frameworks which avoid discrimination and enable explanation.},
  number       = {3},
  journal      = {AI Magazine},
  author       = {Goodman, Bryce and Flaxman, Seth},
  year         = {2017},
  month        = {Oct.},
  pages        = {50-57}
}

@inproceedings{ExplaniableAIASurvey_Dosilovic,
  author    = {Dosilovic, Filip Karlo and Brcic, Mario and Hlupic, Nikica},
  booktitle = {2018 41st International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)},
  title     = {Explainable artificial intelligence: A survey},
  year      = {2018},
  volume    = {},
  number    = {},
  pages     = {0210-0215},
  doi       = {10.23919/MIPRO.2018.8400040}
}

@inproceedings{xAIForDesigners_Zhu,
  author    = {Zhu, Jichen and Liapis, Antonios and Risi, Sebastian and Bidarra, Rafael and Youngblood, G. Michael},
  title     = {Explainable AI for Designers: A Human-Centered Perspective on Mixed-Initiative Co-Creation},
  year      = {2018},
  publisher = {IEEE Press},
  url       = {https://doi.org/10.1109/CIG.2018.8490433},
  doi       = {10.1109/CIG.2018.8490433},
  abstract  = {Growing interest in eXplainable Artificial Intelligence (XAI) aims to make AI and machine learning more understandable to human users. However, most existing work focuses on new algorithms, and not on usability, practical interpretability and efficacy on real users. In this vision paper, we propose a new research area of eXplainable AI for Designers (XAID), specifically for game designers. By focusing on a specific user group, their needs and tasks, we propose a human-centered approach for facilitating game designers to co-create with AI/ML techniques through XAID. We illustrate our initial XAID framework through three use cases, which require an understanding both of the innate properties of the AI techniques and users' needs, and we identify key open challenges.},
  booktitle = {2018 IEEE Conference on Computational Intelligence and Games (CIG)},
  pages     = {1–-8},
  numpages  = {8},
  location  = {Maastricht, Netherlands}
}

@article{StopExplainingBlackBoxmodels_Rudin,
  doi       = {10.48550/ARXIV.1811.10154},
  url       = {https://arxiv.org/abs/1811.10154},
  author    = {Rudin, Cynthia},
  keywords  = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead},
  publisher = {arXiv},
  year      = {2018},
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}

@article{MethodsForInterpretingAndUnderstandingDNNs_Montavon,
  title    = {Methods for interpreting and understanding deep neural networks},
  journal  = {Digital Signal Processing},
  volume   = {73},
  pages    = {1-15},
  year     = {2018},
  issn     = {1051-2004},
  doi      = {https://doi.org/10.1016/j.dsp.2017.10.011},
  url      = {https://www.sciencedirect.com/science/article/pii/S1051200417302385},
  author   = {Grégoire Montavon and Wojciech Samek and Klaus-Robert Müller},
  keywords = {Deep neural networks, Activation maximization, Sensitivity analysis, Taylor decomposition, Layer-wise relevance propagation},
  abstract = {This paper provides an entry point to the problem of interpreting a deep neural network model and explaining its predictions. It is based on a tutorial given at ICASSP 2017. As a tutorial paper, the set of methods covered here is not exhaustive, but sufficiently representative to discuss a number of questions in interpretability, technical challenges, and possible applications. The second part of the tutorial focuses on the recently proposed layer-wise relevance propagation (LRP) technique, for which we provide theory, recommendations, and tricks, to make most efficient use of it on real data.}
}

@article{TheBayesianCaseModel_Kim,
  doi       = {10.48550/ARXIV.1503.01161},
  url       = {https://arxiv.org/abs/1503.01161},
  author    = {Kim, Been and Rudin, Cynthia and Shah, Julie},
  keywords  = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {The Bayesian Case Model: A Generative Approach for Case-Based Reasoning and Prototype Classification},
  publisher = {arXiv},
  year      = {2015},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

 @misc{InteractiveAndInterpretableMLModels_Kim,
  url       = {https://dspace.mit.edu/handle/1721.1/98680},
  journal   = {Interactive and interpretable machine learning models for human machine collaboration},
  publisher = {Massachusetts Institute of Technology},
  author    = {Kim, Been},
  year      = {2015},
  month     = {Sep}
} Thesis: Ph. D., Massachusetts Institute of Technology, Department of Aeronautics and Astronautics, 2015.

@article{DetectingAdversarilaImageExamples_Bin,
  doi       = {10.1109/tdsc.2018.2874243},
  url       = {https://doi.org/10.1109%2Ftdsc.2018.2874243},
  year      = {2021},
  month     = {01},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume    = {18},
  number    = {1},
  pages     = {72--85},
  author    = {Bin Liang and Hongcheng Li and Miaoqiang Su and Xirong Li and Wenchang Shi and Xiaofeng Wang},
  title     = {Detecting Adversarial Image Examples in Deep Neural Networks with Adaptive Noise Reduction},
  journal   = {{IEEE} Transactions on Dependable and Secure Computing}
}

@misc{AdversarialExamples_Yuan,
  doi       = {10.48550/ARXIV.1712.07107},
  url       = {https://arxiv.org/abs/1712.07107},
  author    = {Yuan, Xiaoyong and He, Pan and Zhu, Qile and Li, Xiaolin},
  keywords  = {Machine Learning (cs.LG), Cryptography and Security (cs.CR), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Adversarial Examples: Attacks and Defenses for Deep Learning},
  publisher = {arXiv},
  year      = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{RegressionShrinkage_Tibshirani,
  author   = {Tibshirani, Robert},
  title    = {Regression Shrinkage and Selection Via the Lasso},
  journal  = {Journal of the Royal Statistical Society: Series B (Methodological)},
  volume   = {58},
  number   = {1},
  pages    = {267-288},
  keywords = {quadratic programming, regression, shrinkage, subset selection},
  doi      = {https://doi.org/10.1111/j.2517-6161.1996.tb02080.x},
  url      = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.2517-6161.1996.tb02080.x},
  eprint   = {https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.2517-6161.1996.tb02080.x},
  abstract = {SUMMARY We propose a new method for estimation in linear models. The ‘lasso’ minimizes the residual sum of squares subject to the sum of the absolute value of the coefficients being less than a constant. Because of the nature of this constraint it tends to produce some coefficients that are exactly 0 and hence gives interpretable models. Our simulation studies suggest that the lasso enjoys some of the favourable properties of both subset selection and ridge regression. It produces interpretable models like subset selection and exhibits the stability of ridge regression. There is also an interesting relationship with recent work in adaptive function estimation by Donoho and Johnstone. The lasso idea is quite general and can be applied in a variety of statistical models: extensions to generalized regression models and tree-based models are briefly described.},
  year     = {1996}
}

@inproceedings{WhyShouldITrustYou_Riberio,
  author    = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  title     = {"Why Should I Trust You?": Explaining the Predictions of Any Classifier},
  year      = {2016},
  isbn      = {9781450342322},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2939672.2939778},
  doi       = {10.1145/2939672.2939778},
  abstract  = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one.In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally varound the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
  booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages     = {1135–1144},
  numpages  = {10},
  keywords  = {interpretable machine learning, interpretability, black box classifier, explaining machine learning},
  location  = {San Francisco, California, USA},
  series    = {KDD '16}
}

 @book{AnIntroductionToStatisticalLearning_Gareth,
  place     = {New York, NY},
  edition   = {1},
  title     = {An introduction to statistical learning: With applications in R},
  url       = {https://doi.org/10.1007/978-1-4614-7138-7},
  journal   = {An Introduction to Statistical Learning},
  publisher = {Springer},
  author    = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
  year      = {2013}
}

@article{ASurveyOfMethodsForExplainingBlackBoxModels_Guidotti,
  author     = {Guidotti, Riccardo and Monreale, Anna and Ruggieri, Salvatore and Turini, Franco and Giannotti, Fosca and Pedreschi, Dino},
  title      = {A Survey of Methods for Explaining Black Box Models},
  year       = {2018},
  issue_date = {September 2019},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {51},
  number     = {5},
  issn       = {0360-0300},
  url        = {https://doi.org/10.1145/3236009},
  doi        = {10.1145/3236009},
  abstract   = {In recent years, many accurate decision support systems have been constructed as black boxes, that is as systems that hide their internal logic to the user. This lack of explanation constitutes both a practical and an ethical issue. The literature reports many approaches aimed at overcoming this crucial weakness, sometimes at the cost of sacrificing accuracy for interpretability. The applications in which black box decision systems can be used are various, and each approach is typically developed to provide a solution for a specific problem and, as a consequence, it explicitly or implicitly delineates its own definition of interpretability and explanation. The aim of this article is to provide a classification of the main problems addressed in the literature with respect to the notion of explanation and the type of black box system. Given a problem definition, a black box type, and a desired explanation, this survey should help the researcher to find the proposals more useful for his own work. The proposed classification of approaches to open black box models should also be useful for putting the many research open questions in perspective.},
  journal    = {ACM Comput. Surv.},
  month      = {aug},
  articleno  = {93},
  numpages   = {42},
  keywords   = {Open the black box, explanations, transparent models, interpretability}
}

@misc{TowardsExplainableNeuralSymbolic_Bennetot,
  doi       = {10.48550/ARXIV.1909.09065},
  url       = {https://arxiv.org/abs/1909.09065},
  author    = {Bennetot, Adrien and Laurent, Jean-Luc and Chatila, Raja and Díaz-Rodríguez, Natalia},
  keywords  = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Towards Explainable Neural-Symbolic Visual Reasoning},
  publisher = {arXiv},
  year      = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{HowTheMachineThinks_Burrell,
  author   = {Jenna Burrell},
  title    = {How the machine ‘thinks’: Understanding opacity in machine learning algorithms},
  journal  = {Big Data \& Society},
  volume   = {3},
  number   = {1},
  pages    = {2053951715622512},
  year     = {2016},
  doi      = {10.1177/2053951715622512},
  url      = {https://doi.org/10.1177/2053951715622512},
  eprint   = {https://doi.org/10.1177/2053951715622512},
  abstract = {This article considers the issue of opacity as a problem for socially consequential mechanisms of classification and ranking, such as spam filters, credit card fraud detection, search engines, news trends, market segmentation and advertising, insurance or loan qualification, and credit scoring. These mechanisms of classification all frequently rely on computational algorithms, and in many cases on machine learning algorithms to do this work. In this article, I draw a distinction between three forms of opacity: (1) opacity as intentional corporate or state secrecy, (2) opacity as technical illiteracy, and (3) an opacity that arises from the characteristics of machine learning algorithms and the scale required to apply them usefully. The analysis in this article gets inside the algorithms themselves. I cite existing literatures in computer science, known industry practices (as they are publicly presented), and do some testing and manipulation of code as a form of lightweight code audit. I argue that recognizing the distinct forms of opacity that may be coming into play in a given application is a key to determining which of a variety of technical and non-technical solutions could help to prevent harm. }
}

@article{CaseBasedExplanation_Caruana,
  title    = {Case-based explanation of non-case-based learning methods},
  author   = {Caruana, R and Kangarloo, H and Dionisio, J D and Sinha, U and
              Johnson, D},
  abstract = {We show how to generate case-based explanations for
              non-case-based learning methods such as artificial neural nets or
              decision trees. The method uses the trained model (e.g., the
              neural net or the decision tree) as a distance metric to
              determine which cases in the training set are most similar to the
              case that needs to be explained. This approach is well suited to
              medical domains, where it is important to understand predictions
              made by complex machine learning models, and where training and
              clinical practice makes users adept at case interpretation.},
  journal  = {Proc AMIA Symp},
  pages    = {212--215},
  year     = 1999,
  language = {en}
}

@article{ExploitingTriRelationshipFakeNews_Shu,
  title   = {Exploiting Tri-Relationship for Fake News Detection},
  author  = {Kai Shu and Suhang Wang and Huan Liu},
  journal = {ArXiv},
  year    = {2017},
  volume  = {abs/1712.07709}
}

@misc{ExplanationInAI_Miller,
  doi       = {10.48550/ARXIV.1706.07269},
  url       = {https://arxiv.org/abs/1706.07269},
  author    = {Miller, Tim},
  keywords  = {Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Explanation in Artificial Intelligence: Insights from the Social Sciences},
  publisher = {arXiv},
  year      = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@book{ExplainableAndInterpretableModels_Escalante,
  author    = {Escalante, Hugo Jair and Escalera, Sergio and Guyon, Isabelle and Baro, Xavier and Gucluturk, Yagmur and Guclu, Umut and van Gerven, Marcel},
  title     = {Explainable and Interpretable Models in Computer Vision and Machine Learning},
  year      = {2018},
  isbn      = {3319981307},
  publisher = {Springer Publishing Company, Incorporated},
  edition   = {1st},
  pages     = {39--80},
  abstract  = {This book compiles leading research on the development of explainable and interpretable machine learning methods in the context of computer vision and machine learning. Research progress in computer vision and pattern recognition has led to a variety of modeling techniques with almost human-like performance. Although these models have obtained astounding results, they are limited in their explainability and interpretability: what is the rationale behind the decision made? what in the model structure explains its functioning? Hence, while good performance is a critical required characteristic for learning machines, explainability and interpretability capabilities are needed to take learning machines to the next step to include them in decision support systems involving human supervision. This book, written by leading international researchers, addresses key topics of explainability and interpretability, including the following: Evaluation and Generalization in Interpretable Machine Learning Explanation Methods in Deep Learning Learning Functional Causal Models with Generative Neural Networks Learning Interpreatable Rules for Multi-Label Classification Structuring Neural Networks for More Explainable Predictions Generating Post Hoc Rationales of Deep Visual Classification Decisions Ensembling Visual Explanations Explainable Deep Driving by Visualizing Causal Attention Interdisciplinary Perspective on Algorithmic Job Candidate Search Multimodal Personality Trait Analysis for Explainable Modeling of Job Interview Decisions Inherent Explainability Pattern Theory-based Video Event Interpretations}
}

@misc{MLCVPatternRecognition_Lopez,
  doi       = {10.48550/ARXIV.1605.08179},
  url       = {https://arxiv.org/abs/1605.08179},
  author    = {Lopez-Paz, David and Nishihara, Robert and Chintala, Soumith and Schölkopf, Bernhard and Bottou, Léon},
  keywords  = {Machine Learning (stat.ML), Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Discovering Causal Signals in Images},
  publisher = {arXiv},
  year      = {2016},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{CounterfactualsInXAI_Byrne,
  title     = {Counterfactuals in Explainable Artificial Intelligence (XAI): Evidence from Human Reasoning},
  author    = {Byrne, Ruth M. J.},
  booktitle = {Proceedings of the Twenty-Eighth International Joint Conference on
               Artificial Intelligence, {IJCAI-19}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  pages     = {6276--6282},
  year      = {2019},
  month     = {7},
  doi       = {10.24963/ijcai.2019/876},
  url       = {https://doi.org/10.24963/ijcai.2019/876}
}

@article{ContrastiveExplanation_Lipton,
  title     = {Contrastive Explanation},
  volume    = {27},
  doi       = {10.1017/S1358246100005130},
  journal   = {Royal Institute of Philosophy Supplement},
  publisher = {Cambridge University Press},
  author    = {Lipton, Peter},
  year      = {1990},
  pages     = {247–266}
}

@inproceedings{BeingAccurateIsNotEnough_McNee,
  title     = {Being accurate is not enough: how accuracy metrics have hurt recommender systems},
  author    = {McNee, Sean M and Riedl, John and Konstan, Joseph A},
  booktitle = {CHI'06 extended abstracts on Human factors in computing systems},
  pages     = {1097--1101},
  year      = {2006}
}

@article{AReviewOnEvaluationMetrics_Hossin,
  title     = {A review on evaluation metrics for data classification evaluations},
  author    = {Hossin, Mohammad and Sulaiman, Md Nasir},
  journal   = {International journal of data mining \& knowledge management process},
  volume    = {5},
  number    = {2},
  pages     = {1},
  year      = {2015},
  publisher = {Academy \& Industry Research Collaboration Center (AIRCC)}
}

@article{PeeringIntoTheBlackBoxOfAI_Handelman,
  author  = {Handelman, Guy S. and Kok, Hong Kuan and Chandra, Ronil V. and Razavi, Amir H. and Huang, Shiwei and Brooks, Mark and Lee, Michael J. and Asadi, Hamed},
  title   = {Peering Into the Black Box of Artificial Intelligence: Evaluation Metrics of Machine Learning Methods},
  journal = {American Journal of Roentgenology},
  volume  = {212},
  number  = {1},
  pages   = {38-43},
  year    = {2019},
  doi     = {10.2214/AJR.18.20224},
  note    = {PMID: 30332290},
  url     = {https://doi.org/10.2214/AJR.18.20224},
  eprint  = {https://doi.org/10.2214/AJR.18.20224}
}

@article{Stability_Yu,
  doi       = {10.3150/13-bejsp14},
  url       = {https://doi.org/10.3150%2F13-bejsp14},
  year      = 2013,
  month     = {sep},
  publisher = {Bernoulli Society for Mathematical Statistics and Probability},
  volume    = {19},
  number    = {4},
  author    = {Bin Yu},
  title     = {Stability},
  journal   = {Bernoulli}
}

@incollection{FairnessInML_Oneto,
  doi       = {10.1007/978-3-030-43883-8_7},
  url       = {https://doi.org/10.1007%2F978-3-030-43883-8_7},
  year      = {2020},
  publisher = {Springer International Publishing},
  pages     = {155--196},
  author    = {Luca Oneto and Silvia Chiappa},
  title     = {Fairness in Machine Learning},
  booktitle = {Recent Trends in Learning From Data}
}

 @misc{AppliedPredictiveModeling_Kuhn,
  title     = {Applied predictive modeling},
  url       = {https://link.springer.com/book/10.1007/978-1-4614-6849-3},
  journal   = {SpringerLink},
  publisher = {Springer New York},
  author    = {Kuhn, Max and Johnson, Kjell},
  year      = {2013}
}

@misc{XAI_BewareInmatesRunningTheAsylum_Miller,
  doi       = {10.48550/ARXIV.1712.00547},
  url       = {https://arxiv.org/abs/1712.00547},
  author    = {Miller, Tim and Howe, Piers and Sonenberg, Liz},
  keywords  = {Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Explainable AI: Beware of Inmates Running the Asylum Or: How I Learnt to Stop Worrying and Love the Social and Behavioural Sciences},
  publisher = {arXiv},
  year      = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{TransparencyMotivationsAndChallenges_Weller,
  doi       = {10.48550/ARXIV.1708.01870},
  url       = {https://arxiv.org/abs/1708.01870},
  author    = {Weller, Adrian},
  keywords  = {Computers and Society (cs.CY), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Transparency: Motivations and Challenges},
  publisher = {arXiv},
  year      = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@book{Causality_Pearl,
  author    = {Pearl, Judea},
  title     = {Causality: Models, Reasoning and Inference},
  year      = {2009},
  isbn      = {052189560X},
  publisher = {Cambridge University Press},
  address   = {USA},
  edition   = {2nd},
  abstract  = {Written by one of the preeminent researchers in the field, this book provides a comprehensive exposition of modern analysis of causation. It shows how causality has grown from a nebulous concept into a mathematical theory with significant applications in the fields of statistics, artificial intelligence, economics, philosophy, cognitive science, and the health and social sciences. Judea Pearl presents and unifies the probabilistic, manipulative, counterfactual, and structural approaches to causation and devises simple mathematical tools for studying the relationships between causal connections and statistical associations. The book will open the way for including causal analysis in the standard curricula of statistics, artificial intelligence, business, epidemiology, social sciences, and economics. Students in these fields will find natural models, simple inferential procedures, and precise mathematical definitions of causal concepts that traditional texts have evaded or made unduly complicated. The first edition of Causality has led to a paradigmatic change in the way that causality is treated in statistics, philosophy, computer science, social science, and economics. Cited in more than 3,000 scientific publications, it continues to liberate scientists from the traditional molds of statistical thinking. In this revised edition, Judea Pearl elucidates thorny issues, answers readers' questions, and offers a panoramic view of recent advances in this field of research. Causality will be of interests to students and professionals in a wide variety of fields. Anyone who wishes to elucidate meaningful relationships from data, predict effects of actions and policies, assess explanations of reported events, or form theories of causal understanding and causal speech will find this book stimulating and invaluable.}
}

@inproceedings{InteractiveBayesianCaseModel_Kim,
  title  = {iBCM: Interactive Bayesian Case Model Empowering Humans via Intuitive Interaction},
  author = {Been Kim and Elena L. Glassman and Brittney Johnson and Julie A. Shah},
  year   = {2015}
}

@article{StructuringDimensionsForCollaborative_Antunes,
  author     = {Antunes, Pedro and Herskovic, Valeria and Ochoa, Sergio F. and Pino, Jose A.},
  title      = {Structuring Dimensions for Collaborative Systems Evaluation},
  year       = {2008},
  issue_date = {February 2012},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {44},
  number     = {2},
  issn       = {0360-0300},
  url        = {https://doi.org/10.1145/2089125.2089128},
  doi        = {10.1145/2089125.2089128},
  abstract   = {Collaborative systems evaluation is always necessary to determine the impact a solution will have on the individuals, groups, and the organization. Several methods of evaluation have been proposed. These methods comprise a variety of approaches with various goals. Thus, the need for a strategy to select the most appropriate method for a specific case is clear. This research work presents a detailed framework to evaluate collaborative systems according to given variables and performance levels. The proposal assumes that evaluation is an evolving process during the system lifecycle. Therefore, the framework, illustrated with two examples, is complemented with a collection of guidelines to evaluate collaborative systems according to product development status.},
  journal    = {ACM Comput. Surv.},
  month      = {mar},
  articleno  = {8},
  numpages   = {28},
  keywords   = {Collaborative systems evaluation, evaluation dimensions, human-computer interaction, interaction assessment, evaluation guidelines}
}

@inproceedings{InterpretableDecisionSets_Lakkaraju,
  author    = {Lakkaraju, Himabindu and Bach, Stephen H. and Leskovec, Jure},
  title     = {Interpretable Decision Sets: A Joint Framework for Description and Prediction},
  year      = {2016},
  isbn      = {9781450342322},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2939672.2939874},
  doi       = {10.1145/2939672.2939874},
  abstract  = {One of the most important obstacles to deploying predictive models is the fact that humans do not understand and trust them. Knowing which variables are important in a model's prediction and how they are combined can be very powerful in helping people understand and trust automatic decision making systems.Here we propose interpretable decision sets, a framework for building predictive models that are highly accurate, yet also highly interpretable. Decision sets are sets of independent if-then rules. Because each rule can be applied independently, decision sets are simple, concise, and easily interpretable. We formalize decision set learning through an objective function that simultaneously optimizes accuracy and interpretability of the rules. In particular, our approach learns short, accurate, and non-overlapping rules that cover the whole feature space and pay attention to small but important classes. Moreover, we prove that our objective is a non-monotone submodular function, which we efficiently optimize to find a near-optimal set of rules.Experiments show that interpretable decision sets are as accurate at classification as state-of-the-art machine learning techniques. They are also three times smaller on average than rule-based models learned by other methods. Finally, results of a user study show that people are able to answer multiple-choice questions about the decision boundaries of interpretable decision sets and write descriptions of classes based on them faster and more accurately than with other rule-based models that were designed for interpretability. Overall, our framework provides a new approach to interpretable machine learning that balances accuracy, interpretability, and computational efficiency.},
  booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages     = {1675–1684},
  numpages  = {10},
  keywords  = {submodularity, classification, decision sets, interpretable machine learning},
  location  = {San Francisco, California, USA},
  series    = {KDD '16}
}

@article{HowToExplainIndividualClassificationDecisions_Baehrens,
  author  = {David Baehrens and Timon Schroeter and Stefan Harmeling and Motoaki Kawanabe and Katja Hansen and Klaus-Robert M{{\"u}}ller},
  title   = {How to Explain Individual Classification Decisions},
  journal = {Journal of Machine Learning Research},
  year    = {2010},
  volume  = {11},
  number  = {61},
  pages   = {1803--1831},
  url     = {http://jmlr.org/papers/v11/baehrens10a.html}
}

@book{EvaluatingLearningAlgorithms_Japkowicz,
  title     = {Evaluating learning algorithms: a classification perspective},
  author    = {Japkowicz, Nathalie and Shah, Mohak},
  year      = {2011},
  publisher = {Cambridge University Press}
}

@article{PMLB_Olson,
  title    = {{PMLB}: a large benchmark suite for machine learning evaluation
              and comparison},
  author   = {Olson, Randal S and La Cava, William and Orzechowski, Patryk and
              Urbanowicz, Ryan J and Moore, Jason H},
  abstract = {The selection, development, or comparison of machine learning
              methods in data mining can be a difficult task based on the
              target problem and goals of a particular study. Numerous publicly
              available real-world and simulated benchmark datasets have
              emerged from different sources, but their organization and
              adoption as standards have been inconsistent. As such, selecting
              and curating specific benchmarks remains an unnecessary burden on
              machine learning practitioners and data scientists.},
  journal  = {BioData Mining},
  volume   = {10},
  number   = {1},
  pages    = {36},
  month    = {12},
  year     = {2017}
}

@inproceedings{ExplainingCollaborativeFiltering_Herlocker,
  author    = {Herlocker, Jonathan L. and Konstan, Joseph A. and Riedl, John},
  title     = {Explaining Collaborative Filtering Recommendations},
  year      = {2000},
  isbn      = {1581132220},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/358916.358995},
  doi       = {10.1145/358916.358995},
  abstract  = {Automated collaborative filtering (ACF) systems predict a person's affinity for items or information by connecting that person's recorded interests with the recorded interests of a community of people and sharing ratings between like-minded persons. However, current recommender systems are black boxes, providing no transparency into the working of the recommendation. Explanations provide that transparency, exposing the reasoning and data behind a recommendation. In this paper, we address explanation interfaces for ACF systems - how they should be implemented and why they should be implemented. To explore how, we present a model for explanations based on the user's conceptual model of the recommendation process. We then present experimental results demonstrating what components of an explanation are the most compelling. To address why, we present experimental evidence that shows that providing explanations can improve the acceptance of ACF systems. We also describe some initial explorations into measuring how explanations can improve the filtering performance of users.},
  booktitle = {Proceedings of the 2000 ACM Conference on Computer Supported Cooperative Work},
  pages     = {241--250},
  numpages  = {10},
  keywords  = {MoviesLens, explanations, collaborative filtering, recommender systems, GroupLens},
  location  = {Philadelphia, Pennsylvania, USA},
  series    = {CSCW '00}
}

@misc{AHumanGroundedEvaluationBenchmark_Mohseni,
  doi       = {10.48550/ARXIV.1801.05075},
  url       = {https://arxiv.org/abs/1801.05075},
  author    = {Mohseni, Sina and Block, Jeremy E. and Ragan, Eric D.},
  keywords  = {Human-Computer Interaction (cs.HC), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {A Human-Grounded Evaluation Benchmark for Local Explanations of Machine Learning},
  publisher = {arXiv},
  year      = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

 @article{LimitedPrecisionDesignTheory_He,
  publisher = {Northwestern Polytechnical University Press},
  title     = {Neural network and signal processing system—limited precision design theory},
  author    = {He, M. and Bao, Z.},
  year      = {1998}
}

@inproceedings{InputPerturbationSensitivity_Rao,
  author    = {Rao, Zhibo and He, Mingyi and Zhu, Zhidong},
  booktitle = {2019 IEEE International Conference on Image Processing (ICIP)},
  title     = {Input-Perturbation-Sensitivity for Performance Analysis of CNNS on Image Recognition},
  year      = {2019},
  volume    = {},
  number    = {},
  pages     = {2496-2500},
  doi       = {10.1109/ICIP.2019.8803012}
}

@misc{SensitivityAndGeneralizationInNNs_Novak,
  doi       = {10.48550/ARXIV.1802.08760},
  url       = {https://arxiv.org/abs/1802.08760},
  author    = {Novak, Roman and Bahri, Yasaman and Abolafia, Daniel A. and Pennington, Jeffrey and Sohl-Dickstein, Jascha},
  keywords  = {Machine Learning (stat.ML), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Sensitivity and Generalization in Neural Networks: an Empirical Study},
  publisher = {arXiv},
  year      = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{SensitivityAnalysisForPNNs_Kowalski,
  author  = {Kowalski, Piotr A. and Kusy, Maciej},
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  title   = {Sensitivity Analysis for Probabilistic Neural Network Structure Reduction},
  year    = {2018},
  volume  = {29},
  number  = {5},
  pages   = {1919-1932},
  doi     = {10.1109/TNNLS.2017.2688482}
}

@inproceedings{DeepInsideCNNs_Simonyan,
  author    = {Karen Simonyan and
               Andrea Vedaldi and
               Andrew Zisserman},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Deep Inside Convolutional Networks: Visualising Image Classification
               Models and Saliency Maps},
  booktitle = {2nd International Conference on Learning Representations, {ICLR} 2014,
               Banff, AB, Canada, April 14-16, 2014, Workshop Track Proceedings},
  year      = {2014},
  url       = {http://arxiv.org/abs/1312.6034},
  timestamp = {Thu, 25 Jul 2019 14:36:46 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/SimonyanVZ13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{AskTheGRU_Trapit,
  doi       = {10.1145/2959100.2959180},
  url       = {https://doi.org/10.1145%2F2959100.2959180},
  year      = {2016},
  month     = {sep},
  publisher = {{ACM}},
  author    = {Trapit Bansal and David Belanger and Andrew McCallum},
  title     = {Ask the GRU: Multi-Task Learning for Deep Text Recommendations},
  booktitle = {Proceedings of the 10th {ACM} Conference on Recommender Systems}
}

@article{ExtractionOfSalientSentences_Denil,
  author     = {Misha Denil and
                Alban Demiraj and
                Nando de Freitas},
  title      = {Extraction of Salient Sentences from Labelled Documents},
  journal    = {CoRR},
  volume     = {abs/1412.6815},
  year       = {2014},
  url        = {http://arxiv.org/abs/1412.6815},
  eprinttype = {arXiv},
  eprint     = {1412.6815},
  timestamp  = {Mon, 13 Aug 2018 16:49:02 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/DenilDF14.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{LRP_Lapuschkin,
  author  = {Lapuschkin, Sebastian and Binder, Alexander and Montavon, Grégoire and Klauschen, Frederick and Müller, Klaus-Robert and Samek, Wojciech},
  year    = {2015},
  month   = {07},
  pages   = {e0130140},
  title   = {On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation},
  volume  = {10},
  journal = {PLoS ONE},
  doi     = {10.1371/journal.pone.0130140}
}

@misc{ExplainingRNNs_Arras,
  doi       = {10.48550/ARXIV.1706.07206},
  url       = {https://arxiv.org/abs/1706.07206},
  author    = {Arras, Leila and Montavon, Grégoire and Müller, Klaus-Robert and Samek, Wojciech},
  keywords  = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Neural and Evolutionary Computing (cs.NE), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Explaining Recurrent Neural Network Predictions in Sentiment Analysis},
  publisher = {arXiv},
  year      = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{DeepLIFT_Shrikumar,
  doi       = {10.48550/ARXIV.1704.02685},
  url       = {https://arxiv.org/abs/1704.02685},
  author    = {Shrikumar, Avanti and Greenside, Peyton and Kundaje, Anshul},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Learning Important Features Through Propagating Activation Differences},
  publisher = {arXiv},
  year      = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{GradientsOfCounterfactuals_Sundararajan,
  doi       = {10.48550/ARXIV.1611.02639},
  url       = {https://arxiv.org/abs/1611.02639},
  author    = {Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
  keywords  = {Machine Learning (cs.LG), Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Gradients of Counterfactuals},
  publisher = {arXiv},
  year      = {2016},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{AUnifiedApproach_Lundberg,
  doi       = {10.48550/ARXIV.1705.07874},
  url       = {https://arxiv.org/abs/1705.07874},
  author    = {Lundberg, Scott and Lee, Su-In},
  keywords  = {Artificial Intelligence (cs.AI), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {A Unified Approach to Interpreting Model Predictions},
  publisher = {arXiv},
  year      = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@book{GameTheory_Shapley,
  author    = {Shapley, Lloyd S.},
  title     = {A Value for N-Person Games},
  address   = {Santa Monica, CA},
  year      = {1952},
  doi       = {10.7249/P0295},
  publisher = {RAND Corporation}
}


@inproceedings{AlgorithmicTransparencyViaQuantitativeInputInfluence_Datta,
  author    = {Datta, Anupam and Sen, Shayak and Zick, Yair},
  booktitle = {2016 IEEE Symposium on Security and Privacy (SP)},
  title     = {Algorithmic Transparency via Quantitative Input Influence: Theory and Experiments with Learning Systems},
  year      = {2016},
  volume    = {},
  number    = {},
  pages     = {598-617},
  doi       = {10.1109/SP.2016.42}
}

@article{AnalysisOfRegressionInGameTheory_Lipovetsky,
  author   = {Lipovetsky, Stan and Conklin, Michael},
  title    = {Analysis of regression in game theory approach},
  journal  = {Applied Stochastic Models in Business and Industry},
  volume   = {17},
  number   = {4},
  pages    = {319-330},
  keywords = {co-operative games, Shapley Value, multicollinearity, regressors net effects},
  doi      = {https://doi.org/10.1002/asmb.446},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1002/asmb.446},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/asmb.446},
  abstract = {Abstract Working with multiple regression analysis a researcher usually wants to know a comparative importance of predictors in the model. However, the analysis can be made difficult because of multicollinearity among regressors, which produces biased coefficients and negative inputs to multiple determination from presum ably useful regressors. To solve this problem we apply a tool from the co-operative games theory, the Shapley Value imputation. We demonstrate the theoretical and practical advantages of the Shapley Value and show that it provides consistent results in the presence of multicollinearity. Copyright © 2001 John Wiley \& Sons, Ltd.},
  year     = {2001}
}

@article{ExplainingPredictionModels_Strumbelj,
  author   = {{\v{S}}trumbelj, Erik
              and Kononenko, Igor},
  title    = {Explaining prediction models and individual predictions with feature contributions},
  journal  = {Knowledge and Information Systems},
  year     = {2014},
  month    = {Dec},
  day      = {01},
  volume   = {41},
  number   = {3},
  pages    = {647-665},
  abstract = {We present a sensitivity analysis-based method for explaining prediction models that can be applied to any type of classification or regression model. Its advantage over existing general methods is that all subsets of input features are perturbed, so interactions and redundancies between features are taken into account. Furthermore, when explaining an additive model, the method is equivalent to commonly used additive model-specific methods. We illustrate the method's usefulness with examples from artificial and real-world data sets and an empirical analysis of running times. Results from a controlled experiment with 122 participants suggest that the method's explanations improved the participants' understanding of the model.},
  issn     = {0219-3116},
  doi      = {10.1007/s10115-013-0679-x},
  url      = {https://doi.org/10.1007/s10115-013-0679-x}
}

@misc{DeepLearningOnGraphs_Zhang,
  doi       = {10.48550/ARXIV.1812.04202},
  url       = {https://arxiv.org/abs/1812.04202},
  author    = {Zhang, Ziwei and Cui, Peng and Zhu, Wenwu},
  keywords  = {Machine Learning (cs.LG), Social and Information Networks (cs.SI), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Deep Learning on Graphs: A Survey},
  publisher = {arXiv},
  year      = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{GNNsAReview_Zhou,
  doi       = {10.48550/ARXIV.1812.08434},
  url       = {https://arxiv.org/abs/1812.08434},
  author    = {Zhou, Jie and Cui, Ganqu and Hu, Shengding and Zhang, Zhengyan and Yang, Cheng and Liu, Zhiyuan and Wang, Lifeng and Li, Changcheng and Sun, Maosong},
  keywords  = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Graph Neural Networks: A Review of Methods and Applications},
  publisher = {arXiv},
  year      = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{BeyondSigmoids_Zang,
  author    = {Zang, Chengxi and Cui, Peng and Faloutsos, Christos},
  title     = {Beyond Sigmoids: The NetTide Model for Social Network Growth, and Its Applications},
  year      = {2016},
  isbn      = {9781450342322},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2939672.2939825},
  doi       = {10.1145/2939672.2939825},
  abstract  = {What is the growth pattern of social networks, like Facebook and WeChat? Does it truly exhibit exponential early growth, as predicted by textbook models like the Bass model, SI, or the Branching Process? How about the count of links, over time, for which there are few published models?We examine the growth of several real networks, including one of the world's largest online social network, ''WeChat'', with 300 million nodes and 4.75 billion links by 2013; and we observe power law growth for both nodes and links, a fact that completely breaks the sigmoid models (like SI, and Bass). In its place, we propose NETTIDE, along with differential equations for the growth of the count of nodes, as well as links. Our model accurately fits the growth patterns of real graphs; it is general, encompassing as special cases all the known, traditional models (including Bass, SI, log-logistic growth); while still remaining parsimonious, requiring only a handful of parameters. Moreover, our NETTIDE for link growth is the first one of its kind, accurately fitting real data, and naturally leading to the densification phenomenon. We validate our model with four real, time-evolving social networks, where NETTIDE gives good fitting accuracy, and, more importantly, applied on the WeChat data, our NETTIDE forecasted more than 730 days into the future, with 3\% error.},
  booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages     = {2015--2024},
  numpages  = {10},
  keywords  = {fizzle logistic, social networks, power law growth, link growth, growth model},
  location  = {San Francisco, California, USA},
  series    = {KDD '16}
}

@misc{GNNExplainer_Ying,
  doi       = {10.48550/ARXIV.1903.03894},
  url       = {https://arxiv.org/abs/1903.03894},
  author    = {Ying, Rex and Bourgeois, Dylan and You, Jiaxuan and Zitnik, Marinka and Leskovec, Jure},
  keywords  = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {GNNExplainer: Generating Explanations for Graph Neural Networks},
  publisher = {arXiv},
  year      = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

 @misc{MachineBias_Angwin,
  title     = {Machine bias},
  url       = {https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing},
  journal   = {ProPublica},
  publisher = {ProPublica},
  author    = {Angwin, Julia and Larson, Jeff and Kirchner, Lauren and Mattu, Surya},
  year      = {2016},
  month     = {May}
}

@misc{Word2Vec_Mikolov,
  doi       = {10.48550/ARXIV.1301.3781},
  url       = {https://arxiv.org/abs/1301.3781},
  author    = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Efficient Estimation of Word Representations in Vector Space},
  publisher = {arXiv},
  year      = {2013},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{GloVe_Pennington,
  author    = {Jeffrey Pennington and Richard Socher and Christopher D. Manning},
  booktitle = {Empirical Methods in Natural Language Processing (EMNLP)},
  title     = {GloVe: Global Vectors for Word Representation},
  year      = {2014},
  pages     = {1532--1543},
  url       = {http://www.aclweb.org/anthology/D14-1162}
}

@article{ANewAlgorithmForDataCompression_Gage,
  author     = {Gage, Philip},
  title      = {A New Algorithm for Data Compression},
  year       = {1994},
  issue_date = {Feb. 1994},
  publisher  = {R &amp; D Publications, Inc.},
  address    = {USA},
  volume     = {12},
  number     = {2},
  issn       = {0898-9788},
  journal    = {C Users J.},
  month      = {feb},
  pages      = {23–38},
  numpages   = {16}
}

@misc{NeuralMachineTranslationOfRareWords_Sennrich,
  doi       = {10.48550/ARXIV.1508.07909},
  url       = {https://arxiv.org/abs/1508.07909},
  author    = {Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Neural Machine Translation of Rare Words with Subword Units},
  publisher = {arXiv},
  year      = {2015},
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{DistilBERT_Sanh,
  doi       = {10.48550/ARXIV.1910.01108},
  url       = {https://arxiv.org/abs/1910.01108},
  author    = {Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  publisher = {arXiv},
  year      = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{RoBERTa_Liu,
  doi       = {10.48550/ARXIV.1907.11692},
  url       = {https://arxiv.org/abs/1907.11692},
  author    = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {RoBERTa: A Robustly Optimized BERT Pretraining Approach},
  publisher = {arXiv},
  year      = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{BookCorpus_Yukun,
  title     = {Aligning Books and Movies: Towards Story-like Visual Explanations by Watching Movies and Reading Books},
  author    = {Yukun Zhu and Ryan Kiros and Richard Zemel and Ruslan Salakhutdinov and Raquel Urtasun and Antonio Torralba and Sanja Fidler},
  booktitle = {arXiv preprint arXiv:1506.06724},
  year      = {2015}
}

 @misc{EnglishWikipedia_Wiki,
  title     = {English Wikipedia},
  url       = {https://en.wikipedia.org/wiki/English_Wikipedia},
  journal   = {Wikipedia},
  publisher = {Wikimedia Foundation},
  year      = {2022},
  month     = {Sep}
}

@inproceedings{OpenWebText_Radford,
  title  = {Language Models are Unsupervised Multitask Learners},
  author = {Alec Radford and Jeff Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever},
  year   = {2019}
}

 @misc{CCNews_Nagel,
  title     = {CC-News},
  url       = {https://commoncrawl.org/2016/10/news-dataset-available/},
  journal   = {Common crawl},
  publisher = {Common crawl},
  author    = {Nagel, Sebastian},
  year      = {2016},
  month     = {Oct}
}

@misc{ASimpleMethodForCommonsenseReasoning_Trinh,
  doi       = {10.48550/ARXIV.1806.02847},
  url       = {https://arxiv.org/abs/1806.02847},
  author    = {Trinh, Trieu H. and Le, Quoc V.},
  keywords  = {Artificial Intelligence (cs.AI), Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {A Simple Method for Commonsense Reasoning},
  publisher = {arXiv},
  year      = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{Adam_Kingma,
  doi       = {10.48550/ARXIV.1412.6980},
  url       = {https://arxiv.org/abs/1412.6980},
  author    = {Kingma, Diederik P. and Ba, Jimmy},
  keywords  = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Adam: A Method for Stochastic Optimization},
  publisher = {arXiv},
  year      = {2014},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

 @article{GD_Cauchy,
  title   = {M´ethode g{\'e}n{\'e}rale pour la r{\'e}solution des syst{\'e}mes d'{\'e}quations simultan{\'e}es},
  journal = {Compte Rendu {\'a} l'Acad{\'e}mie des Sciences},
  author  = {Cauchy, Louis Augustin},
  year    = {1847},
  month   = {Oct}
} 

@article{SGD_Robbins,
  author    = {Herbert Robbins and Sutton Monro},
  title     = {{A Stochastic Approximation Method}},
  volume    = {22},
  journal   = {The Annals of Mathematical Statistics},
  number    = {3},
  publisher = {Institute of Mathematical Statistics},
  pages     = {400 -- 407},
  year      = {1951},
  doi       = {10.1214/aoms/1177729586},
  url       = {https://doi.org/10.1214/aoms/1177729586}
}


@inproceedings{Softmax_Bridle,
  author    = {Bridle, John},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {D. Touretzky},
  pages     = {},
  publisher = {Morgan-Kaufmann},
  title     = {Training Stochastic Model Recognition Algorithms as Networks can Lead to Maximum Mutual Information Estimation of Parameters},
  url       = {https://proceedings.neurips.cc/paper/1989/file/0336dcbab05b9d5ad24f4333c7658a0e-Paper.pdf},
  volume    = {2},
  year      = {1989}
}

@inproceedings{ImprovingWordRepresentations_Huang,
  title     = {Improving Word Representations via Global Context and Multiple Word Prototypes},
  author    = {Huang, Eric  and
               Socher, Richard  and
               Manning, Christopher  and
               Ng, Andrew},
  booktitle = {Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month     = jul,
  year      = {2012},
  address   = {Jeju Island, Korea},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/P12-1092},
  pages     = {873--882}
}

@article{LSTM_Hochreiter,
  author  = {Hochreiter, Sepp and Schmidhuber, Jürgen},
  year    = {1997},
  month   = {12},
  pages   = {1735-80},
  title   = {Long Short-term Memory},
  volume  = {9},
  journal = {Neural computation},
  doi     = {10.1162/neco.1997.9.8.1735}
}

@inproceedings{LSTMPeephole_Gers,
  author    = {Gers, F.A. and Schmidhuber, J.},
  booktitle = {Proceedings of the IEEE-INNS-ENNS International Joint Conference on Neural Networks. IJCNN 2000. Neural Computing: New Challenges and Perspectives for the New Millennium},
  title     = {Recurrent nets that time and count},
  year      = {2000},
  volume    = {3},
  number    = {},
  pages     = {189-194 vol.3},
  doi       = {10.1109/IJCNN.2000.861302}
}

@article{AchievingHumanParityinConvSR_Wayne,
  author     = {Wayne Xiong and
                Jasha Droppo and
                Xuedong Huang and
                Frank Seide and
                Mike Seltzer and
                Andreas Stolcke and
                Dong Yu and
                Geoffrey Zweig},
  title      = {Achieving Human Parity in Conversational Speech Recognition},
  journal    = {CoRR},
  volume     = {abs/1610.05256},
  year       = {2016},
  url        = {http://arxiv.org/abs/1610.05256},
  eprinttype = {arXiv},
  eprint     = {1610.05256},
  timestamp  = {Thu, 18 Jun 2020 14:52:42 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/XiongDHSSSYZ16a.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{LearningLongTermDependenciesHard_Bengio,
  title    = {Learning long-term dependencies with gradient descent is
              difficult},
  author   = {Bengio, Y and Simard, P and Frasconi, P},
  abstract = {Recurrent neural networks can be used to map input sequences to
              output sequences, such as for recognition, production or
              prediction problems. However, practical difficulties have been
              reported in training recurrent neural networks to perform tasks
              in which the temporal contingencies present in the input/output
              sequences span long intervals. We show why gradient based
              learning algorithms face an increasingly difficult problem as the
              duration of the dependencies to be captured increases. These
              results expose a trade-off between efficient learning by gradient
              descent and latching on information for long periods. Based on an
              understanding of this problem, alternatives to standard gradient
              descent are considered.},
  journal  = {IEEE Trans Neural Netw},
  volume   = {5},
  number   = {2},
  pages    = {157--166},
  year     = {1994},
  address  = {United States},
  language = {en}
}

@misc{OnTheDifficultyOfTrainingRNNs_Pascanu,
  doi       = {10.48550/ARXIV.1211.5063},
  url       = {https://arxiv.org/abs/1211.5063},
  author    = {Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
  keywords  = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {On the difficulty of training Recurrent Neural Networks},
  publisher = {arXiv},
  year      = {2012},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{ByteNet_Kalchbrenner,
  doi       = {10.48550/ARXIV.1610.10099},
  url       = {https://arxiv.org/abs/1610.10099},
  author    = {Kalchbrenner, Nal and Espeholt, Lasse and Simonyan, Karen and Oord, Aaron van den and Graves, Alex and Kavukcuoglu, Koray},
  keywords  = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Neural Machine Translation in Linear Time},
  publisher = {arXiv},
  year      = {2016},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{ConvS2S_Gehring,
  doi       = {10.48550/ARXIV.1705.03122},
  url       = {https://arxiv.org/abs/1705.03122},
  author    = {Gehring, Jonas and Auli, Michael and Grangier, David and Yarats, Denis and Dauphin, Yann N.},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Convolutional Sequence to Sequence Learning},
  publisher = {arXiv},
  year      = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{AttentionIsAllYouNeed_Vaswani,
  doi       = {10.48550/ARXIV.1706.03762},
  url       = {https://arxiv.org/abs/1706.03762},
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  keywords  = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Attention Is All You Need},
  publisher = {arXiv},
  year      = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{S2SLearningWithNNs_Sutskever,
  doi       = {10.48550/ARXIV.1409.3215},
  url       = {https://arxiv.org/abs/1409.3215},
  author    = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V.},
  keywords  = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Sequence to Sequence Learning with Neural Networks},
  publisher = {arXiv},
  year      = {2014},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{LearningPhraseRepresentations_Cho,
  doi       = {10.48550/ARXIV.1406.1078},
  url       = {https://arxiv.org/abs/1406.1078},
  author    = {Cho, Kyunghyun and van Merrienboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
  keywords  = {Computation and Language (cs.CL), Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation},
  publisher = {arXiv},
  year      = {2014},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{LearningByTransduction_Gammerman,
  author    = {A. Gammerman and V. Vovk and V. Vapnik},
  title     = {Learning by Transduction},
  booktitle = {In Uncertainty in Artificial Intelligence},
  year      = {1998},
  pages     = {148--155},
  publisher = {Morgan Kaufmann}
}

@misc{NeuralMachineTranslationByJointlyLearning_Bahdanau,
  doi       = {10.48550/ARXIV.1409.0473},
  url       = {https://arxiv.org/abs/1409.0473},
  author    = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  keywords  = {Computation and Language (cs.CL), Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Neural Machine Translation by Jointly Learning to Align and Translate},
  publisher = {arXiv},
  year      = {2014},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{LayerNorm_Ba,
  doi       = {10.48550/ARXIV.1607.06450},
  url       = {https://arxiv.org/abs/1607.06450},
  author    = {Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E.},
  keywords  = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Layer Normalization},
  publisher = {arXiv},
  year      = {2016},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{ResidualConnection_He,
  doi       = {10.48550/ARXIV.1512.03385},
  url       = {https://arxiv.org/abs/1512.03385},
  author    = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Deep Residual Learning for Image Recognition},
  publisher = {arXiv},
  year      = {2015},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{DistillingTheKnowledge_Hinton,
  doi       = {10.48550/ARXIV.1503.02531},
  url       = {https://arxiv.org/abs/1503.02531},
  author    = {Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  keywords  = {Machine Learning (stat.ML), Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Distilling the Knowledge in a Neural Network},
  publisher = {arXiv},
  year      = {2015},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{ModelCompression_Bucilua,
  author    = {Bucilu{\^a}, Cristian and Caruana, Rich and Niculescu-Mizil, Alexandru},
  title     = {Model Compression},
  year      = {2006},
  isbn      = {1595933395},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/1150402.1150464},
  doi       = {10.1145/1150402.1150464},
  abstract  = {Often the best performing supervised learning models are ensembles of hundreds or thousands of base-level classifiers. Unfortunately, the space required to store this many classifiers, and the time required to execute them at run-time, prohibits their use in applications where test sets are large (e.g. Google), where storage space is at a premium (e.g. PDAs), and where computational power is limited (e.g. hea-ring aids). We present a method for "compressing" large, complex ensembles into smaller, faster models, usually without significant loss in performance.},
  booktitle = {Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages     = {535–541},
  numpages  = {7},
  keywords  = {model compression, supervised learning},
  location  = {Philadelphia, PA, USA},
  series    = {KDD '06}
}

@misc{ALargeAnnotatedCorpus_Bowman,
  doi       = {10.48550/ARXIV.1508.05326},
  url       = {https://arxiv.org/abs/1508.05326},
  author    = {Bowman, Samuel R. and Angeli, Gabor and Potts, Christopher and Manning, Christopher D.},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {A large annotated corpus for learning natural language inference},
  publisher = {arXiv},
  year      = {2015},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{OpenWebTextCorpus_Gokaslan,
  title  = {OpenWebText Corpus},
  author = {Aaron Gokaslan and Vanya Cohen},
  url    = {http://skylion007.github.io/OpenWebTextCorpus},
  year   = {2019}
}

@article{WordCloud_Oesper,
  title     = {WordCloud: a Cytoscape plugin to create a visual semantic summary of networks},
  author    = {Oesper, Layla and Merico, Daniele and Isserlin, Ruth and Bader, Gary D},
  journal   = {Source code for biology and medicine},
  volume    = {6},
  number    = {1},
  pages     = {7},
  year      = {2011},
  publisher = {Springer}
}

@misc{GELU_Hendrycks,
  doi       = {10.48550/ARXIV.1606.08415},
  url       = {https://arxiv.org/abs/1606.08415},
  author    = {Hendrycks, Dan and Gimpel, Kevin},
  keywords  = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Gaussian Error Linear Units (GELUs)},
  publisher = {arXiv},
  year      = {2016},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{Dropout_Nitish,
  author  = {Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov},
  title   = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  journal = {Journal of Machine Learning Research},
  year    = {2014},
  volume  = {15},
  number  = {56},
  pages   = {1929--1958},
  url     = {http://jmlr.org/papers/v15/srivastava14a.html}
}

@misc{GeometricDeepLearning_Bronstein,
  doi       = {10.48550/ARXIV.2104.13478},
  url       = {https://arxiv.org/abs/2104.13478},
  author    = {Bronstein, Michael M. and Bruna, Joan and Cohen, Taco and Veličković, Petar},
  keywords  = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Computational Geometry (cs.CG), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges},
  publisher = {arXiv},
  year      = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{GNN_Scarselli,
  author  = {Scarselli, Franco and Gori, Marco and Tsoi, Ah Chung and Hagenbuchner, Markus and Monfardini, Gabriele},
  journal = {IEEE Transactions on Neural Networks},
  title   = {The Graph Neural Network Model},
  year    = {2009},
  volume  = {20},
  number  = {1},
  pages   = {61-80},
  doi     = {10.1109/TNN.2008.2005605}
}

@inproceedings{Transformers_Wolf,
  title     = {Transformers: State-of-the-Art Natural Language Processing},
  author    = {Wolf, Thomas  and
               Debut, Lysandre  and
               Sanh, Victor  and
               Chaumond, Julien  and
               Delangue, Clement  and
               Moi, Anthony  and
               Cistac, Pierric  and
               Rault, Tim  and
               Louf, Remi  and
               Funtowicz, Morgan  and
               Davison, Joe  and
               Shleifer, Sam  and
               von Platen, Patrick  and
               Ma, Clara  and
               Jernite, Yacine  and
               Plu, Julien  and
               Xu, Canwen  and
               Le Scao, Teven  and
               Gugger, Sylvain  and
               Drame, Mariama  and
               Lhoest, Quentin  and
               Rush, Alexander},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},
  month     = oct,
  year      = {2020},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2020.emnlp-demos.6},
  doi       = {10.18653/v1/2020.emnlp-demos.6},
  pages     = {38--45},
  abstract  = {Recent progress in natural language processing has been driven by advances in both model architecture and model pretraining. Transformer architectures have facilitated building higher-capacity models and pretraining has made it possible to effectively utilize this capacity for a wide variety of tasks. Transformers is an open-source library with the goal of opening up these advances to the wider machine learning community. The library consists of carefully engineered state-of-the art Transformer architectures under a unified API. Backing this library is a curated collection of pretrained models made by and available for the community. Transformers is designed to be extensible by researchers, simple for practitioners, and fast and robust in industrial deployments. The library is available at https://github.com/huggingface/transformers.}
}

@article{TheEmergingFieldOfSignalProcessingOnGraphs_Shuman,
  title     = {The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains},
  author    = {Shuman, David I and Narang, Sunil K and Frossard, Pascal and Ortega, Antonio and Vandergheynst, Pierre},
  journal   = {IEEE signal processing magazine},
  volume    = {30},
  number    = {3},
  pages     = {83--98},
  year      = {2013},
  publisher = {IEEE}
}

@book{AWaveletTourOfSignalProcessing_Mallat,
  title     = {A wavelet tour of signal processing},
  author    = {Mallat, St{\'e}phane},
  year      = {1999},
  publisher = {Elsevier}
}

@misc{GCN_Kipf,
  doi       = {10.48550/ARXIV.1609.02907},
  url       = {https://arxiv.org/abs/1609.02907},
  author    = {Kipf, Thomas N. and Welling, Max},
  keywords  = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Semi-Supervised Classification with Graph Convolutional Networks},
  publisher = {arXiv},
  year      = {2016},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{AGCN_Li,
  title     = {Adaptive graph convolutional neural networks},
  author    = {Li, Ruoyu and Wang, Sheng and Zhu, Feiyun and Huang, Junzhou},
  booktitle = {Proceedings of the AAAI conference on artificial intelligence},
  volume    = {32},
  number    = {1},
  year      = {2018}
}

@article{DCNN_Atwood,
  title   = {Diffusion-convolutional neural networks},
  author  = {Atwood, James and Towsley, Don},
  journal = {Advances in neural information processing systems},
  volume  = {29},
  year    = {2016}
}

@article{LGCN_Gao,
  author     = {Hongyang Gao and
                Zhengyang Wang and
                Shuiwang Ji},
  title      = {Large-Scale Learnable Graph Convolutional Networks},
  journal    = {CoRR},
  volume     = {abs/1808.03965},
  year       = {2018},
  url        = {http://arxiv.org/abs/1808.03965},
  eprinttype = {arXiv},
  eprint     = {1808.03965},
  timestamp  = {Sun, 02 Sep 2018 15:01:55 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1808-03965.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@misc{GeometricDeepLearningOnGraphsAndManifolds_Monti,
  doi       = {10.48550/ARXIV.1611.08402},
  url       = {https://arxiv.org/abs/1611.08402},
  author    = {Monti, Federico and Boscaini, Davide and Masci, Jonathan and Rodolà, Emanuele and Svoboda, Jan and Bronstein, Michael M.},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Geometric deep learning on graphs and manifolds using mixture model CNNs},
  publisher = {arXiv},
  year      = {2016},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{GeodesicCNNsOnRiemannManifolds_Masci,
  title     = {Geodesic convolutional neural networks on riemannian manifolds},
  author    = {Masci, Jonathan and Boscaini, Davide and Bronstein, Michael and Vandergheynst, Pierre},
  booktitle = {Proceedings of the IEEE international conference on computer vision workshops},
  pages     = {37--45},
  year      = {2015}
}

@inproceedings{ClusterGCN_Chiang,
  doi       = {10.1145/3292500.3330925},
  url       = {https://doi.org/10.1145%2F3292500.3330925},
  year      = {2019},
  month     = {jul},
  publisher = {{ACM}},
  author    = {Wei-Lin Chiang and Xuanqing Liu and Si Si and Yang Li and Samy Bengio and Cho-Jui Hsieh},
  title     = {Cluster-{GCN}},
  booktitle = {Proceedings of the 25th {ACM} {SIGKDD} International Conference on Knowledge Discovery {\&} Data Mining}
}

@misc{GraphSAINT_Zeng,
  doi       = {10.48550/ARXIV.1907.04931},
  url       = {https://arxiv.org/abs/1907.04931},
  author    = {Zeng, Hanqing and Zhou, Hongkuan and Srivastava, Ajitesh and Kannan, Rajgopal and Prasanna, Viktor},
  keywords  = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {GraphSAINT: Graph Sampling Based Inductive Learning Method},
  publisher = {arXiv},
  year      = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

 @misc{TwitterAPI_Twitter,
  title     = {Twitter API},
  url       = {https://developer.twitter.com/en/products/twitter-api},
  journal   = {Twitter},
  author    = {Twitter},
  publisher = {Twitter},
  year      = {2022}
}

@article{SpaCy_Honnibal,
  title   = {{spaCy} 2: {Natural} language understanding with {Bloom} embeddings, convolutional neural networks and incremental parsing},
  journal = {To appear},
  author  = {Honnibal, Matthew and Montani, Ines},
  year    = {2018}
}

@misc{BertAsAService_Xiao,
  title  = {bert-as-service},
  author = {Xiao, Han},
  url    = {https://github.com/hanxiao/bert-as-service},
  year   = {2018}
}

@misc{UPFD_PyGTeam,
  title  = {UPFD Source Code},
  url    = {https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/datasets/upfd.html#UPFD},
  author = {PyG Team},
  year   = {2022}
}

@article{tSNE_vanDerMaaten,
  title   = {Visualizing Data using t-SNE},
  author  = {Laurens van der Maaten and Geoffrey E. Hinton},
  journal = {Journal of Machine Learning Research},
  year    = {2008},
  volume  = {9},
  pages   = {2579--2605}
}

@article{ScikitLearn_Pedregosa,
  title   = {Scikit-learn: Machine Learning in {P}ython},
  author  = {Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
             and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
             and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
             Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  journal = {Journal of Machine Learning Research},
  volume  = {12},
  pages   = {2825--2830},
  year    = {2011}
}

@inproceedings{ReLU_Nair,
  author  = {Nair, Vinod and Hinton, Geoffrey},
  year    = {2010},
  month   = {06},
  pages   = {807-814},
  title   = {Rectified Linear Units Improve Restricted Boltzmann Machines Vinod Nair},
  volume  = {27},
  journal = {Proceedings of ICML}
}

@misc{CNNsOnGraphsForLearningMolecularFingerprints_Duvenaud,
  doi       = {10.48550/ARXIV.1509.09292},
  url       = {https://arxiv.org/abs/1509.09292},
  author    = {Duvenaud, David and Maclaurin, Dougal and Aguilera-Iparraguirre, Jorge and Gómez-Bombarelli, Rafael and Hirzel, Timothy and Aspuru-Guzik, Alán and Adams, Ryan P.},
  keywords  = {Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Convolutional Networks on Graphs for Learning Molecular Fingerprints},
  publisher = {arXiv},
  year      = {2015},
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{PyTorch_Paszke,
  doi       = {10.48550/ARXIV.1912.01703},
  url       = {https://arxiv.org/abs/1912.01703},
  author    = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Köpf, Andreas and Yang, Edward and DeVito, Zach and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
  keywords  = {Machine Learning (cs.LG), Mathematical Software (cs.MS), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  publisher = {arXiv},
  year      = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{PyTorchGeometric_Fey,
  title     = {Fast Graph Representation Learning with {PyTorch Geometric}},
  author    = {Fey, Matthias and Lenssen, Jan E.},
  booktitle = {ICLR Workshop on Representation Learning on Graphs and Manifolds},
  year      = {2019}
}

@techreport{Python_Rossum,
  title       = {Python tutorial},
  author      = {G. van Rossum},
  number      = {CS-R9526},
  institution = {Centrum voor Wiskunde en Informatica (CWI)},
  year        = {1995},
  address     = {Amsterdam},
  month       = {05}
}


@inproceedings{NetworkX_Hagberg,
  author    = {Aric A. Hagberg and Daniel A. Schult and Pieter J. Swart},
  title     = {Exploring Network Structure, Dynamics, and Function using NetworkX},
  booktitle = {Proceedings of the 7th Python in Science Conference},
  pages     = {11 - 15},
  address   = {Pasadena, CA USA},
  year      = {2008},
  editor    = {Ga\"el Varoquaux and Travis Vaught and Jarrod Millman}
}

@article{Matplotlib_Hunter,
  author    = {Hunter, J. D.},
  title     = {Matplotlib: A 2D graphics environment},
  journal   = {Computing in Science \& Engineering},
  volume    = {9},
  number    = {3},
  pages     = {90--95},
  abstract  = {Matplotlib is a 2D graphics package used for Python for
               application development, interactive scripting, and publication-quality
               image generation across user interfaces and operating systems.},
  publisher = {IEEE COMPUTER SOC},
  doi       = {10.1109/MCSE.2007.55},
  year      = {2007}
}

@inproceedings{OwenValues_Owen,
  author    = {Owen, Guilliermo},
  editor    = {Henn, Rudolf
               and Moeschlin, Otto},
  title     = {Values of Games with a Priori Unions},
  booktitle = {Mathematical Economics and Game Theory},
  year      = {1977},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {76--88},
  abstract  = {We study here the problem of modifying the (Shapley) value of a characteristic function game so as to take into account the possibility that some players --- because of personal or political affinities --- may be more likely to act together than others. We shall use y[v] to denote the usual value of the game v.},
  isbn      = {978-3-642-45494-3}
}

@article{TheOwenAndShapleyValue_Casajus,
  author  = {Casajus, André},
  year    = {2009},
  month   = {12},
  pages   = {453-457},
  title   = {The shapley value, the owen value, and the veil of ignorance},
  volume  = {11},
  journal = {International Game Theory Review (IGTR)},
  doi     = {10.1142/S0219198909002431}
}

@article{MonotonicSolutionsOfCooperativeGames_Young,
  author   = {Young, H. P.},
  title    = {Monotonic solutions of cooperative games},
  journal  = {International Journal of Game Theory},
  year     = {1985},
  month    = {Jun},
  day      = {01},
  volume   = {14},
  number   = {2},
  pages    = {65-72},
  abstract = {The principle of monotonicity for cooperative games states that if a game changes so that some player's contribution to all coalitions increases or stays the same then the player's allocation should not decrease. There is a unique symmetric and efficient solution concept that is monotonic in this most general sense --- the Shapley value. Monotonicity thus provides a simple characterization of the value without resorting to the usual ``additivity'' and ``dummy'' assumptions, and lends support to the use of the value in applications where the underlying ``game'' is changing, e.g. in cost allocation problems.},
  issn     = {1432-1270},
  doi      = {10.1007/BF01769885},
  url      = {https://doi.org/10.1007/BF01769885}
}

 @misc{ThePrincipleOfTruthOMeter_Holan,
  title     = {The Principles of the Truth-O-Meter: PolitiFact’s methodology for independent fact-checking},
  url       = {https://www.politifact.com/article/2018/feb/12/principles-truth-o-meter-politifacts-methodology-i/},
  journal   = {Politifact},
  publisher = {The Polyner Institute},
  author    = {Holan, Angie Drobnic},
  year      = {2018},
  month     = {12}
}

 @misc{FactCheckRatings_Snopes,
  title     = {Fact check ratings},
  url       = {https://www.snopes.com/fact-check-ratings/},
  journal   = {Fact Check Ratings | Snopes.com},
  publisher = {Snopes},
  year      = {2022}
}

 @misc{DiversityOfPerspectives_Twitter,
  title     = {Diversity of perspectives},
  url       = {https://twitter.github.io/birdwatch/diversity-of-perspectives/},
  journal   = {Diversity of perspectives | Birdwatch Guide},
  publisher = {Twitter},
  year      = {2022}
}

 @misc{MetaFactCheckingProgram_Meta,
  title     = {How facebook's third-party fact-checking program works},
  url       = {https://www.facebook.com/formedia/blog/third-party-fact-checking-how-it-works},
  journal   = {How Meta's third-party fact-checking program works},
  publisher = {Meta},
  year      = {2021},
  month     = {Jun}
}

@article{SequenceTransdutionWithRNNs_Graves,
  author     = {Alex Graves},
  title      = {Sequence Transduction with Recurrent Neural Networks},
  journal    = {CoRR},
  volume     = {abs/1211.3711},
  year       = {2012},
  url        = {http://arxiv.org/abs/1211.3711},
  eprinttype = {arXiv},
  eprint     = {1211.3711},
  timestamp  = {Mon, 13 Aug 2018 16:48:55 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1211-3711.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

 @misc{BirdwatchOverview_Twitter,
  title     = {Birdwatch Guide},
  url       = {https://twitter.github.io/birdwatch/overview/},
  journal   = {Overview | Birdwatch Guide},
  publisher = {Twitter},
  year      = {2022}
}

@misc{EffectiveApproachesToAttentionBased_Luong,
  doi       = {10.48550/ARXIV.1508.04025},
  url       = {https://arxiv.org/abs/1508.04025},
  author    = {Luong, Minh-Thang and Pham, Hieu and Manning, Christopher D.},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Effective Approaches to Attention-based Neural Machine Translation},
  publisher = {arXiv},
  year      = {2015},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

 @misc{ScikitTSNE_scikit,
  title     = {Sklearn.manifold.TSNE},
  url       = {https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html},
  journal   = {scikit},
  publisher = {scikit-learn},
  year      = {2022}
} 